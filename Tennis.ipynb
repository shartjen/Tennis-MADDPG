{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env_file_name = \"Tennis_Windows_x86_64/Tennis.exe\"\n",
    "# env = UnityEnvironment(file_name=env_file_name)\n",
    "env = UnityEnvironment(file_name=env_file_name,no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "states shape :  (2, 24)\n",
      "Both states look like :  [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -6.65278625 -1.5\n",
      "  -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -6.4669857  -1.5\n",
      "   0.          0.         -6.83172083  6.          0.          0.        ]]\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.         -13.30557251  -3.          -0.           0.\n",
      "   13.66344166  12.          -0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.         -12.93397141  -3.           0.           0.\n",
      "  -13.66344166  12.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "print('states shape : ',states.shape)\n",
    "print('Both states look like : ',states)\n",
    "print(2*states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    total_scores = []\n",
    "    for i in range(100):                                        # play game for 5 episodes\n",
    "        env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "        states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        t = 0\n",
    "        while True:\n",
    "            actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "            actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "            # print('actions : ',actions)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            t += 1\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "        print('Score (max over agents) from episode {}: {}, and {} steps taken'.format(i, np.max(scores),t))\n",
    "        print(scores)\n",
    "        total_scores.append(scores)\n",
    "    print('Average Random Score : ', np.mean(total_scores))\n",
    "        \n",
    "def plot_results(results):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    plt.ion()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(results.all_rewards)), [np.sum(ar) for ar in results.all_rewards])\n",
    "    plt.plot(np.arange(len(results.avg_rewards)), results.avg_rewards)\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(results.critic_loss)), results.critic_loss)\n",
    "    plt.ylabel('critic_losses')\n",
    "    plt.xlabel('Learn Step #')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(results.actor_loss)), results.actor_loss)\n",
    "    plt.ylabel('actor_losses')\n",
    "    plt.xlabel('Learn Step #')\n",
    "    plt.show()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 0/3023   0% ETA:  --:--:-- |                                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "New Run :\n",
      "-------------------------------------\n",
      "Config Parameters    : \n",
      "gamma                : 0.99\n",
      "tau                  : 0.01\n",
      "action_size          : 2\n",
      "state_size           : 24\n",
      "hidden_size          : 256\n",
      "buffer_size          : 50000\n",
      "batch_size           : 256\n",
      "seed                 : 64\n",
      "max_episodes         : 3023\n",
      "dropout              : 0.01\n",
      "learn_every          : 1\n",
      "learn_num            : 2\n",
      "critic_learning_rate : 0.001\n",
      "actor_learning_rate  : 0.001\n",
      "noise_decay          : 0.999\n",
      "sigma                : 1\n",
      "num_agents           : 2\n",
      "env_file_name        : Tennis_Windows_x86_64/Tennis.exe\n",
      "load_model           : False\n",
      "save_model           : True\n",
      "train_mode           : True\n",
      "brain_name           : TennisBrain\n",
      "Running on device :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\drlnd\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\programdata\\anaconda3\\envs\\drlnd\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 with 15 steps || Reward : [ 0.   -0.01] || avg reward :  0.000 || Noise  0.999 || 0.138 seconds, mem : 15\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 20/3023   0% ETA:  0:05:32 |                                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 with 15 steps || Reward : [ 0.   -0.01] || avg reward :  0.000 || Noise  0.979 || 0.236 seconds, mem : 299\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 39/3023   1% ETA:  0:08:37 |                                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.000 || Noise  0.960 || 0.254 seconds, mem : 583\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 43/3023   1% ETA:  0:09:08 |                                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 42 with 29 steps || Reward : [0.   0.09] || avg reward :  0.002 || Noise  0.958 || 0.317 seconds, mem : 626\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 57/3023   1% ETA:  0:09:39 |                                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.001 || Noise  0.941 || 0.177 seconds, mem : 882\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 80/3023   2% ETA:  0:09:35 |-                                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80 with 15 steps || Reward : [ 0.   -0.01] || avg reward :  0.001 || Noise  0.922 || 0.195 seconds, mem : 1166\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 98/3023   3% ETA:  0:09:30 |/                                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 with 15 steps || Reward : [ 0.   -0.01] || avg reward :  0.001 || Noise  0.904 || 0.193 seconds, mem : 1450\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 122/3023   4% ETA:  0:09:22 |/                                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 120 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.001 || Noise  0.886 || 0.189 seconds, mem : 1734\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 140/3023   4% ETA:  0:09:18 ||                                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.001 || Noise  0.868 || 0.183 seconds, mem : 2018\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 146/3023   4% ETA:  0:09:16 |/                                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 146 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.001 || Noise  0.863 || 0.254 seconds, mem : 2119\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 157/3023   5% ETA:  0:09:15 |\\\\                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 160 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.001 || Noise  0.851 || 0.200 seconds, mem : 2318\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 181/3023   5% ETA:  0:09:24 |||                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 180 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.001 || Noise  0.834 || 0.221 seconds, mem : 2602\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 201/3023   6% ETA:  0:09:26 |||                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.001 || Noise  0.818 || 0.202 seconds, mem : 2886\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 206/3023   6% ETA:  0:09:26 |//                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 209 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.002 || Noise  0.810 || 0.277 seconds, mem : 3031\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 221/3023   7% ETA:  0:09:27 |||                                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 220 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.002 || Noise  0.802 || 0.195 seconds, mem : 3187\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 241/3023   7% ETA:  0:09:26 ||||                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 240 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.002 || Noise  0.786 || 0.230 seconds, mem : 3471\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 246/3023   8% ETA:  0:09:26 |///                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 245 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.003 || Noise  0.782 || 0.313 seconds, mem : 3560\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 251/3023   8% ETA:  0:09:26 |---                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 254 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.003 || Noise  0.775 || 0.302 seconds, mem : 3703\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 261/3023   8% ETA:  0:09:25 ||||                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 260 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.003 || Noise  0.770 || 0.216 seconds, mem : 3788\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 281/3023   9% ETA:  0:09:22 ||||                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.003 || Noise  0.755 || 0.202 seconds, mem : 4071\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 286/3023   9% ETA:  0:09:21 |///                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 286 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.004 || Noise  0.750 || 0.283 seconds, mem : 4173\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 301/3023   9% ETA:  0:09:20 ||||                                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.004 || Noise  0.740 || 0.210 seconds, mem : 4371\n",
      "\u001b[0m\u001b[41mEpisode 301 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.005 || Noise  0.739 || 0.292 seconds, mem : 4402\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 311/3023  10% ETA:  0:09:20 |----                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 311 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.005 || Noise  0.732 || 0.290 seconds, mem : 4569\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 316/3023  10% ETA:  0:09:20 |\\\\\\\\                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 319 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.006 || Noise  0.726 || 0.288 seconds, mem : 4699\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 321/3023  10% ETA:  0:09:20 |||||                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 320 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.006 || Noise  0.725 || 0.231 seconds, mem : 4713\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 331/3023  10% ETA:  0:09:18 |----                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 333 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.007 || Noise  0.716 || 0.285 seconds, mem : 4913\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 336/3023  11% ETA:  0:09:18 |\\\\\\\\                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 335 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.008 || Noise  0.715 || 0.267 seconds, mem : 4957\n",
      "\u001b[0m\u001b[41mEpisode 338 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.009 || Noise  0.712 || 0.276 seconds, mem : 5016\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 341/3023  11% ETA:  0:09:19 |||||                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 340 with 30 steps || Reward : [-0.01  0.  ] || avg reward :  0.009 || Noise  0.711 || 0.314 seconds, mem : 5060\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 359/3023  11% ETA:  0:09:20 |||||                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 360 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.007 || Noise  0.697 || 0.204 seconds, mem : 5344\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 364/3023  12% ETA:  0:09:20 |////                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 364 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.008 || Noise  0.694 || 0.252 seconds, mem : 5418\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 382/3023  12% ETA:  0:09:11 |||||                                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 380 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.008 || Noise  0.683 || 0.136 seconds, mem : 5645\n",
      "\u001b[0m\u001b[41mEpisode 381 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.009 || Noise  0.682 || 0.177 seconds, mem : 5675\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 390/3023  12% ETA:  0:09:06 |/////                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 390 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.009 || Noise  0.676 || 0.210 seconds, mem : 5819\n",
      "\u001b[0m\u001b[41mEpisode 392 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.010 || Noise  0.675 || 0.215 seconds, mem : 5864\n",
      "\u001b[0m\u001b[41mEpisode 393 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.011 || Noise  0.674 || 0.186 seconds, mem : 5895\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 396/3023  13% ETA:  0:09:03 |-----                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.011 || Noise  0.670 || 0.152 seconds, mem : 5994\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 403/3023  13% ETA:  0:08:59 |\\\\\\\\\\                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 403 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.011 || Noise  0.668 || 0.192 seconds, mem : 6052\n",
      "\u001b[0m\u001b[41mEpisode 407 with 28 steps || Reward : [-0.01  0.1 ] || avg reward :  0.012 || Noise  0.665 || 0.204 seconds, mem : 6123\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 417/3023  13% ETA:  0:08:58 |-----                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 416 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.012 || Noise  0.659 || 0.276 seconds, mem : 6267\n",
      "\u001b[0m\u001b[41mEpisode 419 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.012 || Noise  0.657 || 0.328 seconds, mem : 6327\n",
      "\u001b[0mEpisode 420 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.012 || Noise  0.656 || 0.208 seconds, mem : 6341\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 439/3023  14% ETA:  0:09:10 ||||||                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 440 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.010 || Noise  0.643 || 0.463 seconds, mem : 6650\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 442/3023  14% ETA:  0:09:11 |/////                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 443 with 32 steps || Reward : [0.   0.09] || avg reward :  0.011 || Noise  0.641 || 0.457 seconds, mem : 6710\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 445/3023  14% ETA:  0:09:14 |-----                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 444 with 31 steps || Reward : [0.   0.09] || avg reward :  0.012 || Noise  0.641 || 0.480 seconds, mem : 6741\n",
      "\u001b[0m\u001b[41mEpisode 447 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.013 || Noise  0.639 || 0.289 seconds, mem : 6800\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 449/3023  14% ETA:  0:09:15 |\\\\\\\\\\                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 449 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.014 || Noise  0.637 || 0.408 seconds, mem : 6846\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 452/3023  14% ETA:  0:09:16 ||||||                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 451 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.015 || Noise  0.636 || 0.402 seconds, mem : 6892\n",
      "\u001b[0m\u001b[41mEpisode 453 with 32 steps || Reward : [0.   0.09] || avg reward :  0.016 || Noise  0.635 || 0.344 seconds, mem : 6938\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 455/3023  15% ETA:  0:09:18 |/////                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 457 with 31 steps || Reward : [0.   0.09] || avg reward :  0.017 || Noise  0.632 || 0.317 seconds, mem : 7012\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 459/3023  15% ETA:  0:09:19 |-----                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 458 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.018 || Noise  0.632 || 0.422 seconds, mem : 7041\n",
      "\u001b[0mEpisode 460 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.018 || Noise  0.631 || 0.241 seconds, mem : 7069\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 463/3023  15% ETA:  0:09:20 |\\\\\\\\\\                                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 463 with 27 steps || Reward : [-0.01  0.1 ] || avg reward :  0.019 || Noise  0.629 || 0.285 seconds, mem : 7124\n",
      "\u001b[0m\u001b[41mEpisode 465 with 31 steps || Reward : [0.   0.09] || avg reward :  0.019 || Noise  0.627 || 0.283 seconds, mem : 7169\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 468/3023  15% ETA:  0:09:19 |||||||                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 471 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.020 || Noise  0.624 || 0.257 seconds, mem : 7271\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 473/3023  15% ETA:  0:09:18 |//////                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 473 with 30 steps || Reward : [0.   0.09] || avg reward :  0.020 || Noise  0.622 || 0.274 seconds, mem : 7315\n",
      "\u001b[0m\u001b[41mEpisode 474 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.021 || Noise  0.622 || 0.284 seconds, mem : 7345\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 478/3023  15% ETA:  0:09:17 |------                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 479 with 29 steps || Reward : [0.   0.09] || avg reward :  0.022 || Noise  0.619 || 0.265 seconds, mem : 7431\n",
      "\u001b[0mEpisode 480 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.022 || Noise  0.618 || 0.199 seconds, mem : 7445\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 483/3023  15% ETA:  0:09:16 |\\\\\\\\\\\\                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 482 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.022 || Noise  0.617 || 0.262 seconds, mem : 7490\n",
      "\u001b[0m\u001b[41mEpisode 483 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.023 || Noise  0.616 || 0.288 seconds, mem : 7522\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 488/3023  16% ETA:  0:09:15 |||||||                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 489 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.024 || Noise  0.612 || 0.270 seconds, mem : 7634\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 493/3023  16% ETA:  0:09:14 |//////                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 493 with 41 steps || Reward : [ 0.1  -0.01] || avg reward :  0.022 || Noise  0.610 || 0.306 seconds, mem : 7718\n",
      "\u001b[0m\u001b[41mEpisode 494 with 26 steps || Reward : [ 0.1  -0.01] || avg reward :  0.023 || Noise  0.609 || 0.247 seconds, mem : 7744\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 497/3023  16% ETA:  0:09:14 |------                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 496 with 31 steps || Reward : [0.   0.09] || avg reward :  0.024 || Noise  0.608 || 0.282 seconds, mem : 7789\n",
      "\u001b[0m\u001b[41mEpisode 499 with 30 steps || Reward : [0.   0.09] || avg reward :  0.025 || Noise  0.606 || 0.251 seconds, mem : 7848\n",
      "\u001b[0mEpisode 500 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.025 || Noise  0.606 || 0.184 seconds, mem : 7862\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 502/3023  16% ETA:  0:09:13 |\\\\\\\\\\\\                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 502 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.026 || Noise  0.605 || 0.275 seconds, mem : 7913\n",
      "\u001b[0m\u001b[41mEpisode 504 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.026 || Noise  0.603 || 0.256 seconds, mem : 7957\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 507/3023  16% ETA:  0:09:12 |||||||                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 506 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.027 || Noise  0.602 || 0.254 seconds, mem : 8002\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 512/3023  16% ETA:  0:09:11 |//////                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 512 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.027 || Noise  0.599 || 0.259 seconds, mem : 8107\n",
      "\u001b[0m\u001b[41mEpisode 513 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.028 || Noise  0.598 || 0.264 seconds, mem : 8138\n",
      "\u001b[0m\u001b[41mEpisode 514 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.029 || Noise  0.597 || 0.265 seconds, mem : 8168\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 516/3023  17% ETA:  0:09:11 |------                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 515 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.030 || Noise  0.597 || 0.271 seconds, mem : 8197\n",
      "\u001b[0m\u001b[41mEpisode 517 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.030 || Noise  0.596 || 0.467 seconds, mem : 8239\n",
      "\u001b[0m\u001b[41mEpisode 518 with 32 steps || Reward : [0.   0.09] || avg reward :  0.031 || Noise  0.595 || 0.327 seconds, mem : 8271\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 520/3023  17% ETA:  0:09:12 |\\\\\\\\\\\\                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 520 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.030 || Noise  0.594 || 0.201 seconds, mem : 8299\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 525/3023  17% ETA:  0:09:10 |||||||                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 525 with 31 steps || Reward : [0.   0.09] || avg reward :  0.031 || Noise  0.591 || 0.290 seconds, mem : 8387\n",
      "\u001b[0m\u001b[41mEpisode 527 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.032 || Noise  0.590 || 0.261 seconds, mem : 8431\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 530/3023  17% ETA:  0:09:09 |//////                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 529 with 26 steps || Reward : [-0.01  0.1 ] || avg reward :  0.033 || Noise  0.588 || 0.241 seconds, mem : 8471\n",
      "\u001b[0m\u001b[41mEpisode 531 with 31 steps || Reward : [0.   0.09] || avg reward :  0.034 || Noise  0.587 || 0.265 seconds, mem : 8516\n",
      "\u001b[0m\u001b[41mEpisode 533 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.035 || Noise  0.586 || 0.267 seconds, mem : 8560\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 535/3023  17% ETA:  0:09:09 |------                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 535 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.585 || 0.252 seconds, mem : 8604\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 540/3023  17% ETA:  0:09:08 |\\\\\\\\\\\\                                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 538 with 30 steps || Reward : [0.   0.09] || avg reward :  0.037 || Noise  0.583 || 0.321 seconds, mem : 8663\n",
      "\u001b[0m\u001b[41mEpisode 540 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.582 || 0.272 seconds, mem : 8707\n",
      "\u001b[0m\u001b[41mEpisode 541 with 30 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.581 || 0.268 seconds, mem : 8737\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 545/3023  18% ETA:  0:09:07 ||||||||                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 547 with 34 steps || Reward : [0.1  0.09] || avg reward :  0.036 || Noise  0.578 || 0.289 seconds, mem : 8842\n",
      "\u001b[0m\u001b[41mEpisode 548 with 27 steps || Reward : [-0.01  0.1 ] || avg reward :  0.037 || Noise  0.577 || 0.241 seconds, mem : 8869\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 550/3023  18% ETA:  0:09:06 |///////                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 549 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.577 || 0.250 seconds, mem : 8898\n",
      "\u001b[0m\u001b[41mEpisode 552 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.575 || 0.249 seconds, mem : 8957\n",
      "\u001b[0m\u001b[41mEpisode 553 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.574 || 0.265 seconds, mem : 8988\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 555/3023  18% ETA:  0:09:05 |-------                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 555 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.573 || 0.295 seconds, mem : 9034\n",
      "\u001b[0m\u001b[41mEpisode 556 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.573 || 0.247 seconds, mem : 9062\n",
      "\u001b[0m\u001b[41mEpisode 557 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.572 || 0.260 seconds, mem : 9092\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 560/3023  18% ETA:  0:09:05 |\\\\\\\\\\\\\\                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 559 with 30 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.571 || 0.296 seconds, mem : 9136\n",
      "\u001b[0mEpisode 560 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.039 || Noise  0.570 || 0.195 seconds, mem : 9150\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 565/3023  18% ETA:  0:09:04 ||||||||                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 568 with 32 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.566 || 0.287 seconds, mem : 9281\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 570/3023  18% ETA:  0:09:02 |///////                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 571 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.564 || 0.256 seconds, mem : 9339\n",
      "\u001b[0m\u001b[44mEpisode 572 with 34 steps || Reward : [0.1  0.09] || avg reward :  0.039 || Noise  0.564 || 0.287 seconds, mem : 9373\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 575/3023  19% ETA:  0:09:02 |-------                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 575 with 31 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.562 || 0.265 seconds, mem : 9432\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 580/3023  19% ETA:  0:09:01 |\\\\\\\\\\\\\\                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 579 with 29 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.560 || 0.254 seconds, mem : 9504\n",
      "\u001b[0mEpisode 580 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.038 || Noise  0.559 || 0.191 seconds, mem : 9518\n",
      "\u001b[0m\u001b[41mEpisode 582 with 30 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.558 || 0.287 seconds, mem : 9562\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 590/3023  19% ETA:  0:08:58 |///////                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 589 with 30 steps || Reward : [0.   0.09] || avg reward :  0.037 || Noise  0.554 || 0.255 seconds, mem : 9682\n",
      "\u001b[0m\u001b[41mEpisode 590 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.554 || 0.271 seconds, mem : 9712\n",
      "\u001b[0m\u001b[41mEpisode 593 with 29 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.552 || 0.248 seconds, mem : 9770\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 595/3023  19% ETA:  0:08:57 |-------                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 594 with 33 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.551 || 0.268 seconds, mem : 9803\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 600/3023  19% ETA:  0:08:56 |\\\\\\\\\\\\\\                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.036 || Noise  0.548 || 0.249 seconds, mem : 9892\n",
      "\u001b[0m\u001b[41mEpisode 601 with 31 steps || Reward : [0.   0.09] || avg reward :  0.037 || Noise  0.548 || 0.260 seconds, mem : 9923\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 605/3023  20% ETA:  0:08:55 ||||||||                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 604 with 32 steps || Reward : [0.   0.09] || avg reward :  0.036 || Noise  0.546 || 0.278 seconds, mem : 9983\n",
      "\u001b[0m\u001b[41mEpisode 606 with 30 steps || Reward : [0.   0.09] || avg reward :  0.035 || Noise  0.545 || 0.263 seconds, mem : 10027\n",
      "\u001b[0m\u001b[41mEpisode 607 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.544 || 0.258 seconds, mem : 10058\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 610/3023  20% ETA:  0:08:55 |///////                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 609 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.543 || 0.283 seconds, mem : 10104\n",
      "\u001b[0m\u001b[41mEpisode 610 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.038 || Noise  0.543 || 0.289 seconds, mem : 10136\n",
      "\u001b[0m\u001b[41mEpisode 611 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.542 || 0.258 seconds, mem : 10167\n",
      "\u001b[0m\u001b[41mEpisode 612 with 41 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.542 || 0.356 seconds, mem : 10208\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 614/3023  20% ETA:  0:08:54 |-------                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 616 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.539 || 0.279 seconds, mem : 10281\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 619/3023  20% ETA:  0:08:54 |\\\\\\\\\\\\\\                                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 618 with 31 steps || Reward : [0.   0.09] || avg reward :  0.036 || Noise  0.538 || 0.265 seconds, mem : 10326\n",
      "\u001b[0m\u001b[41mEpisode 619 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.037 || Noise  0.538 || 0.266 seconds, mem : 10357\n",
      "\u001b[0mEpisode 620 with 13 steps || Reward : [-0.01  0.  ] || avg reward :  0.037 || Noise  0.537 || 0.215 seconds, mem : 10370\n",
      "\u001b[0m\u001b[41mEpisode 621 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.537 || 0.278 seconds, mem : 10402\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 624/3023  20% ETA:  0:08:53 |||||||||                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 623 with 30 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.536 || 0.251 seconds, mem : 10446\n",
      "\u001b[0m\u001b[41mEpisode 626 with 31 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.534 || 0.266 seconds, mem : 10505\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 629/3023  20% ETA:  0:08:52 |////////                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 629 with 32 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.532 || 0.301 seconds, mem : 10566\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 634/3023  20% ETA:  0:08:50 |--------                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 634 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.530 || 0.286 seconds, mem : 10656\n",
      "\u001b[0m\u001b[41mEpisode 635 with 30 steps || Reward : [0.   0.09] || avg reward :  0.037 || Noise  0.529 || 0.284 seconds, mem : 10686\n",
      "\u001b[0m\u001b[41mEpisode 636 with 29 steps || Reward : [-0.01  0.1 ] || avg reward :  0.038 || Noise  0.529 || 0.251 seconds, mem : 10715\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 638/3023  21% ETA:  0:08:50 |\\\\\\\\\\\\\\\\                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 637 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.528 || 0.283 seconds, mem : 10748\n",
      "\u001b[0m\u001b[41mEpisode 638 with 31 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.528 || 0.280 seconds, mem : 10779\n",
      "\u001b[0m\u001b[41mEpisode 640 with 41 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.527 || 0.286 seconds, mem : 10834\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 642/3023  21% ETA:  0:08:50 |||||||||                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 641 with 32 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.526 || 0.304 seconds, mem : 10866\n",
      "\u001b[0m\u001b[41mEpisode 642 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.040 || Noise  0.526 || 0.278 seconds, mem : 10898\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 646/3023  21% ETA:  0:08:50 |////////                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 645 with 42 steps || Reward : [-0.01  0.1 ] || avg reward :  0.041 || Noise  0.524 || 0.335 seconds, mem : 10968\n",
      "\u001b[0m\u001b[41mEpisode 646 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.042 || Noise  0.523 || 0.268 seconds, mem : 10998\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 651/3023  21% ETA:  0:08:48 |--------                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 651 with 29 steps || Reward : [-0.01  0.1 ] || avg reward :  0.040 || Noise  0.521 || 0.271 seconds, mem : 11083\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 656/3023  21% ETA:  0:08:47 |\\\\\\\\\\\\\\\\                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 655 with 31 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.519 || 0.267 seconds, mem : 11155\n",
      "\u001b[0m\u001b[41mEpisode 656 with 31 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.518 || 0.279 seconds, mem : 11186\n",
      "\u001b[0m\u001b[41mEpisode 657 with 43 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.518 || 0.303 seconds, mem : 11229\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 660/3023  21% ETA:  0:08:47 |||||||||                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 660 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.516 || 0.270 seconds, mem : 11289\n",
      "\u001b[0m\u001b[41mEpisode 662 with 32 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.515 || 0.284 seconds, mem : 11336\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 664/3023  21% ETA:  0:08:46 |////////                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 663 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.040 || Noise  0.515 || 0.268 seconds, mem : 11364\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 669/3023  22% ETA:  0:08:45 |--------                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 669 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.040 || Noise  0.512 || 0.286 seconds, mem : 11468\n",
      "\u001b[0m\u001b[41mEpisode 670 with 31 steps || Reward : [0.   0.09] || avg reward :  0.041 || Noise  0.511 || 0.266 seconds, mem : 11499\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 674/3023  22% ETA:  0:08:44 |\\\\\\\\\\\\\\\\                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 673 with 31 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.509 || 0.282 seconds, mem : 11558\n",
      "\u001b[0m\u001b[41mEpisode 677 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.040 || Noise  0.507 || 0.257 seconds, mem : 11639\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 679/3023  22% ETA:  0:08:43 |||||||||                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 679 with 32 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.506 || 0.282 seconds, mem : 11685\n",
      "\u001b[0mEpisode 680 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.040 || Noise  0.506 || 0.203 seconds, mem : 11699\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 683/3023  22% ETA:  0:08:43 |////////                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 681 with 31 steps || Reward : [0.   0.09] || avg reward :  0.041 || Noise  0.505 || 0.360 seconds, mem : 11730\n",
      "\u001b[0m\u001b[41mEpisode 684 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.504 || 0.313 seconds, mem : 11789\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 686/3023  22% ETA:  0:08:44 |--------                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 686 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.042 || Noise  0.503 || 0.377 seconds, mem : 11835\n",
      "\u001b[0m\u001b[41mEpisode 687 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.043 || Noise  0.502 || 0.298 seconds, mem : 11865\n",
      "\u001b[0m\u001b[41mEpisode 688 with 31 steps || Reward : [0.   0.09] || avg reward :  0.044 || Noise  0.502 || 0.285 seconds, mem : 11896\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 690/3023  22% ETA:  0:08:44 |\\\\\\\\\\\\\\\\                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 690 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.043 || Noise  0.501 || 0.266 seconds, mem : 11940\n",
      "\u001b[0m\u001b[41mEpisode 692 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.044 || Noise  0.500 || 0.268 seconds, mem : 11984\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 695/3023  22% ETA:  0:08:43 |||||||||                               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 694 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.043 || Noise  0.499 || 0.294 seconds, mem : 12031\n",
      "\u001b[0m\u001b[41mEpisode 695 with 31 steps || Reward : [0.   0.09] || avg reward :  0.044 || Noise  0.498 || 0.280 seconds, mem : 12062\n",
      "\u001b[0m\u001b[41mEpisode 696 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.045 || Noise  0.498 || 0.285 seconds, mem : 12092\n",
      "\u001b[0m\u001b[41mEpisode 697 with 33 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.497 || 0.310 seconds, mem : 12125\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 699/3023  23% ETA:  0:08:43 |/////////                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 699 with 30 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.496 || 0.266 seconds, mem : 12169\n",
      "\u001b[0m\u001b[41mEpisode 700 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.048 || Noise  0.496 || 0.285 seconds, mem : 12202\n",
      "\u001b[0m\u001b[41mEpisode 701 with 30 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.495 || 0.294 seconds, mem : 12232\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 703/3023  23% ETA:  0:08:42 |---------                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 703 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.049 || Noise  0.494 || 0.289 seconds, mem : 12279\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 708/3023  23% ETA:  0:08:42 |\\\\\\\\\\\\\\\\\\                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 707 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.047 || Noise  0.492 || 0.270 seconds, mem : 12356\n",
      "\u001b[0m\u001b[41mEpisode 708 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.048 || Noise  0.492 || 0.299 seconds, mem : 12388\n",
      "\u001b[0m\u001b[41mEpisode 709 with 29 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.491 || 0.295 seconds, mem : 12417\n",
      "\u001b[0m\u001b[41mEpisode 710 with 30 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.491 || 0.282 seconds, mem : 12447\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 712/3023  23% ETA:  0:08:41 ||||||||||                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 711 with 32 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.490 || 0.274 seconds, mem : 12479\n",
      "\u001b[0m\u001b[41mEpisode 714 with 32 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.489 || 0.272 seconds, mem : 12539\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 716/3023  23% ETA:  0:08:41 |/////////                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 715 with 31 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.489 || 0.281 seconds, mem : 12570\n",
      "\u001b[0m\u001b[41mEpisode 717 with 32 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.488 || 0.282 seconds, mem : 12616\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 721/3023  23% ETA:  0:08:40 |---------                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 720 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.046 || Noise  0.486 || 0.211 seconds, mem : 12658\n",
      "\u001b[0m\u001b[41mEpisode 721 with 31 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.486 || 0.290 seconds, mem : 12689\n",
      "\u001b[0m\u001b[41mEpisode 723 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.046 || Noise  0.485 || 0.295 seconds, mem : 12737\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 725/3023  23% ETA:  0:08:39 |\\\\\\\\\\\\\\\\\\                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 725 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.047 || Noise  0.484 || 0.289 seconds, mem : 12785\n",
      "\u001b[0m\u001b[41mEpisode 726 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.048 || Noise  0.483 || 0.287 seconds, mem : 12819\n",
      "\u001b[0m\u001b[41mEpisode 727 with 32 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.483 || 0.259 seconds, mem : 12851\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 729/3023  24% ETA:  0:08:39 ||||||||||                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 730 with 31 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.481 || 0.275 seconds, mem : 12910\n",
      "\u001b[0m\u001b[41mEpisode 732 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.049 || Noise  0.480 || 0.288 seconds, mem : 12956\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 734/3023  24% ETA:  0:08:38 |/////////                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 733 with 32 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.480 || 0.297 seconds, mem : 12988\n",
      "\u001b[0m\u001b[44mEpisode 737 with 43 steps || Reward : [0.1  0.09] || avg reward :  0.047 || Noise  0.478 || 0.322 seconds, mem : 13073\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 739/3023  24% ETA:  0:08:37 |---------                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 738 with 32 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.477 || 0.285 seconds, mem : 13105\n",
      "\u001b[0m\u001b[41mEpisode 740 with 32 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.476 || 0.310 seconds, mem : 13157\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 743/3023  24% ETA:  0:08:37 |\\\\\\\\\\\\\\\\\\                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 743 with 30 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.475 || 0.263 seconds, mem : 13234\n",
      "\u001b[0m\u001b[41mEpisode 744 with 32 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.475 || 0.341 seconds, mem : 13266\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 747/3023  24% ETA:  0:08:36 ||||||||||                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 749 with 30 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.472 || 0.258 seconds, mem : 13352\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 752/3023  24% ETA:  0:08:35 |/////////                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 751 with 29 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.471 || 0.242 seconds, mem : 13396\n",
      "\u001b[0m\u001b[41mEpisode 752 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.047 || Noise  0.471 || 0.327 seconds, mem : 13429\n",
      "\u001b[0m\u001b[41mEpisode 754 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.048 || Noise  0.470 || 0.297 seconds, mem : 13475\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 756/3023  25% ETA:  0:08:35 |---------                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 757 with 27 steps || Reward : [-0.01  0.1 ] || avg reward :  0.046 || Noise  0.468 || 0.249 seconds, mem : 13530\n",
      "\u001b[0m\u001b[41mEpisode 758 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.047 || Noise  0.468 || 0.298 seconds, mem : 13563\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 760/3023  25% ETA:  0:08:34 |\\\\\\\\\\\\\\\\\\                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 759 with 29 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.467 || 0.274 seconds, mem : 13592\n",
      "\u001b[0m\u001b[41mEpisode 760 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.048 || Noise  0.467 || 0.307 seconds, mem : 13623\n",
      "\u001b[0m\u001b[41mEpisode 761 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.049 || Noise  0.467 || 0.318 seconds, mem : 13657\n",
      "\u001b[0m\u001b[41mEpisode 762 with 31 steps || Reward : [0.   0.09] || avg reward :  0.049 || Noise  0.466 || 0.271 seconds, mem : 13688\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 764/3023  25% ETA:  0:08:34 ||||||||||                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 764 with 32 steps || Reward : [0.   0.09] || avg reward :  0.049 || Noise  0.465 || 0.289 seconds, mem : 13736\n",
      "\u001b[0m\u001b[41mEpisode 765 with 32 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.465 || 0.295 seconds, mem : 13768\n",
      "\u001b[0m\u001b[41mEpisode 766 with 30 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.464 || 0.264 seconds, mem : 13798\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 768/3023  25% ETA:  0:08:34 |/////////                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 767 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.464 || 0.292 seconds, mem : 13828\n",
      "\u001b[0m\u001b[41mEpisode 769 with 31 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.463 || 0.262 seconds, mem : 13879\n",
      "\u001b[0m\u001b[41mEpisode 770 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.462 || 0.276 seconds, mem : 13909\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 772/3023  25% ETA:  0:08:33 |---------                              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 771 with 30 steps || Reward : [0.   0.09] || avg reward :  0.053 || Noise  0.462 || 0.261 seconds, mem : 13939\n",
      "\u001b[0m\u001b[41mEpisode 773 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.461 || 0.262 seconds, mem : 13986\n",
      "\u001b[0m\u001b[41mEpisode 774 with 32 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.461 || 0.287 seconds, mem : 14018\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 777/3023  25% ETA:  0:08:33 |\\\\\\\\\\\\\\\\\\\\                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 776 with 31 steps || Reward : [0.   0.09] || avg reward :  0.055 || Noise  0.460 || 0.289 seconds, mem : 14063\n",
      "\u001b[0m\u001b[41mEpisode 778 with 31 steps || Reward : [0.   0.09] || avg reward :  0.055 || Noise  0.459 || 0.290 seconds, mem : 14108\n",
      "\u001b[0m\u001b[41mEpisode 780 with 31 steps || Reward : [0.   0.09] || avg reward :  0.055 || Noise  0.458 || 0.293 seconds, mem : 14153\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 782/3023  25% ETA:  0:08:32 |||||||||||                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 785 with 30 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.455 || 0.270 seconds, mem : 14240\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 787/3023  26% ETA:  0:08:31 |//////////                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 786 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.054 || Noise  0.455 || 0.300 seconds, mem : 14273\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 791/3023  26% ETA:  0:08:30 |----------                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 790 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.453 || 0.279 seconds, mem : 14346\n",
      "\u001b[0m\u001b[41mEpisode 793 with 33 steps || Reward : [ 0.1  -0.02] || avg reward :  0.052 || Noise  0.452 || 0.269 seconds, mem : 14408\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 795/3023  26% ETA:  0:08:30 |\\\\\\\\\\\\\\\\\\\\                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 796 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.450 || 0.252 seconds, mem : 14466\n",
      "\u001b[0m\u001b[41mEpisode 797 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.450 || 0.288 seconds, mem : 14496\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 799/3023  26% ETA:  0:08:30 |||||||||||                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 799 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.449 || 0.287 seconds, mem : 14540\n",
      "\u001b[0m\u001b[41mEpisode 800 with 30 steps || Reward : [0.   0.09] || avg reward :  0.049 || Noise  0.449 || 0.254 seconds, mem : 14570\n",
      "\u001b[0m\u001b[41mEpisode 801 with 33 steps || Reward : [ 0.1  -0.02] || avg reward :  0.050 || Noise  0.448 || 0.295 seconds, mem : 14603\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 803/3023  26% ETA:  0:08:29 |//////////                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 802 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.448 || 0.262 seconds, mem : 14633\n",
      "\u001b[0m\u001b[41mEpisode 803 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.050 || Noise  0.447 || 0.308 seconds, mem : 14666\n",
      "\u001b[0m\u001b[41mEpisode 804 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.051 || Noise  0.447 || 0.281 seconds, mem : 14700\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 808/3023  26% ETA:  0:08:28 |----------                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 809 with 31 steps || Reward : [0.   0.09] || avg reward :  0.049 || Noise  0.445 || 0.282 seconds, mem : 14796\n",
      "\u001b[0m\u001b[44mEpisode 810 with 35 steps || Reward : [0.1  0.09] || avg reward :  0.050 || Noise  0.444 || 0.282 seconds, mem : 14831\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 812/3023  26% ETA:  0:08:28 |\\\\\\\\\\\\\\\\\\\\                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 812 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.443 || 0.269 seconds, mem : 14875\n",
      "\u001b[0m\u001b[41mEpisode 813 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.051 || Noise  0.443 || 0.299 seconds, mem : 14908\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 816/3023  26% ETA:  0:08:27 |||||||||||                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 815 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.050 || Noise  0.442 || 0.292 seconds, mem : 14955\n",
      "\u001b[0m\u001b[41mEpisode 817 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.050 || Noise  0.441 || 0.297 seconds, mem : 15002\n",
      "\u001b[0m\u001b[41mEpisode 818 with 33 steps || Reward : [ 0.1  -0.02] || avg reward :  0.051 || Noise  0.441 || 0.292 seconds, mem : 15035\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 821/3023  27% ETA:  0:08:26 |//////////                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 820 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.051 || Noise  0.440 || 0.196 seconds, mem : 15063\n",
      "\u001b[0m\u001b[41mEpisode 821 with 32 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.439 || 0.298 seconds, mem : 15095\n",
      "\u001b[0m\u001b[41mEpisode 822 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.439 || 0.265 seconds, mem : 15125\n",
      "\u001b[0m\u001b[41mEpisode 823 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.052 || Noise  0.438 || 0.296 seconds, mem : 15158\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 825/3023  27% ETA:  0:08:26 |----------                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 824 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.438 || 0.278 seconds, mem : 15191\n",
      "\u001b[0m\u001b[41mEpisode 825 with 30 steps || Reward : [0.   0.09] || avg reward :  0.053 || Noise  0.438 || 0.287 seconds, mem : 15221\n",
      "\u001b[0m\u001b[41mEpisode 826 with 31 steps || Reward : [0.   0.09] || avg reward :  0.053 || Noise  0.437 || 0.275 seconds, mem : 15252\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 829/3023  27% ETA:  0:08:25 |\\\\\\\\\\\\\\\\\\\\                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 828 with 35 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.436 || 0.295 seconds, mem : 15301\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 834/3023  27% ETA:  0:08:24 |||||||||||                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 833 with 31 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.434 || 0.280 seconds, mem : 15408\n",
      "\u001b[0m\u001b[41mEpisode 834 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.434 || 0.281 seconds, mem : 15438\n",
      "\u001b[0m\u001b[41mEpisode 837 with 29 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.432 || 0.273 seconds, mem : 15496\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 839/3023  27% ETA:  0:08:23 |//////////                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 838 with 30 steps || Reward : [0.   0.09] || avg reward :  0.052 || Noise  0.432 || 0.269 seconds, mem : 15526\n",
      "\u001b[0m\u001b[44mEpisode 840 with 33 steps || Reward : [0.1  0.09] || avg reward :  0.052 || Noise  0.431 || 0.281 seconds, mem : 15573\n",
      "\u001b[0m\u001b[41mEpisode 841 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.431 || 0.274 seconds, mem : 15602\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 844/3023  27% ETA:  0:08:22 |----------                             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 846 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.052 || Noise  0.429 || 0.263 seconds, mem : 15691\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 853/3023  28% ETA:  0:08:20 ||||||||||||                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 852 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.050 || Noise  0.426 || 0.318 seconds, mem : 15795\n",
      "\u001b[0m\u001b[41mEpisode 853 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.051 || Noise  0.426 || 0.381 seconds, mem : 15827\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 857/3023  28% ETA:  0:08:20 |///////////                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 856 with 31 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.424 || 0.280 seconds, mem : 15889\n",
      "\u001b[0m\u001b[41mEpisode 857 with 29 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.424 || 0.283 seconds, mem : 15918\n",
      "\u001b[0m\u001b[44mEpisode 858 with 36 steps || Reward : [0.1  0.09] || avg reward :  0.051 || Noise  0.423 || 0.334 seconds, mem : 15954\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 861/3023  28% ETA:  0:08:20 |-----------                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 860 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.049 || Noise  0.423 || 0.274 seconds, mem : 15982\n",
      "\u001b[0m\u001b[41mEpisode 861 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.049 || Noise  0.422 || 0.338 seconds, mem : 16014\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 865/3023  28% ETA:  0:08:19 |\\\\\\\\\\\\\\\\\\\\\\                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 865 with 31 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.420 || 0.307 seconds, mem : 16089\n",
      "\u001b[0m\u001b[41mEpisode 866 with 30 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.420 || 0.357 seconds, mem : 16119\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 869/3023  28% ETA:  0:08:19 ||||||||||||                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 869 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.046 || Noise  0.419 || 0.323 seconds, mem : 16199\n",
      "\u001b[0m\u001b[41mEpisode 870 with 30 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.418 || 0.342 seconds, mem : 16229\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 873/3023  28% ETA:  0:08:19 |///////////                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 873 with 31 steps || Reward : [0.   0.09] || avg reward :  0.045 || Noise  0.417 || 0.368 seconds, mem : 16288\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 877/3023  29% ETA:  0:08:18 |-----------                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 876 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.045 || Noise  0.416 || 0.292 seconds, mem : 16355\n",
      "\u001b[0m\u001b[41mEpisode 877 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.046 || Noise  0.415 || 0.312 seconds, mem : 16384\n",
      "\u001b[0m\u001b[41mEpisode 879 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.046 || Noise  0.415 || 0.299 seconds, mem : 16431\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 881/3023  29% ETA:  0:08:18 |\\\\\\\\\\\\\\\\\\\\\\                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 880 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.045 || Noise  0.414 || 0.247 seconds, mem : 16445\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 886/3023  29% ETA:  0:08:17 ||||||||||||                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 888 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.044 || Noise  0.411 || 0.300 seconds, mem : 16577\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 891/3023  29% ETA:  0:08:16 |///////////                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 891 with 33 steps || Reward : [ 0.1  -0.02] || avg reward :  0.044 || Noise  0.410 || 0.297 seconds, mem : 16638\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 895/3023  29% ETA:  0:08:15 |-----------                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 894 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.044 || Noise  0.408 || 0.260 seconds, mem : 16695\n",
      "\u001b[0m\u001b[41mEpisode 898 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.043 || Noise  0.407 || 0.292 seconds, mem : 16770\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 900/3023  29% ETA:  0:08:14 |\\\\\\\\\\\\\\\\\\\\\\                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 900 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.042 || Noise  0.406 || 0.289 seconds, mem : 16815\n",
      "\u001b[0m\u001b[41mEpisode 902 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.405 || 0.288 seconds, mem : 16861\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 904/3023  29% ETA:  0:08:13 ||||||||||||                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 904 with 29 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.404 || 0.281 seconds, mem : 16904\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 908/3023  30% ETA:  0:08:13 |///////////                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 907 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.403 || 0.286 seconds, mem : 16969\n",
      "\u001b[0m\u001b[41mEpisode 910 with 32 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.402 || 0.296 seconds, mem : 17032\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 912/3023  30% ETA:  0:08:12 |-----------                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 911 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.402 || 0.298 seconds, mem : 17066\n",
      "\u001b[0m\u001b[41mEpisode 912 with 30 steps || Reward : [0.   0.09] || avg reward :  0.041 || Noise  0.401 || 0.345 seconds, mem : 17096\n",
      "\u001b[0m\u001b[41mEpisode 913 with 32 steps || Reward : [0.   0.09] || avg reward :  0.041 || Noise  0.401 || 0.288 seconds, mem : 17128\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 916/3023  30% ETA:  0:08:11 |\\\\\\\\\\\\\\\\\\\\\\                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 916 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.400 || 0.323 seconds, mem : 17188\n",
      "\u001b[0m\u001b[41mEpisode 917 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.399 || 0.314 seconds, mem : 17221\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 920/3023  30% ETA:  0:08:11 ||||||||||||                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 920 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.041 || Noise  0.398 || 0.320 seconds, mem : 17285\n",
      "\u001b[0m\u001b[41mEpisode 922 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.040 || Noise  0.397 || 0.282 seconds, mem : 17331\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 929/3023  30% ETA:  0:08:09 |-----------                            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 929 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.037 || Noise  0.394 || 0.291 seconds, mem : 17449\n",
      "\u001b[0m\u001b[41mEpisode 931 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.394 || 0.294 seconds, mem : 17494\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 933/3023  30% ETA:  0:08:08 |\\\\\\\\\\\\\\\\\\\\\\\\                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 933 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.393 || 0.297 seconds, mem : 17541\n",
      "\u001b[0m\u001b[41mEpisode 934 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.038 || Noise  0.392 || 0.287 seconds, mem : 17572\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 937/3023  30% ETA:  0:08:08 |||||||||||||                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 936 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.392 || 0.290 seconds, mem : 17616\n",
      "\u001b[0mEpisode 940 with 24 steps || Reward : [ 0.   -0.01] || avg reward :  0.036 || Noise  0.390 || 0.261 seconds, mem : 17683\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 942/3023  31% ETA:  0:08:07 |////////////                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 941 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.390 || 0.314 seconds, mem : 17716\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 947/3023  31% ETA:  0:08:05 |------------                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 948 with 29 steps || Reward : [0.   0.09] || avg reward :  0.036 || Noise  0.387 || 0.310 seconds, mem : 17834\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 952/3023  31% ETA:  0:08:04 |\\\\\\\\\\\\\\\\\\\\\\\\                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 952 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.385 || 0.327 seconds, mem : 17911\n",
      "\u001b[0m\u001b[41mEpisode 954 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.385 || 0.290 seconds, mem : 17960\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 956/3023  31% ETA:  0:08:04 |||||||||||||                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 956 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.036 || Noise  0.384 || 0.317 seconds, mem : 18003\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 960/3023  31% ETA:  0:08:03 |////////////                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 960 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.034 || Noise  0.382 || 0.266 seconds, mem : 18066\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 964/3023  31% ETA:  0:08:02 |------------                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 963 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.034 || Noise  0.381 || 0.305 seconds, mem : 18145\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 969/3023  32% ETA:  0:08:01 |\\\\\\\\\\\\\\\\\\\\\\\\                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 970 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.031 || Noise  0.379 || 0.295 seconds, mem : 18265\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 979/3023  32% ETA:  0:07:59 |////////////                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 980 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.028 || Noise  0.375 || 0.208 seconds, mem : 18409\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 994/3023  32% ETA:  0:07:55 |||||||||||||                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 994 with 29 steps || Reward : [0.   0.09] || avg reward :  0.025 || Noise  0.370 || 0.323 seconds, mem : 18623\n",
      "\u001b[0m\u001b[41mEpisode 995 with 30 steps || Reward : [0.   0.09] || avg reward :  0.026 || Noise  0.369 || 0.354 seconds, mem : 18653\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 998/3023  33% ETA:  0:07:54 |////////////                           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 998 with 29 steps || Reward : [0.   0.09] || avg reward :  0.026 || Noise  0.368 || 0.319 seconds, mem : 18710\n",
      "\u001b[0mEpisode 1000 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.025 || Noise  0.367 || 0.219 seconds, mem : 18739\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1007/3023  33% ETA:  0:07:52 |\\\\\\\\\\\\\\\\\\\\\\\\                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1006 with 30 steps || Reward : [0.   0.09] || avg reward :  0.024 || Noise  0.365 || 0.313 seconds, mem : 18841\n",
      "\u001b[0m\u001b[41mEpisode 1008 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.024 || Noise  0.364 || 0.286 seconds, mem : 18889\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1016/3023  33% ETA:  0:07:50 |////////////                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1015 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.022 || Noise  0.362 || 0.310 seconds, mem : 19006\n",
      "\u001b[0m\u001b[41mEpisode 1016 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.022 || Noise  0.361 || 0.306 seconds, mem : 19038\n",
      "\u001b[0m\u001b[41mEpisode 1017 with 30 steps || Reward : [0.   0.09] || avg reward :  0.021 || Noise  0.361 || 0.290 seconds, mem : 19068\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1020/3023  33% ETA:  0:07:50 |------------                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1020 with 30 steps || Reward : [0.   0.09] || avg reward :  0.021 || Noise  0.360 || 0.283 seconds, mem : 19127\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1024/3023  33% ETA:  0:07:49 |\\\\\\\\\\\\\\\\\\\\\\\\                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1023 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.021 || Noise  0.359 || 0.302 seconds, mem : 19188\n",
      "\u001b[0m\u001b[41mEpisode 1025 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.022 || Noise  0.358 || 0.316 seconds, mem : 19235\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1028/3023  34% ETA:  0:07:48 |||||||||||||                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1031 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.021 || Noise  0.356 || 0.300 seconds, mem : 19337\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1033/3023  34% ETA:  0:07:47 |////////////                          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1036 with 30 steps || Reward : [0.   0.09] || avg reward :  0.019 || Noise  0.354 || 0.292 seconds, mem : 19424\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1038/3023  34% ETA:  0:07:46 |-------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1038 with 44 steps || Reward : [0.   0.19] || avg reward :  0.021 || Noise  0.354 || 0.385 seconds, mem : 19482\n",
      "\u001b[0mEpisode 1040 with 14 steps || Reward : [ 0.   -0.01] || avg reward :  0.021 || Noise  0.353 || 0.208 seconds, mem : 19510\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1047/3023  34% ETA:  0:07:44 ||||||||||||||                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1049 with 29 steps || Reward : [0.   0.09] || avg reward :  0.020 || Noise  0.350 || 0.267 seconds, mem : 19653\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1052/3023  34% ETA:  0:07:43 |/////////////                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1052 with 30 steps || Reward : [0.   0.09] || avg reward :  0.020 || Noise  0.349 || 0.307 seconds, mem : 19715\n",
      "\u001b[0m\u001b[41mEpisode 1053 with 30 steps || Reward : [0.   0.09] || avg reward :  0.021 || Noise  0.348 || 0.285 seconds, mem : 19745\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1056/3023  34% ETA:  0:07:42 |-------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1056 with 29 steps || Reward : [0.   0.09] || avg reward :  0.020 || Noise  0.347 || 0.307 seconds, mem : 19803\n",
      "\u001b[0m\u001b[41mEpisode 1058 with 30 steps || Reward : [0.   0.09] || avg reward :  0.021 || Noise  0.347 || 0.336 seconds, mem : 19848\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1060/3023  35% ETA:  0:07:41 |\\\\\\\\\\\\\\\\\\\\\\\\\\                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1060 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.021 || Noise  0.346 || 0.219 seconds, mem : 19876\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1065/3023  35% ETA:  0:07:40 ||||||||||||||                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1064 with 30 steps || Reward : [0.   0.09] || avg reward :  0.021 || Noise  0.345 || 0.296 seconds, mem : 19949\n",
      "\u001b[0m\u001b[41mEpisode 1065 with 30 steps || Reward : [0.   0.09] || avg reward :  0.022 || Noise  0.344 || 0.300 seconds, mem : 19979\n",
      "\u001b[0m\u001b[41mEpisode 1066 with 31 steps || Reward : [0.   0.09] || avg reward :  0.022 || Noise  0.344 || 0.310 seconds, mem : 20010\n",
      "\u001b[0m\u001b[41mEpisode 1067 with 30 steps || Reward : [0.   0.09] || avg reward :  0.023 || Noise  0.344 || 0.287 seconds, mem : 20040\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1069/3023  35% ETA:  0:07:40 |/////////////                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1070 with 30 steps || Reward : [0.   0.09] || avg reward :  0.023 || Noise  0.342 || 0.314 seconds, mem : 20099\n",
      "\u001b[0m\u001b[41mEpisode 1071 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.024 || Noise  0.342 || 0.299 seconds, mem : 20130\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1073/3023  35% ETA:  0:07:39 |-------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1072 with 31 steps || Reward : [0.   0.09] || avg reward :  0.025 || Noise  0.342 || 0.296 seconds, mem : 20161\n",
      "\u001b[0m\u001b[41mEpisode 1073 with 29 steps || Reward : [0.   0.09] || avg reward :  0.026 || Noise  0.341 || 0.303 seconds, mem : 20190\n",
      "\u001b[0m\u001b[41mEpisode 1074 with 30 steps || Reward : [0.   0.09] || avg reward :  0.027 || Noise  0.341 || 0.325 seconds, mem : 20220\n",
      "\u001b[0m\u001b[41mEpisode 1075 with 30 steps || Reward : [0.   0.09] || avg reward :  0.028 || Noise  0.341 || 0.285 seconds, mem : 20250\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1077/3023  35% ETA:  0:07:39 |\\\\\\\\\\\\\\\\\\\\\\\\\\                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1076 with 31 steps || Reward : [0.   0.09] || avg reward :  0.029 || Noise  0.340 || 0.332 seconds, mem : 20281\n",
      "\u001b[0m\u001b[41mEpisode 1078 with 29 steps || Reward : [0.   0.09] || avg reward :  0.030 || Noise  0.340 || 0.273 seconds, mem : 20326\n",
      "\u001b[0m\u001b[41mEpisode 1079 with 29 steps || Reward : [0.   0.09] || avg reward :  0.031 || Noise  0.339 || 0.301 seconds, mem : 20355\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1081/3023  35% ETA:  0:07:38 ||||||||||||||                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1080 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.032 || Noise  0.339 || 0.313 seconds, mem : 20386\n",
      "\u001b[0m\u001b[41mEpisode 1081 with 31 steps || Reward : [0.   0.09] || avg reward :  0.032 || Noise  0.339 || 0.313 seconds, mem : 20417\n",
      "\u001b[0m\u001b[41mEpisode 1082 with 30 steps || Reward : [0.   0.09] || avg reward :  0.033 || Noise  0.338 || 0.288 seconds, mem : 20447\n",
      "\u001b[0m\u001b[41mEpisode 1083 with 30 steps || Reward : [0.   0.09] || avg reward :  0.034 || Noise  0.338 || 0.299 seconds, mem : 20477\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1085/3023  35% ETA:  0:07:38 |/////////////                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1085 with 30 steps || Reward : [0.   0.09] || avg reward :  0.035 || Noise  0.337 || 0.285 seconds, mem : 20521\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1089/3023  36% ETA:  0:07:37 |-------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1088 with 30 steps || Reward : [0.   0.09] || avg reward :  0.036 || Noise  0.336 || 0.298 seconds, mem : 20583\n",
      "\u001b[0m\u001b[41mEpisode 1089 with 31 steps || Reward : [0.   0.09] || avg reward :  0.037 || Noise  0.336 || 0.289 seconds, mem : 20614\n",
      "\u001b[0m\u001b[41mEpisode 1090 with 31 steps || Reward : [0.   0.09] || avg reward :  0.038 || Noise  0.336 || 0.319 seconds, mem : 20645\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1093/3023  36% ETA:  0:07:36 |\\\\\\\\\\\\\\\\\\\\\\\\\\                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1093 with 31 steps || Reward : [0.   0.09] || avg reward :  0.039 || Noise  0.335 || 0.290 seconds, mem : 20704\n",
      "\u001b[0m\u001b[41mEpisode 1094 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.334 || 0.310 seconds, mem : 20734\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1097/3023  36% ETA:  0:07:35 ||||||||||||||                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1096 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.039 || Noise  0.334 || 0.285 seconds, mem : 20780\n",
      "\u001b[0m\u001b[41mEpisode 1097 with 30 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.333 || 0.341 seconds, mem : 20810\n",
      "\u001b[0m\u001b[41mEpisode 1099 with 30 steps || Reward : [0.   0.09] || avg reward :  0.040 || Noise  0.333 || 0.302 seconds, mem : 20855\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1101/3023  36% ETA:  0:07:35 |/////////////                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1100 with 31 steps || Reward : [0.   0.09] || avg reward :  0.041 || Noise  0.332 || 0.289 seconds, mem : 20886\n",
      "\u001b[0m\u001b[41mEpisode 1101 with 30 steps || Reward : [0.   0.09] || avg reward :  0.042 || Noise  0.332 || 0.322 seconds, mem : 20916\n",
      "\u001b[0m\u001b[41mEpisode 1102 with 32 steps || Reward : [0.   0.09] || avg reward :  0.043 || Noise  0.332 || 0.362 seconds, mem : 20948\n",
      "\u001b[0m\u001b[41mEpisode 1103 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.044 || Noise  0.331 || 0.288 seconds, mem : 20980\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1105/3023  36% ETA:  0:07:35 |-------------                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1104 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.045 || Noise  0.331 || 0.328 seconds, mem : 21013\n",
      "\u001b[0m\u001b[41mEpisode 1105 with 30 steps || Reward : [0.   0.09] || avg reward :  0.045 || Noise  0.331 || 0.320 seconds, mem : 21043\n",
      "\u001b[0m\u001b[41mEpisode 1106 with 29 steps || Reward : [0.   0.09] || avg reward :  0.045 || Noise  0.330 || 0.277 seconds, mem : 21072\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1109/3023  36% ETA:  0:07:34 |\\\\\\\\\\\\\\\\\\\\\\\\\\                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1109 with 31 steps || Reward : [0.   0.09] || avg reward :  0.045 || Noise  0.329 || 0.303 seconds, mem : 21131\n",
      "\u001b[0m\u001b[41mEpisode 1110 with 31 steps || Reward : [0.   0.09] || avg reward :  0.046 || Noise  0.329 || 0.286 seconds, mem : 21162\n",
      "\u001b[0m\u001b[41mEpisode 1111 with 31 steps || Reward : [0.   0.09] || avg reward :  0.047 || Noise  0.329 || 0.327 seconds, mem : 21193\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1113/3023  36% ETA:  0:07:33 ||||||||||||||                         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1112 with 30 steps || Reward : [0.   0.09] || avg reward :  0.048 || Noise  0.328 || 0.304 seconds, mem : 21223\n",
      "\u001b[0m\u001b[41mEpisode 1113 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.049 || Noise  0.328 || 0.308 seconds, mem : 21255\n",
      "\u001b[0m\u001b[41mEpisode 1114 with 31 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.328 || 0.335 seconds, mem : 21286\n",
      "\u001b[0m\u001b[41mEpisode 1115 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.327 || 0.316 seconds, mem : 21316\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1117/3023  36% ETA:  0:07:33 |//////////////                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1117 with 31 steps || Reward : [0.   0.09] || avg reward :  0.049 || Noise  0.327 || 0.294 seconds, mem : 21362\n",
      "\u001b[0m\u001b[41mEpisode 1118 with 30 steps || Reward : [0.   0.09] || avg reward :  0.050 || Noise  0.326 || 0.299 seconds, mem : 21392\n",
      "\u001b[0m\u001b[41mEpisode 1119 with 31 steps || Reward : [0.   0.09] || avg reward :  0.051 || Noise  0.326 || 0.313 seconds, mem : 21423\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1121/3023  37% ETA:  0:07:32 |--------------                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1120 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.051 || Noise  0.326 || 0.333 seconds, mem : 21455\n",
      "\u001b[0m\u001b[41mEpisode 1121 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.052 || Noise  0.325 || 0.328 seconds, mem : 21487\n",
      "\u001b[0m\u001b[41mEpisode 1122 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.325 || 0.312 seconds, mem : 21518\n",
      "\u001b[0m\u001b[41mEpisode 1123 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.053 || Noise  0.325 || 0.298 seconds, mem : 21550\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1125/3023  37% ETA:  0:07:32 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1124 with 31 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.324 || 0.316 seconds, mem : 21581\n",
      "\u001b[0m\u001b[41mEpisode 1125 with 32 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.324 || 0.334 seconds, mem : 21613\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1130/3023  37% ETA:  0:07:31 |||||||||||||||                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1130 with 32 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.323 || 0.309 seconds, mem : 21701\n",
      "\u001b[0m\u001b[41mEpisode 1132 with 31 steps || Reward : [0.   0.09] || avg reward :  0.054 || Noise  0.322 || 0.300 seconds, mem : 21750\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1134/3023  37% ETA:  0:07:30 |//////////////                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1133 with 30 steps || Reward : [0.   0.09] || avg reward :  0.055 || Noise  0.322 || 0.317 seconds, mem : 21780\n",
      "\u001b[0m\u001b[41mEpisode 1134 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.056 || Noise  0.321 || 0.300 seconds, mem : 21810\n",
      "\u001b[0m\u001b[41mEpisode 1135 with 30 steps || Reward : [0.   0.09] || avg reward :  0.057 || Noise  0.321 || 0.316 seconds, mem : 21840\n",
      "\u001b[0m\u001b[41mEpisode 1136 with 32 steps || Reward : [0.   0.09] || avg reward :  0.057 || Noise  0.321 || 0.314 seconds, mem : 21872\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1138/3023  37% ETA:  0:07:30 |--------------                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1137 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.058 || Noise  0.320 || 0.293 seconds, mem : 21903\n",
      "\u001b[0m\u001b[41mEpisode 1138 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.057 || Noise  0.320 || 0.337 seconds, mem : 21934\n",
      "\u001b[0m\u001b[41mEpisode 1139 with 31 steps || Reward : [0.   0.09] || avg reward :  0.058 || Noise  0.320 || 0.309 seconds, mem : 21965\n",
      "\u001b[0m\u001b[41mEpisode 1140 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.059 || Noise  0.319 || 0.289 seconds, mem : 21995\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1142/3023  37% ETA:  0:07:29 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1141 with 31 steps || Reward : [0.   0.09] || avg reward :  0.060 || Noise  0.319 || 0.313 seconds, mem : 22026\n",
      "\u001b[0m\u001b[41mEpisode 1142 with 30 steps || Reward : [0.   0.09] || avg reward :  0.061 || Noise  0.319 || 0.295 seconds, mem : 22056\n",
      "\u001b[0m\u001b[41mEpisode 1143 with 31 steps || Reward : [0.   0.09] || avg reward :  0.062 || Noise  0.318 || 0.299 seconds, mem : 22087\n",
      "\u001b[0m\u001b[41mEpisode 1144 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.063 || Noise  0.318 || 0.281 seconds, mem : 22119\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1146/3023  37% ETA:  0:07:29 |||||||||||||||                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1145 with 30 steps || Reward : [0.   0.09] || avg reward :  0.064 || Noise  0.318 || 0.314 seconds, mem : 22149\n",
      "\u001b[0m\u001b[41mEpisode 1147 with 29 steps || Reward : [0.   0.09] || avg reward :  0.065 || Noise  0.317 || 0.274 seconds, mem : 22196\n",
      "\u001b[0m\u001b[41mEpisode 1148 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.066 || Noise  0.317 || 0.339 seconds, mem : 22226\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1150/3023  38% ETA:  0:07:28 |//////////////                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1149 with 30 steps || Reward : [0.   0.09] || avg reward :  0.066 || Noise  0.316 || 0.289 seconds, mem : 22256\n",
      "\u001b[0m\u001b[41mEpisode 1151 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.067 || Noise  0.316 || 0.278 seconds, mem : 22303\n",
      "\u001b[0m\u001b[41mEpisode 1152 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.067 || Noise  0.316 || 0.305 seconds, mem : 22334\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1154/3023  38% ETA:  0:07:27 |--------------                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1153 with 30 steps || Reward : [0.   0.09] || avg reward :  0.067 || Noise  0.315 || 0.310 seconds, mem : 22364\n",
      "\u001b[0m\u001b[41mEpisode 1154 with 30 steps || Reward : [0.   0.09] || avg reward :  0.068 || Noise  0.315 || 0.285 seconds, mem : 22394\n",
      "\u001b[0m\u001b[41mEpisode 1155 with 31 steps || Reward : [0.   0.09] || avg reward :  0.069 || Noise  0.315 || 0.317 seconds, mem : 22425\n",
      "\u001b[0m\u001b[41mEpisode 1156 with 31 steps || Reward : [0.   0.09] || avg reward :  0.069 || Noise  0.314 || 0.299 seconds, mem : 22456\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1158/3023  38% ETA:  0:07:27 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1157 with 32 steps || Reward : [0.   0.09] || avg reward :  0.069 || Noise  0.314 || 0.299 seconds, mem : 22488\n",
      "\u001b[0m\u001b[41mEpisode 1158 with 31 steps || Reward : [0.   0.09] || avg reward :  0.069 || Noise  0.314 || 0.328 seconds, mem : 22519\n",
      "\u001b[0m\u001b[41mEpisode 1159 with 31 steps || Reward : [0.   0.09] || avg reward :  0.070 || Noise  0.313 || 0.292 seconds, mem : 22550\n",
      "\u001b[0m\u001b[41mEpisode 1160 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.071 || Noise  0.313 || 0.353 seconds, mem : 22582\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1162/3023  38% ETA:  0:07:26 |||||||||||||||                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1161 with 31 steps || Reward : [0.   0.09] || avg reward :  0.072 || Noise  0.313 || 0.317 seconds, mem : 22613\n",
      "\u001b[0m\u001b[41mEpisode 1162 with 30 steps || Reward : [0.   0.09] || avg reward :  0.073 || Noise  0.312 || 0.303 seconds, mem : 22643\n",
      "\u001b[0m\u001b[41mEpisode 1163 with 32 steps || Reward : [0.   0.09] || avg reward :  0.074 || Noise  0.312 || 0.327 seconds, mem : 22675\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1166/3023  38% ETA:  0:07:26 |//////////////                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1165 with 31 steps || Reward : [0.   0.09] || avg reward :  0.073 || Noise  0.311 || 0.310 seconds, mem : 22720\n",
      "\u001b[0m\u001b[41mEpisode 1167 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.072 || Noise  0.311 || 0.285 seconds, mem : 22765\n",
      "\u001b[0m\u001b[41mEpisode 1168 with 31 steps || Reward : [0.   0.09] || avg reward :  0.073 || Noise  0.310 || 0.323 seconds, mem : 22796\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1170/3023  38% ETA:  0:07:25 |--------------                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1169 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.074 || Noise  0.310 || 0.294 seconds, mem : 22827\n",
      "\u001b[0m\u001b[41mEpisode 1170 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.074 || Noise  0.310 || 0.317 seconds, mem : 22857\n",
      "\u001b[0m\u001b[41mEpisode 1171 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.074 || Noise  0.310 || 0.289 seconds, mem : 22887\n",
      "\u001b[0m\u001b[41mEpisode 1172 with 32 steps || Reward : [0.   0.09] || avg reward :  0.074 || Noise  0.309 || 0.319 seconds, mem : 22919\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1174/3023  38% ETA:  0:07:25 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1173 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.074 || Noise  0.309 || 0.297 seconds, mem : 22948\n",
      "\u001b[0m\u001b[41mEpisode 1174 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.075 || Noise  0.309 || 0.297 seconds, mem : 22978\n",
      "\u001b[0m\u001b[41mEpisode 1175 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.075 || Noise  0.308 || 0.307 seconds, mem : 23009\n",
      "\u001b[0m\u001b[41mEpisode 1176 with 31 steps || Reward : [0.   0.09] || avg reward :  0.075 || Noise  0.308 || 0.303 seconds, mem : 23040\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1178/3023  38% ETA:  0:07:24 |||||||||||||||                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1177 with 31 steps || Reward : [0.   0.09] || avg reward :  0.076 || Noise  0.308 || 0.313 seconds, mem : 23071\n",
      "\u001b[0m\u001b[41mEpisode 1178 with 32 steps || Reward : [0.   0.09] || avg reward :  0.076 || Noise  0.307 || 0.347 seconds, mem : 23103\n",
      "\u001b[0m\u001b[41mEpisode 1179 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.076 || Noise  0.307 || 0.321 seconds, mem : 23133\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1181/3023  39% ETA:  0:07:24 |//////////////                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1180 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.076 || Noise  0.307 || 0.330 seconds, mem : 23164\n",
      "\u001b[0m\u001b[41mEpisode 1181 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.076 || Noise  0.306 || 0.381 seconds, mem : 23194\n",
      "\u001b[0m\u001b[41mEpisode 1182 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.076 || Noise  0.306 || 0.339 seconds, mem : 23225\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1184/3023  39% ETA:  0:07:24 |--------------                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1183 with 31 steps || Reward : [0.   0.09] || avg reward :  0.076 || Noise  0.306 || 0.355 seconds, mem : 23256\n",
      "\u001b[0m\u001b[41mEpisode 1184 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.077 || Noise  0.306 || 0.402 seconds, mem : 23287\n",
      "\u001b[0m\u001b[41mEpisode 1185 with 31 steps || Reward : [0.   0.09] || avg reward :  0.077 || Noise  0.305 || 0.360 seconds, mem : 23318\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1188/3023  39% ETA:  0:07:23 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1187 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.078 || Noise  0.305 || 0.327 seconds, mem : 23363\n",
      "\u001b[0m\u001b[41mEpisode 1188 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.078 || Noise  0.304 || 0.325 seconds, mem : 23394\n",
      "\u001b[0m\u001b[41mEpisode 1189 with 30 steps || Reward : [0.   0.09] || avg reward :  0.078 || Noise  0.304 || 0.316 seconds, mem : 23424\n",
      "\u001b[0m\u001b[41mEpisode 1190 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.078 || Noise  0.304 || 0.323 seconds, mem : 23454\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1192/3023  39% ETA:  0:07:23 |||||||||||||||                        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1191 with 30 steps || Reward : [0.   0.09] || avg reward :  0.079 || Noise  0.303 || 0.321 seconds, mem : 23484\n",
      "\u001b[0m\u001b[41mEpisode 1192 with 30 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.303 || 0.326 seconds, mem : 23514\n",
      "\u001b[0m\u001b[41mEpisode 1193 with 32 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.303 || 0.344 seconds, mem : 23546\n",
      "\u001b[0m\u001b[41mEpisode 1194 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.080 || Noise  0.303 || 0.320 seconds, mem : 23577\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1196/3023  39% ETA:  0:07:22 |///////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1195 with 30 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.302 || 0.313 seconds, mem : 23607\n",
      "\u001b[0m\u001b[41mEpisode 1196 with 50 steps || Reward : [-0.01  0.1 ] || avg reward :  0.081 || Noise  0.302 || 0.446 seconds, mem : 23657\n",
      "\u001b[0m\u001b[41mEpisode 1197 with 29 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.302 || 0.317 seconds, mem : 23686\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1199/3023  39% ETA:  0:07:22 |---------------                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1199 with 30 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.301 || 0.321 seconds, mem : 23730\n",
      "\u001b[0m\u001b[41mEpisode 1200 with 30 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.301 || 0.197 seconds, mem : 23760\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1204/3023  39% ETA:  0:07:21 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1204 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.078 || Noise  0.300 || 0.264 seconds, mem : 23833\n",
      "\u001b[0m\u001b[41mEpisode 1205 with 30 steps || Reward : [0.   0.09] || avg reward :  0.078 || Noise  0.299 || 0.302 seconds, mem : 23863\n",
      "\u001b[0m\u001b[41mEpisode 1206 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.078 || Noise  0.299 || 0.314 seconds, mem : 23893\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1208/3023  39% ETA:  0:07:20 ||||||||||||||||                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1207 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.079 || Noise  0.299 || 0.360 seconds, mem : 23925\n",
      "\u001b[0m\u001b[44mEpisode 1208 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.080 || Noise  0.298 || 0.487 seconds, mem : 23990\n",
      "\u001b[0m\u001b[41mEpisode 1209 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.080 || Noise  0.298 || 0.306 seconds, mem : 24020\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1211/3023  40% ETA:  0:07:20 |///////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1210 with 31 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.298 || 0.311 seconds, mem : 24051\n",
      "\u001b[0m\u001b[41mEpisode 1211 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.080 || Noise  0.297 || 0.336 seconds, mem : 24083\n",
      "\u001b[0m\u001b[41mEpisode 1212 with 30 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.297 || 0.287 seconds, mem : 24113\n",
      "\u001b[0m\u001b[41mEpisode 1213 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.080 || Noise  0.297 || 0.341 seconds, mem : 24145\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1215/3023  40% ETA:  0:07:19 |---------------                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1214 with 30 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.297 || 0.324 seconds, mem : 24175\n",
      "\u001b[0m\u001b[41mEpisode 1215 with 30 steps || Reward : [0.   0.09] || avg reward :  0.080 || Noise  0.296 || 0.321 seconds, mem : 24205\n",
      "\u001b[0m\u001b[41mEpisode 1216 with 30 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.296 || 0.323 seconds, mem : 24235\n",
      "\u001b[0m\u001b[41mEpisode 1217 with 31 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.296 || 0.329 seconds, mem : 24266\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1219/3023  40% ETA:  0:07:19 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1218 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.081 || Noise  0.295 || 0.311 seconds, mem : 24296\n",
      "\u001b[0m\u001b[41mEpisode 1219 with 31 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.295 || 0.342 seconds, mem : 24327\n",
      "\u001b[0m\u001b[41mEpisode 1220 with 31 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.295 || 0.310 seconds, mem : 24358\n",
      "\u001b[0m\u001b[41mEpisode 1221 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.081 || Noise  0.294 || 0.317 seconds, mem : 24389\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1223/3023  40% ETA:  0:07:18 ||||||||||||||||                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1222 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.081 || Noise  0.294 || 0.335 seconds, mem : 24420\n",
      "\u001b[0m\u001b[41mEpisode 1223 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.081 || Noise  0.294 || 0.326 seconds, mem : 24450\n",
      "\u001b[0m\u001b[44mEpisode 1224 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.081 || Noise  0.294 || 0.553 seconds, mem : 24515\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1226/3023  40% ETA:  0:07:18 |///////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1225 with 31 steps || Reward : [0.   0.09] || avg reward :  0.081 || Noise  0.293 || 0.384 seconds, mem : 24546\n",
      "\u001b[0m\u001b[41mEpisode 1226 with 30 steps || Reward : [0.   0.09] || avg reward :  0.082 || Noise  0.293 || 0.326 seconds, mem : 24576\n",
      "\u001b[0m\u001b[41mEpisode 1227 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.083 || Noise  0.293 || 0.339 seconds, mem : 24607\n",
      "\u001b[0m\u001b[41mEpisode 1228 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.084 || Noise  0.292 || 0.325 seconds, mem : 24638\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1230/3023  40% ETA:  0:07:18 |---------------                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1229 with 27 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.292 || 0.272 seconds, mem : 24665\n",
      "\u001b[0m\u001b[41mEpisode 1230 with 30 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.292 || 0.317 seconds, mem : 24695\n",
      "\u001b[0m\u001b[41mEpisode 1231 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.292 || 0.306 seconds, mem : 24727\n",
      "\u001b[0m\u001b[41mEpisode 1232 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.291 || 0.307 seconds, mem : 24758\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1234/3023  40% ETA:  0:07:17 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1233 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.291 || 0.305 seconds, mem : 24789\n",
      "\u001b[0m\u001b[41mEpisode 1234 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.291 || 0.310 seconds, mem : 24820\n",
      "\u001b[0m\u001b[41mEpisode 1235 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.290 || 0.306 seconds, mem : 24851\n",
      "\u001b[0m\u001b[41mEpisode 1236 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.290 || 0.278 seconds, mem : 24881\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1238/3023  40% ETA:  0:07:17 ||||||||||||||||                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1237 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.290 || 0.313 seconds, mem : 24913\n",
      "\u001b[0m\u001b[41mEpisode 1238 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.289 || 0.311 seconds, mem : 24944\n",
      "\u001b[0m\u001b[41mEpisode 1239 with 30 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.289 || 0.276 seconds, mem : 24974\n",
      "\u001b[0mEpisode 1240 with 15 steps || Reward : [-0.01  0.  ] || avg reward :  0.085 || Noise  0.289 || 0.260 seconds, mem : 24989\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1242/3023  41% ETA:  0:07:16 |///////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1241 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.289 || 0.300 seconds, mem : 25020\n",
      "\u001b[0m\u001b[41mEpisode 1242 with 31 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.288 || 0.335 seconds, mem : 25051\n",
      "\u001b[0m\u001b[41mEpisode 1243 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.288 || 0.329 seconds, mem : 25080\n",
      "\u001b[0m\u001b[41mEpisode 1244 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.288 || 0.302 seconds, mem : 25110\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1246/3023  41% ETA:  0:07:15 |---------------                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1245 with 30 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.287 || 0.293 seconds, mem : 25140\n",
      "\u001b[0m\u001b[41mEpisode 1246 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.287 || 0.187 seconds, mem : 25169\n",
      "\u001b[0m\u001b[41mEpisode 1247 with 31 steps || Reward : [0.   0.09] || avg reward :  0.087 || Noise  0.287 || 0.309 seconds, mem : 25200\n",
      "\u001b[0m\u001b[41mEpisode 1248 with 30 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.287 || 0.304 seconds, mem : 25230\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1250/3023  41% ETA:  0:07:15 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1249 with 32 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.286 || 0.309 seconds, mem : 25262\n",
      "\u001b[0m\u001b[41mEpisode 1250 with 32 steps || Reward : [0.   0.09] || avg reward :  0.087 || Noise  0.286 || 0.356 seconds, mem : 25294\n",
      "\u001b[0m\u001b[41mEpisode 1251 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.286 || 0.297 seconds, mem : 25323\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1254/3023  41% ETA:  0:07:14 ||||||||||||||||                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1253 with 30 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.285 || 0.296 seconds, mem : 25369\n",
      "\u001b[0m\u001b[41mEpisode 1254 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.285 || 0.335 seconds, mem : 25400\n",
      "\u001b[0m\u001b[44mEpisode 1255 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.087 || Noise  0.285 || 0.458 seconds, mem : 25463\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1257/3023  41% ETA:  0:07:14 |///////////////                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1257 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.284 || 0.324 seconds, mem : 25509\n",
      "\u001b[0m\u001b[41mEpisode 1258 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.284 || 0.308 seconds, mem : 25540\n",
      "\u001b[0m\u001b[41mEpisode 1259 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.283 || 0.296 seconds, mem : 25569\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1261/3023  41% ETA:  0:07:13 |---------------                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1260 with 32 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.283 || 0.342 seconds, mem : 25601\n",
      "\u001b[0m\u001b[41mEpisode 1261 with 32 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.283 || 0.321 seconds, mem : 25633\n",
      "\u001b[0m\u001b[41mEpisode 1262 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.283 || 0.299 seconds, mem : 25664\n",
      "\u001b[0m\u001b[41mEpisode 1263 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.282 || 0.340 seconds, mem : 25695\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1265/3023  41% ETA:  0:07:12 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1264 with 32 steps || Reward : [0.   0.09] || avg reward :  0.087 || Noise  0.282 || 0.310 seconds, mem : 25727\n",
      "\u001b[0m\u001b[41mEpisode 1265 with 29 steps || Reward : [0.   0.09] || avg reward :  0.087 || Noise  0.282 || 0.294 seconds, mem : 25756\n",
      "\u001b[0m\u001b[41mEpisode 1266 with 31 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.281 || 0.682 seconds, mem : 25787\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1268/3023  41% ETA:  0:07:12 ||||||||||||||||                       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1267 with 29 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.281 || 0.287 seconds, mem : 25816\n",
      "\u001b[0m\u001b[41mEpisode 1268 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.281 || 0.303 seconds, mem : 25847\n",
      "\u001b[0m\u001b[41mEpisode 1271 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.280 || 0.256 seconds, mem : 25907\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1273/3023  42% ETA:  0:07:11 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1272 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.280 || 0.312 seconds, mem : 25939\n",
      "\u001b[0m\u001b[41mEpisode 1274 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.279 || 0.283 seconds, mem : 25982\n",
      "\u001b[0m\u001b[41mEpisode 1275 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.279 || 0.301 seconds, mem : 26014\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1277/3023  42% ETA:  0:07:10 |----------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1276 with 31 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.279 || 0.320 seconds, mem : 26045\n",
      "\u001b[0m\u001b[41mEpisode 1277 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.278 || 0.312 seconds, mem : 26076\n",
      "\u001b[0m\u001b[41mEpisode 1278 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.278 || 0.281 seconds, mem : 26107\n",
      "\u001b[0m\u001b[41mEpisode 1279 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.278 || 0.327 seconds, mem : 26139\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1281/3023  42% ETA:  0:07:10 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1280 with 30 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.278 || 0.307 seconds, mem : 26169\n",
      "\u001b[0m\u001b[41mEpisode 1281 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.277 || 0.297 seconds, mem : 26200\n",
      "\u001b[0m\u001b[41mEpisode 1282 with 32 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.277 || 0.313 seconds, mem : 26232\n",
      "\u001b[0m\u001b[41mEpisode 1283 with 32 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.277 || 0.288 seconds, mem : 26264\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1285/3023  42% ETA:  0:07:09 |||||||||||||||||                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1284 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.276 || 0.283 seconds, mem : 26294\n",
      "\u001b[0m\u001b[41mEpisode 1285 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.276 || 0.290 seconds, mem : 26326\n",
      "\u001b[0m\u001b[41mEpisode 1286 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.276 || 0.316 seconds, mem : 26358\n",
      "\u001b[0m\u001b[41mEpisode 1287 with 32 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.276 || 0.304 seconds, mem : 26390\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1289/3023  42% ETA:  0:07:08 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1288 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.275 || 0.282 seconds, mem : 26421\n",
      "\u001b[0m\u001b[41mEpisode 1289 with 30 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.275 || 0.323 seconds, mem : 26451\n",
      "\u001b[0m\u001b[41mEpisode 1290 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.275 || 0.275 seconds, mem : 26482\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1293/3023  42% ETA:  0:07:07 |----------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1292 with 31 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.274 || 0.266 seconds, mem : 26526\n",
      "\u001b[0m\u001b[41mEpisode 1293 with 31 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.274 || 0.330 seconds, mem : 26557\n",
      "\u001b[0m\u001b[41mEpisode 1294 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.274 || 0.282 seconds, mem : 26589\n",
      "\u001b[0m\u001b[41mEpisode 1295 with 31 steps || Reward : [0.   0.09] || avg reward :  0.085 || Noise  0.273 || 0.298 seconds, mem : 26620\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1297/3023  42% ETA:  0:07:07 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1296 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.273 || 0.297 seconds, mem : 26652\n",
      "\u001b[0m\u001b[41mEpisode 1297 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.273 || 0.279 seconds, mem : 26683\n",
      "\u001b[0m\u001b[41mEpisode 1298 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.273 || 0.271 seconds, mem : 26714\n",
      "\u001b[0m\u001b[41mEpisode 1299 with 31 steps || Reward : [0.   0.09] || avg reward :  0.086 || Noise  0.272 || 0.267 seconds, mem : 26745\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1301/3023  43% ETA:  0:07:06 |||||||||||||||||                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1300 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.272 || 0.321 seconds, mem : 26776\n",
      "\u001b[0m\u001b[41mEpisode 1301 with 30 steps || Reward : [0.   0.09] || avg reward :  0.087 || Noise  0.272 || 0.303 seconds, mem : 26806\n",
      "\u001b[0m\u001b[41mEpisode 1302 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.272 || 0.273 seconds, mem : 26837\n",
      "\u001b[0m\u001b[41mEpisode 1303 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.271 || 0.308 seconds, mem : 26868\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1305/3023  43% ETA:  0:07:05 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1304 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.271 || 0.268 seconds, mem : 26898\n",
      "\u001b[0m\u001b[41mEpisode 1305 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.271 || 0.282 seconds, mem : 26929\n",
      "\u001b[0m\u001b[41mEpisode 1306 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.270 || 0.263 seconds, mem : 26959\n",
      "\u001b[0m\u001b[41mEpisode 1307 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.270 || 0.367 seconds, mem : 26989\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1309/3023  43% ETA:  0:07:04 |----------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1308 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.270 || 0.290 seconds, mem : 27022\n",
      "\u001b[0m\u001b[41mEpisode 1309 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.270 || 0.300 seconds, mem : 27053\n",
      "\u001b[0m\u001b[41mEpisode 1310 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.269 || 0.309 seconds, mem : 27084\n",
      "\u001b[0m\u001b[41mEpisode 1311 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.269 || 0.298 seconds, mem : 27114\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1313/3023  43% ETA:  0:07:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1312 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.269 || 0.296 seconds, mem : 27144\n",
      "\u001b[0m\u001b[41mEpisode 1313 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.269 || 0.311 seconds, mem : 27173\n",
      "\u001b[0m\u001b[41mEpisode 1314 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.268 || 0.278 seconds, mem : 27204\n",
      "\u001b[0m\u001b[41mEpisode 1315 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.268 || 0.272 seconds, mem : 27236\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1317/3023  43% ETA:  0:07:03 |||||||||||||||||                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1316 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.268 || 0.256 seconds, mem : 27267\n",
      "\u001b[0m\u001b[41mEpisode 1317 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.267 || 0.301 seconds, mem : 27298\n",
      "\u001b[0m\u001b[41mEpisode 1318 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.267 || 0.268 seconds, mem : 27329\n",
      "\u001b[0m\u001b[41mEpisode 1319 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.267 || 0.267 seconds, mem : 27360\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1321/3023  43% ETA:  0:07:02 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1320 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.089 || Noise  0.267 || 0.277 seconds, mem : 27390\n",
      "\u001b[0m\u001b[41mEpisode 1321 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.266 || 0.298 seconds, mem : 27421\n",
      "\u001b[0m\u001b[41mEpisode 1322 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.266 || 0.269 seconds, mem : 27452\n",
      "\u001b[0m\u001b[41mEpisode 1323 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.266 || 0.267 seconds, mem : 27483\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1325/3023  43% ETA:  0:07:01 |----------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1324 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.266 || 0.297 seconds, mem : 27514\n",
      "\u001b[0m\u001b[41mEpisode 1325 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.265 || 0.298 seconds, mem : 27545\n",
      "\u001b[0m\u001b[41mEpisode 1326 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.265 || 0.266 seconds, mem : 27576\n",
      "\u001b[0m\u001b[41mEpisode 1327 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.265 || 0.283 seconds, mem : 27608\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1329/3023  43% ETA:  0:07:01 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1328 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.265 || 0.299 seconds, mem : 27639\n",
      "\u001b[0m\u001b[41mEpisode 1329 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.264 || 0.299 seconds, mem : 27670\n",
      "\u001b[0m\u001b[41mEpisode 1330 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.264 || 0.284 seconds, mem : 27701\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1332/3023  44% ETA:  0:07:00 |||||||||||||||||                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1331 with 61 steps || Reward : [0.1  0.19] || avg reward :  0.090 || Noise  0.264 || 0.421 seconds, mem : 27762\n",
      "\u001b[0m\u001b[41mEpisode 1332 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.264 || 0.289 seconds, mem : 27792\n",
      "\u001b[0m\u001b[41mEpisode 1333 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.263 || 0.295 seconds, mem : 27824\n",
      "\u001b[0m\u001b[41mEpisode 1334 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.263 || 0.302 seconds, mem : 27855\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1336/3023  44% ETA:  0:06:59 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1335 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.263 || 0.299 seconds, mem : 27887\n",
      "\u001b[0m\u001b[41mEpisode 1336 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.262 || 0.275 seconds, mem : 27918\n",
      "\u001b[0m\u001b[41mEpisode 1337 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.262 || 0.300 seconds, mem : 27950\n",
      "\u001b[0m\u001b[41mEpisode 1338 with 32 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.262 || 0.286 seconds, mem : 27982\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1340/3023  44% ETA:  0:06:59 |----------------                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1339 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.262 || 0.290 seconds, mem : 28013\n",
      "\u001b[0m\u001b[41mEpisode 1340 with 30 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.261 || 0.286 seconds, mem : 28043\n",
      "\u001b[0m\u001b[41mEpisode 1341 with 32 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.261 || 0.306 seconds, mem : 28075\n",
      "\u001b[0m\u001b[41mEpisode 1342 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.261 || 0.284 seconds, mem : 28105\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1344/3023  44% ETA:  0:06:58 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1343 with 31 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.261 || 0.289 seconds, mem : 28136\n",
      "\u001b[0m\u001b[41mEpisode 1344 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.260 || 0.320 seconds, mem : 28168\n",
      "\u001b[0m\u001b[41mEpisode 1345 with 31 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.260 || 0.302 seconds, mem : 28199\n",
      "\u001b[0m\u001b[41mEpisode 1346 with 30 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.260 || 0.273 seconds, mem : 28229\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1348/3023  44% ETA:  0:06:57 |||||||||||||||||                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1347 with 30 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.260 || 0.299 seconds, mem : 28259\n",
      "\u001b[0m\u001b[41mEpisode 1348 with 30 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.259 || 0.309 seconds, mem : 28289\n",
      "\u001b[0m\u001b[41mEpisode 1349 with 30 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.259 || 0.289 seconds, mem : 28319\n",
      "\u001b[0m\u001b[41mEpisode 1350 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.259 || 0.267 seconds, mem : 28350\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1352/3023  44% ETA:  0:06:56 |////////////////                      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1351 with 31 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.259 || 0.328 seconds, mem : 28381\n",
      "\u001b[0m\u001b[41mEpisode 1352 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.258 || 0.308 seconds, mem : 28412\n",
      "\u001b[0m\u001b[41mEpisode 1353 with 30 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.258 || 0.274 seconds, mem : 28442\n",
      "\u001b[0m\u001b[41mEpisode 1354 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.258 || 0.309 seconds, mem : 28473\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1356/3023  44% ETA:  0:06:56 |-----------------                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1355 with 31 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.258 || 0.291 seconds, mem : 28504\n",
      "\u001b[0m\u001b[41mEpisode 1356 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.257 || 0.275 seconds, mem : 28535\n",
      "\u001b[0m\u001b[41mEpisode 1357 with 32 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.257 || 0.289 seconds, mem : 28567\n",
      "\u001b[0m\u001b[41mEpisode 1358 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.257 || 0.291 seconds, mem : 28598\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1360/3023  44% ETA:  0:06:55 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1359 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.256 || 0.284 seconds, mem : 28629\n",
      "\u001b[0m\u001b[41mEpisode 1360 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.256 || 0.292 seconds, mem : 28659\n",
      "\u001b[0m\u001b[41mEpisode 1361 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.256 || 0.296 seconds, mem : 28689\n",
      "\u001b[0m\u001b[41mEpisode 1362 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.256 || 0.301 seconds, mem : 28720\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1364/3023  45% ETA:  0:06:54 ||||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1363 with 32 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.255 || 0.266 seconds, mem : 28752\n",
      "\u001b[0m\u001b[41mEpisode 1364 with 30 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.255 || 0.298 seconds, mem : 28782\n",
      "\u001b[0m\u001b[41mEpisode 1365 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.255 || 0.282 seconds, mem : 28813\n",
      "\u001b[0m\u001b[41mEpisode 1366 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.255 || 0.268 seconds, mem : 28843\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1368/3023  45% ETA:  0:06:53 |/////////////////                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1367 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.254 || 0.269 seconds, mem : 28875\n",
      "\u001b[0m\u001b[41mEpisode 1368 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.254 || 0.302 seconds, mem : 28906\n",
      "\u001b[0m\u001b[44mEpisode 1369 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.254 || 0.318 seconds, mem : 28968\n",
      "\u001b[0m\u001b[41mEpisode 1370 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.254 || 0.210 seconds, mem : 28999\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1372/3023  45% ETA:  0:06:52 |-----------------                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1371 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.253 || 0.278 seconds, mem : 29030\n",
      "\u001b[0m\u001b[41mEpisode 1372 with 30 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.253 || 0.284 seconds, mem : 29060\n",
      "\u001b[0m\u001b[41mEpisode 1373 with 32 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.253 || 0.292 seconds, mem : 29092\n",
      "\u001b[0m\u001b[41mEpisode 1374 with 30 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.253 || 0.258 seconds, mem : 29122\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1376/3023  45% ETA:  0:06:51 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1375 with 30 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.252 || 0.291 seconds, mem : 29152\n",
      "\u001b[0m\u001b[41mEpisode 1376 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.095 || Noise  0.252 || 0.283 seconds, mem : 29182\n",
      "\u001b[0m\u001b[41mEpisode 1377 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.252 || 0.273 seconds, mem : 29213\n",
      "\u001b[0m\u001b[41mEpisode 1378 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.252 || 0.260 seconds, mem : 29244\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1380/3023  45% ETA:  0:06:50 ||||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1379 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.251 || 0.295 seconds, mem : 29276\n",
      "\u001b[0m\u001b[41mEpisode 1380 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.251 || 0.285 seconds, mem : 29307\n",
      "\u001b[0m\u001b[41mEpisode 1381 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.251 || 0.278 seconds, mem : 29338\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1382 with 61 steps || Reward : [0.1  0.19] || avg reward :  0.096 || Noise  0.251 || 0.410 seconds, mem : 29399\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1384/3023  45% ETA:  0:06:50 |/////////////////                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1383 with 31 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.250 || 0.272 seconds, mem : 29430\n",
      "\u001b[0m\u001b[41mEpisode 1384 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.250 || 0.279 seconds, mem : 29462\n",
      "\u001b[0m\u001b[41mEpisode 1385 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.250 || 0.283 seconds, mem : 29494\n",
      "\u001b[0m\u001b[41mEpisode 1386 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.250 || 0.267 seconds, mem : 29525\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1388/3023  45% ETA:  0:06:49 |-----------------                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1387 with 32 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.249 || 0.284 seconds, mem : 29557\n",
      "\u001b[0m\u001b[41mEpisode 1388 with 32 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.249 || 0.278 seconds, mem : 29589\n",
      "\u001b[0m\u001b[41mEpisode 1389 with 31 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.249 || 0.283 seconds, mem : 29620\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1392/3023  46% ETA:  0:06:48 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1391 with 62 steps || Reward : [0.1  0.19] || avg reward :  0.097 || Noise  0.248 || 0.387 seconds, mem : 29695\n",
      "\u001b[0m\u001b[41mEpisode 1392 with 31 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.248 || 0.292 seconds, mem : 29726\n",
      "\u001b[0m\u001b[41mEpisode 1393 with 30 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.248 || 0.264 seconds, mem : 29756\n",
      "\u001b[0m\u001b[41mEpisode 1394 with 32 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.248 || 0.282 seconds, mem : 29788\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1396/3023  46% ETA:  0:06:47 ||||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1395 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.247 || 0.273 seconds, mem : 29819\n",
      "\u001b[0m\u001b[41mEpisode 1396 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.097 || Noise  0.247 || 0.314 seconds, mem : 29852\n",
      "\u001b[0m\u001b[41mEpisode 1397 with 32 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.247 || 0.292 seconds, mem : 29884\n",
      "\u001b[0m\u001b[41mEpisode 1398 with 31 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.247 || 0.260 seconds, mem : 29915\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1400/3023  46% ETA:  0:06:46 |/////////////////                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1399 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.246 || 0.285 seconds, mem : 29945\n",
      "\u001b[0mEpisode 1400 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.096 || Noise  0.246 || 0.200 seconds, mem : 29959\n",
      "\u001b[0m\u001b[41mEpisode 1401 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.246 || 0.297 seconds, mem : 29989\n",
      "\u001b[0m\u001b[41mEpisode 1402 with 32 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.246 || 0.266 seconds, mem : 30021\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1404/3023  46% ETA:  0:06:45 |-----------------                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1403 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.245 || 0.292 seconds, mem : 30051\n",
      "\u001b[0m\u001b[41mEpisode 1404 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.245 || 0.268 seconds, mem : 30082\n",
      "\u001b[0m\u001b[41mEpisode 1405 with 31 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.245 || 0.283 seconds, mem : 30113\n",
      "\u001b[0m\u001b[41mEpisode 1406 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.245 || 0.263 seconds, mem : 30143\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1408/3023  46% ETA:  0:06:45 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1407 with 31 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.244 || 0.284 seconds, mem : 30174\n",
      "\u001b[0m\u001b[41mEpisode 1408 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.244 || 0.302 seconds, mem : 30206\n",
      "\u001b[0m\u001b[44mEpisode 1409 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.244 || 0.399 seconds, mem : 30271\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1412/3023  46% ETA:  0:06:44 ||||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1411 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.243 || 0.260 seconds, mem : 30316\n",
      "\u001b[0m\u001b[41mEpisode 1412 with 30 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.243 || 0.287 seconds, mem : 30346\n",
      "\u001b[0m\u001b[41mEpisode 1413 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.243 || 0.279 seconds, mem : 30377\n",
      "\u001b[0m\u001b[41mEpisode 1414 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.243 || 0.300 seconds, mem : 30409\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1416/3023  46% ETA:  0:06:43 |/////////////////                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1415 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.243 || 0.278 seconds, mem : 30439\n",
      "\u001b[0m\u001b[41mEpisode 1416 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.242 || 0.267 seconds, mem : 30470\n",
      "\u001b[0m\u001b[41mEpisode 1417 with 32 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.242 || 0.317 seconds, mem : 30502\n",
      "\u001b[0m\u001b[41mEpisode 1418 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.242 || 0.265 seconds, mem : 30533\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1420/3023  46% ETA:  0:06:42 |-----------------                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1419 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.242 || 0.292 seconds, mem : 30565\n",
      "\u001b[0m\u001b[41mEpisode 1420 with 29 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.241 || 0.273 seconds, mem : 30594\n",
      "\u001b[0m\u001b[41mEpisode 1421 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.241 || 0.284 seconds, mem : 30625\n",
      "\u001b[0m\u001b[41mEpisode 1422 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.241 || 0.324 seconds, mem : 30657\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1424/3023  47% ETA:  0:06:41 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1424 with 32 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.240 || 0.304 seconds, mem : 30702\n",
      "\u001b[0m\u001b[41mEpisode 1426 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.240 || 0.294 seconds, mem : 30746\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1428/3023  47% ETA:  0:06:40 ||||||||||||||||||                     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1427 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.240 || 0.261 seconds, mem : 30778\n",
      "\u001b[0m\u001b[44mEpisode 1429 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.239 || 0.357 seconds, mem : 30844\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1432/3023  47% ETA:  0:06:39 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1431 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.239 || 0.266 seconds, mem : 30888\n",
      "\u001b[0m\u001b[41mEpisode 1432 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.238 || 0.310 seconds, mem : 30919\n",
      "\u001b[0m\u001b[41mEpisode 1433 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.238 || 0.277 seconds, mem : 30950\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1436/3023  47% ETA:  0:06:38 |------------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1434 with 29 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.238 || 0.266 seconds, mem : 30979\n",
      "\u001b[0m\u001b[41mEpisode 1436 with 32 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.237 || 0.304 seconds, mem : 31024\n",
      "\u001b[0m\u001b[41mEpisode 1437 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.237 || 0.261 seconds, mem : 31054\n",
      "\u001b[0m\u001b[41mEpisode 1438 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.237 || 0.279 seconds, mem : 31085\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1440/3023  47% ETA:  0:06:38 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1439 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.237 || 0.419 seconds, mem : 31150\n",
      "\u001b[0m\u001b[41mEpisode 1440 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.237 || 0.282 seconds, mem : 31181\n",
      "\u001b[0m\u001b[41mEpisode 1441 with 28 steps || Reward : [-0.01  0.1 ] || avg reward :  0.089 || Noise  0.236 || 0.277 seconds, mem : 31209\n",
      "\u001b[0m\u001b[41mEpisode 1442 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.236 || 0.292 seconds, mem : 31239\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1444/3023  47% ETA:  0:06:37 |||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1443 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.236 || 0.272 seconds, mem : 31269\n",
      "\u001b[0m\u001b[44mEpisode 1445 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.088 || Noise  0.235 || 0.366 seconds, mem : 31336\n",
      "\u001b[0m\u001b[41mEpisode 1446 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.235 || 0.303 seconds, mem : 31366\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1448/3023  47% ETA:  0:06:36 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1447 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.235 || 0.288 seconds, mem : 31399\n",
      "\u001b[0m\u001b[41mEpisode 1448 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.089 || Noise  0.235 || 0.274 seconds, mem : 31430\n",
      "\u001b[0m\u001b[41mEpisode 1449 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.234 || 0.302 seconds, mem : 31462\n",
      "\u001b[0m\u001b[41mEpisode 1450 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.234 || 0.290 seconds, mem : 31492\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1452/3023  48% ETA:  0:06:35 |------------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1451 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.234 || 0.300 seconds, mem : 31524\n",
      "\u001b[0m\u001b[41mEpisode 1452 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.234 || 0.280 seconds, mem : 31555\n",
      "\u001b[0m\u001b[41mEpisode 1453 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.233 || 0.289 seconds, mem : 31586\n",
      "\u001b[0m\u001b[41mEpisode 1454 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.233 || 0.304 seconds, mem : 31617\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1456/3023  48% ETA:  0:06:34 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1455 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.233 || 0.264 seconds, mem : 31648\n",
      "\u001b[0m\u001b[44mEpisode 1456 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.233 || 0.436 seconds, mem : 31713\n",
      "\u001b[0m\u001b[41mEpisode 1457 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.233 || 0.304 seconds, mem : 31743\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1459/3023  48% ETA:  0:06:34 |||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1458 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.232 || 0.389 seconds, mem : 31807\n",
      "\u001b[0m\u001b[41mEpisode 1460 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.232 || 0.275 seconds, mem : 31852\n",
      "\u001b[0m\u001b[41mEpisode 1461 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.232 || 0.282 seconds, mem : 31883\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1463/3023  48% ETA:  0:06:33 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1462 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.088 || Noise  0.231 || 0.285 seconds, mem : 31915\n",
      "\u001b[0m\u001b[41mEpisode 1463 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.231 || 0.298 seconds, mem : 31946\n",
      "\u001b[0m\u001b[41mEpisode 1464 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.231 || 0.298 seconds, mem : 31978\n",
      "\u001b[0m\u001b[41mEpisode 1465 with 30 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.231 || 0.264 seconds, mem : 32008\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1467/3023  48% ETA:  0:06:32 |------------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1466 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.230 || 0.301 seconds, mem : 32039\n",
      "\u001b[0m\u001b[41mEpisode 1467 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.230 || 0.343 seconds, mem : 32071\n",
      "\u001b[0m\u001b[41mEpisode 1468 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.230 || 0.317 seconds, mem : 32101\n",
      "\u001b[0m\u001b[41mEpisode 1469 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.088 || Noise  0.230 || 0.290 seconds, mem : 32131\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1471/3023  48% ETA:  0:06:31 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1470 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.230 || 0.304 seconds, mem : 32163\n",
      "\u001b[0m\u001b[41mEpisode 1471 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.229 || 0.295 seconds, mem : 32195\n",
      "\u001b[0m\u001b[41mEpisode 1472 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.229 || 0.286 seconds, mem : 32226\n",
      "\u001b[0m\u001b[41mEpisode 1473 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.088 || Noise  0.229 || 0.271 seconds, mem : 32257\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1475/3023  48% ETA:  0:06:31 |||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1474 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.229 || 0.283 seconds, mem : 32288\n",
      "\u001b[0m\u001b[44mEpisode 1475 with 61 steps || Reward : [0.   0.19] || avg reward :  0.089 || Noise  0.228 || 0.472 seconds, mem : 32349\n",
      "\u001b[0m\u001b[41mEpisode 1476 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.228 || 0.282 seconds, mem : 32379\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1478/3023  48% ETA:  0:06:30 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1477 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.228 || 0.287 seconds, mem : 32410\n",
      "\u001b[0m\u001b[41mEpisode 1478 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.228 || 0.289 seconds, mem : 32440\n",
      "\u001b[0m\u001b[41mEpisode 1479 with 30 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.227 || 0.301 seconds, mem : 32470\n",
      "\u001b[0m\u001b[41mEpisode 1480 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.227 || 0.276 seconds, mem : 32502\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1482/3023  49% ETA:  0:06:29 |------------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1481 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.227 || 0.281 seconds, mem : 32533\n",
      "\u001b[0m\u001b[41mEpisode 1482 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.227 || 0.304 seconds, mem : 32563\n",
      "\u001b[0m\u001b[41mEpisode 1483 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.227 || 0.258 seconds, mem : 32594\n",
      "\u001b[0m\u001b[41mEpisode 1484 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.226 || 0.293 seconds, mem : 32626\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1486/3023  49% ETA:  0:06:28 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1485 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.226 || 0.293 seconds, mem : 32658\n",
      "\u001b[0m\u001b[41mEpisode 1486 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.226 || 0.381 seconds, mem : 32707\n",
      "\u001b[0m\u001b[41mEpisode 1487 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.226 || 0.289 seconds, mem : 32737\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1489/3023  49% ETA:  0:06:28 |||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1488 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.225 || 0.467 seconds, mem : 32800\n",
      "\u001b[0m\u001b[44mEpisode 1489 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.225 || 0.377 seconds, mem : 32853\n",
      "\u001b[0m\u001b[41mEpisode 1491 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.225 || 0.293 seconds, mem : 32897\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1493/3023  49% ETA:  0:06:27 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1492 with 31 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.225 || 0.279 seconds, mem : 32928\n",
      "\u001b[0m\u001b[41mEpisode 1493 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.224 || 0.274 seconds, mem : 32958\n",
      "\u001b[0m\u001b[44mEpisode 1494 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.088 || Noise  0.224 || 0.463 seconds, mem : 33020\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1496/3023  49% ETA:  0:06:27 |------------------                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1495 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.224 || 0.280 seconds, mem : 33052\n",
      "\u001b[0m\u001b[41mEpisode 1496 with 49 steps || Reward : [-0.01  0.1 ] || avg reward :  0.088 || Noise  0.224 || 0.381 seconds, mem : 33101\n",
      "\u001b[0m\u001b[41mEpisode 1497 with 32 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.223 || 0.318 seconds, mem : 33133\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1499/3023  49% ETA:  0:06:26 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1498 with 31 steps || Reward : [0.   0.09] || avg reward :  0.088 || Noise  0.223 || 0.302 seconds, mem : 33164\n",
      "\u001b[0m\u001b[41mEpisode 1499 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.223 || 0.299 seconds, mem : 33195\n",
      "\u001b[0m\u001b[41mEpisode 1500 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.223 || 0.323 seconds, mem : 33226\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1502/3023  49% ETA:  0:06:26 |||||||||||||||||||                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1501 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.223 || 0.423 seconds, mem : 33291\n",
      "\u001b[0m\u001b[41mEpisode 1502 with 31 steps || Reward : [0.   0.09] || avg reward :  0.089 || Noise  0.222 || 0.297 seconds, mem : 33322\n",
      "\u001b[0m\u001b[41mEpisode 1503 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.222 || 0.237 seconds, mem : 33354\n",
      "\u001b[0m\u001b[41mEpisode 1504 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.222 || 0.202 seconds, mem : 33386\n",
      "\u001b[0m\u001b[41mEpisode 1505 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.222 || 0.187 seconds, mem : 33416\n",
      "\u001b[0m\u001b[41mEpisode 1506 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.089 || Noise  0.221 || 0.193 seconds, mem : 33447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1507/3023  49% ETA:  0:06:24 |//////////////////                    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[41mEpisode 1507 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.221 || 0.195 seconds, mem : 33477\n",
      "\u001b[0m\u001b[41mEpisode 1508 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.221 || 0.206 seconds, mem : 33509\n",
      "\u001b[0m\u001b[41mEpisode 1509 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.221 || 0.204 seconds, mem : 33540\n",
      "\u001b[0m\u001b[41mEpisode 1510 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.221 || 0.236 seconds, mem : 33571\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1512/3023  50% ETA:  0:06:23 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1511 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.220 || 0.275 seconds, mem : 33603\n",
      "\u001b[0m\u001b[41mEpisode 1512 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.220 || 0.294 seconds, mem : 33634\n",
      "\u001b[0m\u001b[41mEpisode 1513 with 32 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.220 || 0.288 seconds, mem : 33666\n",
      "\u001b[0m\u001b[41mEpisode 1514 with 32 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.220 || 0.296 seconds, mem : 33698\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1516/3023  50% ETA:  0:06:22 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1515 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.219 || 0.281 seconds, mem : 33728\n",
      "\u001b[0m\u001b[41mEpisode 1516 with 32 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.219 || 0.337 seconds, mem : 33760\n",
      "\u001b[0m\u001b[41mEpisode 1517 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.219 || 0.264 seconds, mem : 33791\n",
      "\u001b[0m\u001b[41mEpisode 1518 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.219 || 0.280 seconds, mem : 33822\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1520/3023  50% ETA:  0:06:21 ||||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1519 with 30 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.219 || 0.282 seconds, mem : 33852\n",
      "\u001b[0m\u001b[41mEpisode 1520 with 51 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.218 || 0.377 seconds, mem : 33903\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1521 with 67 steps || Reward : [0.2  0.09] || avg reward :  0.091 || Noise  0.218 || 0.438 seconds, mem : 33970\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1523/3023  50% ETA:  0:06:21 |///////////////////                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1522 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.218 || 0.331 seconds, mem : 34002\n",
      "\u001b[0m\u001b[41mEpisode 1523 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.218 || 0.316 seconds, mem : 34033\n",
      "\u001b[0m\u001b[41mEpisode 1524 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.217 || 0.293 seconds, mem : 34064\n",
      "\u001b[0m\u001b[41mEpisode 1525 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.217 || 0.284 seconds, mem : 34095\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1527/3023  50% ETA:  0:06:20 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1526 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.217 || 0.284 seconds, mem : 34126\n",
      "\u001b[0m\u001b[44mEpisode 1527 with 56 steps || Reward : [0.09 0.1 ] || avg reward :  0.093 || Noise  0.217 || 0.393 seconds, mem : 34182\n",
      "\u001b[0m\u001b[44mEpisode 1528 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.217 || 0.485 seconds, mem : 34244\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1530/3023  50% ETA:  0:06:20 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1529 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.216 || 0.288 seconds, mem : 34276\n",
      "\u001b[0m\u001b[41mEpisode 1530 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.216 || 0.292 seconds, mem : 34307\n",
      "\u001b[0m\u001b[41mEpisode 1531 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.216 || 0.303 seconds, mem : 34338\n",
      "\u001b[0m\u001b[41mEpisode 1532 with 32 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.216 || 0.284 seconds, mem : 34370\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1534/3023  50% ETA:  0:06:19 ||||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1534 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.215 || 0.377 seconds, mem : 34436\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1537/3023  50% ETA:  0:06:18 |///////////////////                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1536 with 61 steps || Reward : [0.   0.19] || avg reward :  0.095 || Noise  0.215 || 0.385 seconds, mem : 34510\n",
      "\u001b[0m\u001b[41mEpisode 1537 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.215 || 0.282 seconds, mem : 34542\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1541/3023  50% ETA:  0:06:17 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1540 with 30 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.214 || 0.266 seconds, mem : 34600\n",
      "\u001b[0m\u001b[41mEpisode 1542 with 31 steps || Reward : [0.   0.09] || avg reward :  0.092 || Noise  0.214 || 0.301 seconds, mem : 34645\n",
      "\u001b[0m\u001b[41mEpisode 1543 with 41 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.213 || 0.333 seconds, mem : 34686\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1545/3023  51% ETA:  0:06:16 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1544 with 31 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.213 || 0.279 seconds, mem : 34717\n",
      "\u001b[0m\u001b[41mEpisode 1545 with 32 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.213 || 0.294 seconds, mem : 34749\n",
      "\u001b[0m\u001b[41mEpisode 1546 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.213 || 0.305 seconds, mem : 34781\n",
      "\u001b[0m\u001b[41mEpisode 1547 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.213 || 0.282 seconds, mem : 34812\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1549/3023  51% ETA:  0:06:15 ||||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1548 with 51 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.212 || 0.364 seconds, mem : 34863\n",
      "\u001b[0m\u001b[41mEpisode 1549 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.212 || 0.335 seconds, mem : 34894\n",
      "\u001b[0m\u001b[41mEpisode 1550 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.212 || 0.282 seconds, mem : 34924\n",
      "\u001b[0m\u001b[41mEpisode 1551 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.212 || 0.277 seconds, mem : 34955\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1553/3023  51% ETA:  0:06:14 |///////////////////                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1552 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.211 || 0.330 seconds, mem : 34985\n",
      "\u001b[0m\u001b[44mEpisode 1554 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.211 || 0.403 seconds, mem : 35062\n",
      "\u001b[0m\u001b[41mEpisode 1555 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.211 || 0.313 seconds, mem : 35092\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1557/3023  51% ETA:  0:06:14 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1556 with 50 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.211 || 0.363 seconds, mem : 35142\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1557 with 62 steps || Reward : [0.2  0.09] || avg reward :  0.093 || Noise  0.210 || 0.396 seconds, mem : 35204\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1560/3023  51% ETA:  0:06:13 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1559 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.210 || 0.425 seconds, mem : 35283\n",
      "\u001b[0m\u001b[41mEpisode 1560 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.210 || 0.266 seconds, mem : 35313\n",
      "\u001b[0m\u001b[44mEpisode 1561 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.210 || 0.435 seconds, mem : 35376\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1563/3023  51% ETA:  0:06:13 ||||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1562 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.209 || 0.315 seconds, mem : 35408\n",
      "\u001b[0m\u001b[41mEpisode 1563 with 31 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.209 || 0.275 seconds, mem : 35439\n",
      "\u001b[0m\u001b[41mEpisode 1564 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.209 || 0.329 seconds, mem : 35470\n",
      "\u001b[0m\u001b[41mEpisode 1565 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.209 || 0.309 seconds, mem : 35502\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1567/3023  51% ETA:  0:06:12 |///////////////////                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1566 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.209 || 0.284 seconds, mem : 35533\n",
      "\u001b[0m\u001b[41mEpisode 1567 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.208 || 0.358 seconds, mem : 35563\n",
      "\u001b[0m\u001b[41mEpisode 1568 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.208 || 0.335 seconds, mem : 35595\n",
      "\u001b[0m\u001b[41mEpisode 1569 with 32 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.208 || 0.295 seconds, mem : 35627\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1571/3023  51% ETA:  0:06:11 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1570 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.208 || 0.290 seconds, mem : 35657\n",
      "\u001b[0m\u001b[41mEpisode 1571 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.207 || 0.297 seconds, mem : 35690\n",
      "\u001b[0m\u001b[44mEpisode 1572 with 61 steps || Reward : [ 0.2  -0.01] || avg reward :  0.094 || Noise  0.207 || 0.392 seconds, mem : 35751\n",
      "\u001b[0m\u001b[41mEpisode 1573 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.207 || 0.285 seconds, mem : 35782\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1575/3023  52% ETA:  0:06:10 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1574 with 52 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.207 || 0.383 seconds, mem : 35834\n",
      "\u001b[0m\u001b[41mEpisode 1575 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.207 || 0.294 seconds, mem : 35867\n",
      "\u001b[0m\u001b[41mEpisode 1576 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.206 || 0.271 seconds, mem : 35898\n",
      "\u001b[0m\u001b[41mEpisode 1577 with 31 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.206 || 0.292 seconds, mem : 35929\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1579/3023  52% ETA:  0:06:10 ||||||||||||||||||||                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1578 with 46 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.206 || 0.349 seconds, mem : 35975\n",
      "\u001b[0m\u001b[41mEpisode 1579 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.206 || 0.284 seconds, mem : 36007\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1580 with 62 steps || Reward : [0.19 0.1 ] || avg reward :  0.095 || Noise  0.206 || 0.448 seconds, mem : 36069\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1583/3023  52% ETA:  0:06:09 |///////////////////                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1583 with 30 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.205 || 0.279 seconds, mem : 36126\n",
      "\u001b[0m\u001b[41mEpisode 1585 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.205 || 0.283 seconds, mem : 36170\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1587/3023  52% ETA:  0:06:08 |-------------------                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1586 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.204 || 0.276 seconds, mem : 36202\n",
      "\u001b[0m\u001b[44mEpisode 1587 with 53 steps || Reward : [0.09 0.1 ] || avg reward :  0.092 || Noise  0.204 || 0.405 seconds, mem : 36255\n",
      "\u001b[0m\u001b[44mEpisode 1588 with 52 steps || Reward : [0.09 0.1 ] || avg reward :  0.092 || Noise  0.204 || 0.379 seconds, mem : 36307\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1590/3023  52% ETA:  0:06:07 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1589 with 65 steps || Reward : [0.1  0.29] || avg reward :  0.094 || Noise  0.204 || 0.422 seconds, mem : 36372\n",
      "\u001b[0m\u001b[41mEpisode 1592 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.203 || 0.268 seconds, mem : 36430\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1594/3023  52% ETA:  0:06:06 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1593 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.203 || 0.315 seconds, mem : 36461\n",
      "\u001b[0m\u001b[41mEpisode 1595 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.203 || 0.277 seconds, mem : 36505\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1598/3023  52% ETA:  0:06:05 |////////////////////                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1597 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.202 || 0.456 seconds, mem : 36582\n",
      "\u001b[0m\u001b[41mEpisode 1598 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.202 || 0.322 seconds, mem : 36614\n",
      "\u001b[0m\u001b[41mEpisode 1599 with 32 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.202 || 0.276 seconds, mem : 36646\n",
      "\u001b[0m\u001b[41mEpisode 1600 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.202 || 0.303 seconds, mem : 36676\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1602/3023  52% ETA:  0:06:04 |--------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1601 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.201 || 0.352 seconds, mem : 36706\n",
      "\u001b[0m\u001b[41mEpisode 1602 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.201 || 0.298 seconds, mem : 36738\n",
      "\u001b[0m\u001b[44mEpisode 1603 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.201 || 0.405 seconds, mem : 36790\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1605/3023  53% ETA:  0:06:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1604 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.201 || 0.419 seconds, mem : 36853\n",
      "\u001b[0m\u001b[41mEpisode 1605 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.201 || 0.290 seconds, mem : 36885\n",
      "\u001b[0m\u001b[41mEpisode 1606 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.200 || 0.304 seconds, mem : 36916\n",
      "\u001b[0m\u001b[41mEpisode 1607 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.200 || 0.300 seconds, mem : 36949\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1609/3023  53% ETA:  0:06:03 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1608 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.200 || 0.272 seconds, mem : 36980\n",
      "\u001b[0m\u001b[44mEpisode 1609 with 54 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.200 || 0.381 seconds, mem : 37034\n",
      "\u001b[0m\u001b[41mEpisode 1611 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.199 || 0.298 seconds, mem : 37077\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1613/3023  53% ETA:  0:06:02 |////////////////////                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1612 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.199 || 0.276 seconds, mem : 37108\n",
      "\u001b[0m\u001b[41mEpisode 1613 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.199 || 0.305 seconds, mem : 37138\n",
      "\u001b[0m\u001b[41mEpisode 1614 with 49 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.199 || 0.364 seconds, mem : 37187\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1616/3023  53% ETA:  0:06:02 |--------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1615 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.199 || 0.413 seconds, mem : 37250\n",
      "\u001b[0m\u001b[41mEpisode 1616 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.198 || 0.281 seconds, mem : 37281\n",
      "\u001b[0m\u001b[41mEpisode 1617 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.198 || 0.278 seconds, mem : 37312\n",
      "\u001b[0m\u001b[44mEpisode 1618 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.198 || 0.400 seconds, mem : 37376\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1620/3023  53% ETA:  0:06:01 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1619 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.198 || 0.285 seconds, mem : 37408\n",
      "\u001b[0m\u001b[41mEpisode 1620 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.198 || 0.295 seconds, mem : 37440\n",
      "\u001b[0m\u001b[41mEpisode 1621 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.197 || 0.270 seconds, mem : 37472\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1624/3023  53% ETA:  0:06:00 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1623 with 50 steps || Reward : [ 0.2  -0.01] || avg reward :  0.090 || Noise  0.197 || 0.351 seconds, mem : 37535\n",
      "\u001b[0m\u001b[44mEpisode 1624 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.197 || 0.410 seconds, mem : 37597\n",
      "\u001b[0m\u001b[41mEpisode 1625 with 31 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.197 || 0.302 seconds, mem : 37628\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1627/3023  53% ETA:  0:05:59 |////////////////////                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1626 with 61 steps || Reward : [0.   0.19] || avg reward :  0.090 || Noise  0.196 || 0.410 seconds, mem : 37689\n",
      "\u001b[0m\u001b[44mEpisode 1627 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.196 || 0.417 seconds, mem : 37752\n",
      "\u001b[0m\u001b[44mEpisode 1628 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.196 || 0.402 seconds, mem : 37814\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1630/3023  53% ETA:  0:05:59 |--------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1629 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.196 || 0.278 seconds, mem : 37845\n",
      "\u001b[0m\u001b[44mEpisode 1630 with 61 steps || Reward : [0.   0.19] || avg reward :  0.091 || Noise  0.196 || 0.417 seconds, mem : 37906\n",
      "\u001b[0m\u001b[41mEpisode 1631 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.195 || 0.266 seconds, mem : 37936\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1634/3023  54% ETA:  0:05:58 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1633 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.195 || 0.349 seconds, mem : 38001\n",
      "\u001b[0m\u001b[41mEpisode 1634 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.195 || 0.294 seconds, mem : 38032\n",
      "\u001b[0m\u001b[41mEpisode 1635 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.195 || 0.291 seconds, mem : 38064\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1637/3023  54% ETA:  0:05:58 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1636 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.194 || 0.412 seconds, mem : 38129\n",
      "\u001b[0m\u001b[41mEpisode 1637 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.194 || 0.289 seconds, mem : 38161\n",
      "\u001b[0m\u001b[44mEpisode 1638 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.194 || 0.366 seconds, mem : 38214\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1641/3023  54% ETA:  0:05:57 |////////////////////                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1640 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.194 || 0.311 seconds, mem : 38261\n",
      "\u001b[0m\u001b[41mEpisode 1641 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.193 || 0.271 seconds, mem : 38291\n",
      "\u001b[0m\u001b[41mEpisode 1642 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.193 || 0.284 seconds, mem : 38323\n",
      "\u001b[0m\u001b[41mEpisode 1643 with 52 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.193 || 0.392 seconds, mem : 38375\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1645/3023  54% ETA:  0:05:56 |--------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1644 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.193 || 0.383 seconds, mem : 38430\n",
      "\u001b[0m\u001b[41mEpisode 1645 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.193 || 0.268 seconds, mem : 38460\n",
      "\u001b[0m\u001b[41mEpisode 1646 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.192 || 0.285 seconds, mem : 38491\n",
      "\u001b[0m\u001b[41mEpisode 1647 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.192 || 0.275 seconds, mem : 38520\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1649/3023  54% ETA:  0:05:55 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1648 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.192 || 0.292 seconds, mem : 38551\n",
      "\u001b[0m\u001b[44mEpisode 1649 with 54 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.192 || 0.355 seconds, mem : 38605\n",
      "\u001b[0m\u001b[44mEpisode 1650 with 61 steps || Reward : [0.   0.19] || avg reward :  0.095 || Noise  0.192 || 0.403 seconds, mem : 38666\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1652/3023  54% ETA:  0:05:54 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1651 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.192 || 0.281 seconds, mem : 38697\n",
      "\u001b[0m\u001b[41mEpisode 1653 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.191 || 0.297 seconds, mem : 38742\n",
      "\u001b[0m\u001b[41mEpisode 1655 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.191 || 0.279 seconds, mem : 38786\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1657/3023  54% ETA:  0:05:53 |////////////////////                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1656 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.191 || 0.394 seconds, mem : 38851\n",
      "\u001b[0m\u001b[41mEpisode 1657 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.190 || 0.303 seconds, mem : 38882\n",
      "\u001b[0m\u001b[41mEpisode 1658 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.190 || 0.283 seconds, mem : 38913\n",
      "\u001b[0m\u001b[41mEpisode 1659 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.190 || 0.269 seconds, mem : 38945\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1661/3023  54% ETA:  0:05:52 |--------------------                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1660 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.190 || 0.312 seconds, mem : 38978\n",
      "\u001b[0m\u001b[41mEpisode 1661 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.190 || 0.298 seconds, mem : 39010\n",
      "\u001b[0m\u001b[41mEpisode 1662 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.189 || 0.284 seconds, mem : 39041\n",
      "\u001b[0m\u001b[41mEpisode 1663 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.189 || 0.279 seconds, mem : 39071\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1665/3023  55% ETA:  0:05:51 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1664 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.189 || 0.370 seconds, mem : 39126\n",
      "\u001b[0m\u001b[44mEpisode 1665 with 56 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.189 || 0.385 seconds, mem : 39182\n",
      "\u001b[0m\u001b[41mEpisode 1666 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.189 || 0.288 seconds, mem : 39212\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1668/3023  55% ETA:  0:05:51 |||||||||||||||||||||                  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1667 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.188 || 0.428 seconds, mem : 39278\n",
      "\u001b[0m\u001b[41mEpisode 1668 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.188 || 0.275 seconds, mem : 39308\n",
      "\u001b[0m\u001b[41mEpisode 1669 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.188 || 0.289 seconds, mem : 39339\n",
      "\u001b[0m\u001b[41mEpisode 1670 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.188 || 0.275 seconds, mem : 39370\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1672/3023  55% ETA:  0:05:50 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1671 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.188 || 0.281 seconds, mem : 39400\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1672 with 88 steps || Reward : [0.2  0.19] || avg reward :  0.094 || Noise  0.188 || 0.516 seconds, mem : 39488\n",
      "\u001b[0m\u001b[41mEpisode 1673 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.187 || 0.286 seconds, mem : 39520\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1675/3023  55% ETA:  0:05:49 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1674 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.187 || 0.450 seconds, mem : 39583\n",
      "\u001b[0m\u001b[41mEpisode 1675 with 53 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.187 || 0.376 seconds, mem : 39636\n",
      "\u001b[0m\u001b[41mEpisode 1676 with 51 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.187 || 0.376 seconds, mem : 39687\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1678/3023  55% ETA:  0:05:49 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1677 with 52 steps || Reward : [-0.01  0.1 ] || avg reward :  0.094 || Noise  0.187 || 0.357 seconds, mem : 39739\n",
      "\u001b[0m\u001b[41mEpisode 1678 with 30 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.186 || 0.296 seconds, mem : 39769\n",
      "\u001b[0m\u001b[41mEpisode 1679 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.186 || 0.289 seconds, mem : 39800\n",
      "\u001b[0m\u001b[41mEpisode 1680 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.186 || 0.259 seconds, mem : 39830\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1682/3023  55% ETA:  0:05:48 ||||||||||||||||||||||                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1682 with 50 steps || Reward : [ 0.2  -0.01] || avg reward :  0.095 || Noise  0.186 || 0.383 seconds, mem : 39894\n",
      "\u001b[0m\u001b[44mEpisode 1683 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.095 || Noise  0.185 || 0.405 seconds, mem : 39957\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1685/3023  55% ETA:  0:05:47 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1686 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.185 || 0.269 seconds, mem : 40014\n",
      "\u001b[0m\u001b[41mEpisode 1687 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.185 || 0.281 seconds, mem : 40045\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1690/3023  55% ETA:  0:05:46 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1691 with 33 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.184 || 0.271 seconds, mem : 40120\n",
      "\u001b[0m\u001b[41mEpisode 1692 with 33 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.184 || 0.303 seconds, mem : 40153\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1694/3023  56% ETA:  0:05:45 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1693 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.091 || Noise  0.184 || 0.271 seconds, mem : 40184\n",
      "\u001b[0m\u001b[41mEpisode 1694 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.183 || 0.300 seconds, mem : 40212\n",
      "\u001b[0m\u001b[41mEpisode 1695 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.183 || 0.293 seconds, mem : 40245\n",
      "\u001b[0m\u001b[41mEpisode 1696 with 32 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.183 || 0.294 seconds, mem : 40277\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1698/3023  56% ETA:  0:05:44 ||||||||||||||||||||||                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1697 with 60 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.183 || 0.424 seconds, mem : 40337\n",
      "\u001b[0m\u001b[41mEpisode 1698 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.183 || 0.277 seconds, mem : 40367\n",
      "\u001b[0m\u001b[41mEpisode 1699 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.183 || 0.281 seconds, mem : 40397\n",
      "\u001b[0m\u001b[41mEpisode 1700 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.182 || 0.283 seconds, mem : 40427\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1702/3023  56% ETA:  0:05:43 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1701 with 92 steps || Reward : [0.09 0.2 ] || avg reward :  0.094 || Noise  0.182 || 0.533 seconds, mem : 40519\n",
      "\u001b[0m\u001b[41mEpisode 1702 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.182 || 0.381 seconds, mem : 40567\n",
      "\u001b[0m\u001b[44mEpisode 1703 with 79 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.182 || 0.482 seconds, mem : 40646\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1705/3023  56% ETA:  0:05:43 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1705 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.181 || 0.267 seconds, mem : 40690\n",
      "\u001b[0m\u001b[41mEpisode 1707 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.181 || 0.302 seconds, mem : 40735\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1709/3023  56% ETA:  0:05:42 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1708 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.181 || 0.282 seconds, mem : 40766\n",
      "\u001b[0m\u001b[41mEpisode 1709 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.181 || 0.287 seconds, mem : 40798\n",
      "\u001b[0m\u001b[41mEpisode 1710 with 55 steps || Reward : [-0.01  0.1 ] || avg reward :  0.093 || Noise  0.181 || 0.376 seconds, mem : 40853\n",
      "\u001b[0m\u001b[41mEpisode 1711 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.180 || 0.318 seconds, mem : 40883\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1713/3023  56% ETA:  0:05:41 ||||||||||||||||||||||                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1712 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.180 || 0.288 seconds, mem : 40914\n",
      "\u001b[0m\u001b[44mEpisode 1713 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.180 || 0.446 seconds, mem : 40981\n",
      "\u001b[0m\u001b[41mEpisode 1714 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.180 || 0.303 seconds, mem : 41012\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1717/3023  56% ETA:  0:05:40 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1716 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.179 || 0.423 seconds, mem : 41089\n",
      "\u001b[0m\u001b[44mEpisode 1717 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.179 || 0.413 seconds, mem : 41142\n",
      "\u001b[0m\u001b[41mEpisode 1718 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.179 || 0.308 seconds, mem : 41173\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1720/3023  56% ETA:  0:05:40 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1719 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.179 || 0.303 seconds, mem : 41204\n",
      "\u001b[0m\u001b[44mEpisode 1720 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.179 || 0.455 seconds, mem : 41266\n",
      "\u001b[0m\u001b[44mEpisode 1721 with 33 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.179 || 0.314 seconds, mem : 41299\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1723/3023  56% ETA:  0:05:39 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1722 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.178 || 0.299 seconds, mem : 41331\n",
      "\u001b[0m\u001b[41mEpisode 1723 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.178 || 0.311 seconds, mem : 41361\n",
      "\u001b[0m\u001b[44mEpisode 1724 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.178 || 0.437 seconds, mem : 41426\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1726/3023  57% ETA:  0:05:38 ||||||||||||||||||||||                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1725 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.178 || 0.326 seconds, mem : 41456\n",
      "\u001b[0m\u001b[41mEpisode 1726 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.178 || 0.304 seconds, mem : 41488\n",
      "\u001b[0m\u001b[41mEpisode 1728 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.177 || 0.280 seconds, mem : 41533\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1730/3023  57% ETA:  0:05:38 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1729 with 58 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.177 || 0.406 seconds, mem : 41591\n",
      "\u001b[0m\u001b[41mEpisode 1730 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.177 || 0.311 seconds, mem : 41621\n",
      "\u001b[0m\u001b[41mEpisode 1731 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.177 || 0.294 seconds, mem : 41652\n",
      "\u001b[0m\u001b[41mEpisode 1732 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.177 || 0.298 seconds, mem : 41681\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1734/3023  57% ETA:  0:05:37 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1733 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.176 || 0.381 seconds, mem : 41734\n",
      "\u001b[0m\u001b[41mEpisode 1734 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.176 || 0.312 seconds, mem : 41766\n",
      "\u001b[0m\u001b[41mEpisode 1735 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.176 || 0.293 seconds, mem : 41797\n",
      "\u001b[0m\u001b[44mEpisode 1736 with 54 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.176 || 0.355 seconds, mem : 41851\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1738/3023  57% ETA:  0:05:36 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1737 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.091 || Noise  0.176 || 0.272 seconds, mem : 41881\n",
      "\u001b[0m\u001b[44mEpisode 1738 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.091 || Noise  0.176 || 0.479 seconds, mem : 41945\n",
      "\u001b[0m\u001b[41mEpisode 1739 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.175 || 0.270 seconds, mem : 41976\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1741/3023  57% ETA:  0:05:35 ||||||||||||||||||||||                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1740 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.175 || 0.281 seconds, mem : 42009\n",
      "\u001b[0m\u001b[41mEpisode 1741 with 51 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.175 || 0.397 seconds, mem : 42060\n",
      "\u001b[0m\u001b[41mEpisode 1742 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.175 || 0.280 seconds, mem : 42091\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1744/3023  57% ETA:  0:05:35 |/////////////////////                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1743 with 63 steps || Reward : [0.1  0.08] || avg reward :  0.092 || Noise  0.175 || 0.420 seconds, mem : 42154\n",
      "\u001b[0m\u001b[41mEpisode 1744 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.092 || Noise  0.174 || 0.326 seconds, mem : 42187\n",
      "\u001b[0m\u001b[44mEpisode 1745 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.174 || 0.417 seconds, mem : 42252\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1747/3023  57% ETA:  0:05:34 |---------------------                 | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1746 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.092 || Noise  0.174 || 0.280 seconds, mem : 42283\n",
      "\u001b[0m\u001b[44mEpisode 1747 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.092 || Noise  0.174 || 0.436 seconds, mem : 42345\n",
      "\u001b[0m\u001b[41mEpisode 1748 with 33 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.174 || 0.281 seconds, mem : 42378\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1751/3023  57% ETA:  0:05:33 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1750 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.173 || 0.338 seconds, mem : 42424\n",
      "\u001b[0m\u001b[44mEpisode 1752 with 62 steps || Reward : [0.09 0.1 ] || avg reward :  0.090 || Noise  0.173 || 0.412 seconds, mem : 42499\n",
      "\u001b[0m\u001b[41mEpisode 1753 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.173 || 0.336 seconds, mem : 42530\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1755/3023  58% ETA:  0:05:32 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1754 with 32 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.173 || 0.300 seconds, mem : 42562\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1756 with 75 steps || Reward : [0.2  0.09] || avg reward :  0.090 || Noise  0.172 || 0.487 seconds, mem : 42651\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1758/3023  58% ETA:  0:05:32 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1757 with 54 steps || Reward : [0.09 0.1 ] || avg reward :  0.090 || Noise  0.172 || 0.397 seconds, mem : 42705\n",
      "\u001b[0m\u001b[41mEpisode 1760 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.172 || 0.302 seconds, mem : 42763\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1762/3023  58% ETA:  0:05:31 |----------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1761 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.172 || 0.290 seconds, mem : 42794\n",
      "\u001b[0m\u001b[44mEpisode 1763 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.087 || Noise  0.171 || 0.400 seconds, mem : 42860\n",
      "\u001b[0m\u001b[41mEpisode 1764 with 29 steps || Reward : [-0.01  0.1 ] || avg reward :  0.087 || Noise  0.171 || 0.300 seconds, mem : 42889\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1766/3023  58% ETA:  0:05:30 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1765 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.171 || 0.276 seconds, mem : 42920\n",
      "\u001b[0m\u001b[44mEpisode 1766 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.087 || Noise  0.171 || 0.419 seconds, mem : 42972\n",
      "\u001b[0m\u001b[41mEpisode 1767 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.171 || 0.295 seconds, mem : 43003\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1769/3023  58% ETA:  0:05:29 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1768 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.170 || 0.285 seconds, mem : 43034\n",
      "\u001b[0m\u001b[44mEpisode 1769 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.087 || Noise  0.170 || 0.418 seconds, mem : 43086\n",
      "\u001b[0m\u001b[41mEpisode 1770 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.170 || 0.281 seconds, mem : 43117\n",
      "\u001b[0m\u001b[41mEpisode 1771 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.170 || 0.283 seconds, mem : 43148\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1773/3023  58% ETA:  0:05:28 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1772 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.086 || Noise  0.170 || 0.394 seconds, mem : 43200\n",
      "\u001b[0m\u001b[41mEpisode 1773 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.170 || 0.306 seconds, mem : 43231\n",
      "\u001b[0m\u001b[41mEpisode 1774 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.169 || 0.273 seconds, mem : 43263\n",
      "\u001b[0m\u001b[41mEpisode 1775 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.169 || 0.299 seconds, mem : 43294\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1777/3023  58% ETA:  0:05:27 |----------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1776 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.169 || 0.278 seconds, mem : 43325\n",
      "\u001b[0m\u001b[41mEpisode 1777 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.086 || Noise  0.169 || 0.285 seconds, mem : 43355\n",
      "\u001b[0m\u001b[44mEpisode 1778 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.087 || Noise  0.169 || 0.409 seconds, mem : 43408\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1780/3023  58% ETA:  0:05:27 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1779 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.168 || 0.324 seconds, mem : 43440\n",
      "\u001b[0mEpisode 1780 with 13 steps || Reward : [ 0.   -0.01] || avg reward :  0.086 || Noise  0.168 || 0.219 seconds, mem : 43453\n",
      "\u001b[0m\u001b[41mEpisode 1781 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.168 || 0.274 seconds, mem : 43484\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1784/3023  59% ETA:  0:05:26 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1783 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.085 || Noise  0.168 || 0.282 seconds, mem : 43530\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1785 with 101 steps || Reward : [0.2  0.19] || avg reward :  0.087 || Noise  0.167 || 0.596 seconds, mem : 43644\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1787/3023  59% ETA:  0:05:25 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1786 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.087 || Noise  0.167 || 0.286 seconds, mem : 43676\n",
      "\u001b[0m\u001b[41mEpisode 1787 with 34 steps || Reward : [-0.01  0.1 ] || avg reward :  0.087 || Noise  0.167 || 0.293 seconds, mem : 43710\n",
      "\u001b[0m\u001b[44mEpisode 1788 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.088 || Noise  0.167 || 0.438 seconds, mem : 43778\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1790/3023  59% ETA:  0:05:24 |----------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1789 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.167 || 0.360 seconds, mem : 43830\n",
      "\u001b[0m\u001b[44mEpisode 1790 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.167 || 0.376 seconds, mem : 43882\n",
      "\u001b[0m\u001b[44mEpisode 1791 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.166 || 0.383 seconds, mem : 43935\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1793/3023  59% ETA:  0:05:24 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1792 with 61 steps || Reward : [0.2  0.09] || avg reward :  0.091 || Noise  0.166 || 0.418 seconds, mem : 43996\n",
      "\u001b[0m\u001b[41mEpisode 1793 with 31 steps || Reward : [0.   0.09] || avg reward :  0.091 || Noise  0.166 || 0.313 seconds, mem : 44027\n",
      "\u001b[0m\u001b[41mEpisode 1795 with 30 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.166 || 0.268 seconds, mem : 44071\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1798/3023  59% ETA:  0:05:23 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1797 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.165 || 0.372 seconds, mem : 44135\n",
      "\u001b[0m\u001b[41mEpisode 1798 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.165 || 0.299 seconds, mem : 44166\n",
      "\u001b[0m\u001b[44mEpisode 1799 with 43 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.165 || 0.317 seconds, mem : 44209\n",
      "\u001b[0m\u001b[41mEpisode 1800 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.165 || 0.335 seconds, mem : 44239\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1802/3023  59% ETA:  0:05:22 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1801 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.088 || Noise  0.165 || 0.446 seconds, mem : 44304\n",
      "\u001b[0m\u001b[44mEpisode 1802 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.088 || Noise  0.165 || 0.518 seconds, mem : 44369\n",
      "\u001b[0m\u001b[41mEpisode 1803 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.088 || Noise  0.164 || 0.321 seconds, mem : 44401\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1805/3023  59% ETA:  0:05:21 |----------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1804 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.089 || Noise  0.164 || 0.431 seconds, mem : 44465\n",
      "\u001b[0m\u001b[41mEpisode 1805 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.089 || Noise  0.164 || 0.315 seconds, mem : 44496\n",
      "\u001b[0m\u001b[41mEpisode 1806 with 50 steps || Reward : [0.   0.09] || avg reward :  0.090 || Noise  0.164 || 0.377 seconds, mem : 44546\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1808/3023  59% ETA:  0:05:21 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1807 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.164 || 0.487 seconds, mem : 44612\n",
      "\u001b[0m\u001b[41mEpisode 1808 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.164 || 0.304 seconds, mem : 44643\n",
      "\u001b[0m\u001b[41mEpisode 1809 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.090 || Noise  0.164 || 0.380 seconds, mem : 44695\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1811/3023  59% ETA:  0:05:20 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1810 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.163 || 0.342 seconds, mem : 44726\n",
      "\u001b[0m\u001b[41mEpisode 1811 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.163 || 0.324 seconds, mem : 44756\n",
      "\u001b[0m\u001b[41mEpisode 1812 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.163 || 0.310 seconds, mem : 44786\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1814/3023  60% ETA:  0:05:20 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1813 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.163 || 0.458 seconds, mem : 44851\n",
      "\u001b[0m\u001b[41mEpisode 1814 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.163 || 0.303 seconds, mem : 44882\n",
      "\u001b[0m\u001b[44mEpisode 1815 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.091 || Noise  0.163 || 0.416 seconds, mem : 44949\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1818/3023  60% ETA:  0:05:19 |----------------------                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1817 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.090 || Noise  0.162 || 0.278 seconds, mem : 44993\n",
      "\u001b[0m\u001b[44mEpisode 1818 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.090 || Noise  0.162 || 0.388 seconds, mem : 45048\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1819 with 72 steps || Reward : [0.2  0.09] || avg reward :  0.091 || Noise  0.162 || 0.465 seconds, mem : 45120\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1821/3023  60% ETA:  0:05:18 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1820 with 165 steps || Reward : [0.29       0.40000001] || avg reward :  0.094 || Noise  0.162 || 0.915 seconds, mem : 45285\n",
      "\u001b[0m\u001b[41mEpisode 1821 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.162 || 0.391 seconds, mem : 45337\n",
      "\u001b[0m\u001b[41mEpisode 1822 with 33 steps || Reward : [0.   0.09] || avg reward :  0.093 || Noise  0.161 || 0.302 seconds, mem : 45370\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1824/3023  60% ETA:  0:05:18 |||||||||||||||||||||||                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1823 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.161 || 0.400 seconds, mem : 45432\n",
      "\u001b[0m\u001b[41mEpisode 1824 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.093 || Noise  0.161 || 0.300 seconds, mem : 45464\n",
      "\u001b[0m\u001b[44mEpisode 1825 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.093 || Noise  0.161 || 0.432 seconds, mem : 45529\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1827/3023  60% ETA:  0:05:17 |//////////////////////                | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1826 with 61 steps || Reward : [0.09 0.1 ] || avg reward :  0.093 || Noise  0.161 || 0.445 seconds, mem : 45590\n",
      "\u001b[0m\u001b[41mEpisode 1827 with 30 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.161 || 0.281 seconds, mem : 45620\n",
      "\u001b[0m\u001b[44mEpisode 1828 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.160 || 0.396 seconds, mem : 45682\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1830/3023  60% ETA:  0:05:17 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1829 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.094 || Noise  0.160 || 0.390 seconds, mem : 45734\n",
      "\u001b[0m\u001b[44mEpisode 1830 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.094 || Noise  0.160 || 0.428 seconds, mem : 45798\n",
      "\u001b[0m\u001b[41mEpisode 1831 with 30 steps || Reward : [0.   0.09] || avg reward :  0.094 || Noise  0.160 || 0.307 seconds, mem : 45828\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1833/3023  60% ETA:  0:05:16 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1832 with 49 steps || Reward : [ 0.2  -0.01] || avg reward :  0.095 || Noise  0.160 || 0.400 seconds, mem : 45877\n",
      "\u001b[0m\u001b[44mEpisode 1833 with 52 steps || Reward : [0.09 0.1 ] || avg reward :  0.095 || Noise  0.160 || 0.373 seconds, mem : 45929\n",
      "\u001b[0m\u001b[41mEpisode 1834 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.095 || Noise  0.159 || 0.276 seconds, mem : 45959\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1836/3023  60% ETA:  0:05:15 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1835 with 64 steps || Reward : [ 0.2  -0.01] || avg reward :  0.096 || Noise  0.159 || 0.461 seconds, mem : 46023\n",
      "\u001b[0m\u001b[44mEpisode 1837 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.095 || Noise  0.159 || 0.430 seconds, mem : 46102\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1839/3023  60% ETA:  0:05:15 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1838 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.095 || Noise  0.159 || 0.415 seconds, mem : 46166\n",
      "\u001b[0m\u001b[41mEpisode 1839 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.095 || Noise  0.159 || 0.370 seconds, mem : 46214\n",
      "\u001b[0m\u001b[44mEpisode 1840 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.095 || Noise  0.159 || 0.431 seconds, mem : 46280\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1842/3023  60% ETA:  0:05:14 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1841 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.095 || Noise  0.158 || 0.443 seconds, mem : 46345\n",
      "\u001b[0m\u001b[41mEpisode 1842 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.158 || 0.387 seconds, mem : 46397\n",
      "\u001b[0m\u001b[44mEpisode 1843 with 71 steps || Reward : [0.09 0.1 ] || avg reward :  0.095 || Noise  0.158 || 0.432 seconds, mem : 46468\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1845/3023  61% ETA:  0:05:14 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1844 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.095 || Noise  0.158 || 0.295 seconds, mem : 46499\n",
      "\u001b[0m\u001b[41mEpisode 1845 with 31 steps || Reward : [0.   0.09] || avg reward :  0.095 || Noise  0.158 || 0.300 seconds, mem : 46530\n",
      "\u001b[0m\u001b[41mEpisode 1846 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.158 || 0.264 seconds, mem : 46561\n",
      "\u001b[0m\u001b[41mEpisode 1847 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.157 || 0.302 seconds, mem : 46591\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1849/3023  61% ETA:  0:05:13 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1848 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.095 || Noise  0.157 || 0.275 seconds, mem : 46623\n",
      "\u001b[0m\u001b[44mEpisode 1849 with 34 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.157 || 0.301 seconds, mem : 46657\n",
      "\u001b[0m\u001b[44mEpisode 1850 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.157 || 0.416 seconds, mem : 46721\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1852/3023  61% ETA:  0:05:12 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1851 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.157 || 0.281 seconds, mem : 46753\n",
      "\u001b[0m\u001b[41mEpisode 1852 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.157 || 0.288 seconds, mem : 46783\n",
      "\u001b[0m\u001b[44mEpisode 1853 with 75 steps || Reward : [0.1  0.09] || avg reward :  0.097 || Noise  0.156 || 0.502 seconds, mem : 46858\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1855/3023  61% ETA:  0:05:11 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1854 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.156 || 0.258 seconds, mem : 46888\n",
      "\u001b[0m\u001b[41mEpisode 1855 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.156 || 0.294 seconds, mem : 46920\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1856 with 109 steps || Reward : [0.2  0.19] || avg reward :  0.098 || Noise  0.156 || 0.594 seconds, mem : 47029\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1858/3023  61% ETA:  0:05:11 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1857 with 27 steps || Reward : [-0.01  0.1 ] || avg reward :  0.098 || Noise  0.156 || 0.265 seconds, mem : 47056\n",
      "\u001b[0m\u001b[41mEpisode 1858 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.156 || 0.288 seconds, mem : 47088\n",
      "\u001b[0m\u001b[41mEpisode 1860 with 53 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.155 || 0.368 seconds, mem : 47154\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1862/3023  61% ETA:  0:05:10 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1861 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.155 || 0.398 seconds, mem : 47217\n",
      "\u001b[0m\u001b[44mEpisode 1864 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.155 || 0.394 seconds, mem : 47305\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1866/3023  61% ETA:  0:05:09 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1865 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.155 || 0.421 seconds, mem : 47370\n",
      "\u001b[0m\u001b[41mEpisode 1866 with 45 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.154 || 0.351 seconds, mem : 47415\n",
      "\u001b[0m\u001b[41mEpisode 1867 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.154 || 0.362 seconds, mem : 47467\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1869/3023  61% ETA:  0:05:08 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1868 with 89 steps || Reward : [0.09 0.2 ] || avg reward :  0.099 || Noise  0.154 || 0.524 seconds, mem : 47556\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1869 with 65 steps || Reward : [0.2  0.09] || avg reward :  0.100 || Noise  0.154 || 0.423 seconds, mem : 47621\n",
      "\u001b[0m\u001b[44mEpisode 1870 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.100 || Noise  0.154 || 0.427 seconds, mem : 47686\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1872/3023  61% ETA:  0:05:08 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1871 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.154 || 0.295 seconds, mem : 47718\n",
      "\u001b[0m\u001b[44mEpisode 1872 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.154 || 0.404 seconds, mem : 47780\n",
      "\u001b[0m\u001b[44mEpisode 1873 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.100 || Noise  0.153 || 0.449 seconds, mem : 47845\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1875/3023  62% ETA:  0:05:07 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1874 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.153 || 0.368 seconds, mem : 47897\n",
      "\u001b[0m\u001b[41mEpisode 1875 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.153 || 0.265 seconds, mem : 47927\n",
      "\u001b[0m\u001b[41mEpisode 1877 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.153 || 0.286 seconds, mem : 47970\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1879/3023  62% ETA:  0:05:06 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1879 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.152 || 0.457 seconds, mem : 48047\n",
      "\u001b[0m\u001b[44mEpisode 1880 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.099 || Noise  0.152 || 0.429 seconds, mem : 48115\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1882/3023  62% ETA:  0:05:06 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1881 with 49 steps || Reward : [ 0.2  -0.01] || avg reward :  0.100 || Noise  0.152 || 0.362 seconds, mem : 48164\n",
      "\u001b[0m\u001b[41mEpisode 1882 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.152 || 0.415 seconds, mem : 48216\n",
      "\u001b[0m\u001b[41mEpisode 1883 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.152 || 0.397 seconds, mem : 48268\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1885/3023  62% ETA:  0:05:05 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1884 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.152 || 0.437 seconds, mem : 48335\n",
      "\u001b[0m\u001b[41mEpisode 1885 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.101 || Noise  0.152 || 0.309 seconds, mem : 48365\n",
      "\u001b[0m\u001b[44mEpisode 1886 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.151 || 0.413 seconds, mem : 48429\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1888/3023  62% ETA:  0:05:05 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1887 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.151 || 0.447 seconds, mem : 48493\n",
      "\u001b[0m\u001b[44mEpisode 1888 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.151 || 0.450 seconds, mem : 48555\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1891/3023  62% ETA:  0:05:04 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1890 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.151 || 0.447 seconds, mem : 48635\n",
      "\u001b[0m\u001b[44mEpisode 1892 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.150 || 0.436 seconds, mem : 48713\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1894/3023  62% ETA:  0:05:03 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1893 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.099 || Noise  0.150 || 0.528 seconds, mem : 48799\n",
      "\u001b[0m\u001b[41mEpisode 1894 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.150 || 0.298 seconds, mem : 48829\n",
      "\u001b[0m\u001b[41mEpisode 1895 with 30 steps || Reward : [0.   0.09] || avg reward :  0.100 || Noise  0.150 || 0.282 seconds, mem : 48859\n",
      "\u001b[0m\u001b[41mEpisode 1896 with 53 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.150 || 0.370 seconds, mem : 48912\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1898/3023  62% ETA:  0:05:02 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1897 with 29 steps || Reward : [0.   0.09] || avg reward :  0.101 || Noise  0.150 || 0.277 seconds, mem : 48941\n",
      "\u001b[0m\u001b[44mEpisode 1898 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.150 || 0.429 seconds, mem : 49006\n",
      "\u001b[0m\u001b[41mEpisode 1899 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.149 || 0.375 seconds, mem : 49057\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1901/3023  62% ETA:  0:05:02 ||||||||||||||||||||||||               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1900 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.149 || 0.426 seconds, mem : 49121\n",
      "\u001b[0m\u001b[41mEpisode 1901 with 29 steps || Reward : [0.   0.09] || avg reward :  0.101 || Noise  0.149 || 0.278 seconds, mem : 49150\n",
      "\u001b[0m\u001b[41mEpisode 1902 with 30 steps || Reward : [0.   0.09] || avg reward :  0.101 || Noise  0.149 || 0.306 seconds, mem : 49180\n",
      "\u001b[0m\u001b[41mEpisode 1903 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.149 || 0.303 seconds, mem : 49211\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1905/3023  63% ETA:  0:05:01 |///////////////////////               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1904 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.149 || 0.345 seconds, mem : 49262\n",
      "\u001b[0m\u001b[41mEpisode 1905 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.149 || 0.390 seconds, mem : 49294\n",
      "\u001b[0m\u001b[41mEpisode 1906 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.148 || 0.323 seconds, mem : 49324\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1908/3023  63% ETA:  0:05:00 |-----------------------               | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 1907 with 80 steps || Reward : [0.2  0.09] || avg reward :  0.102 || Noise  0.148 || 0.457 seconds, mem : 49404\n",
      "\u001b[0m\u001b[44mEpisode 1908 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.148 || 0.517 seconds, mem : 49467\n",
      "\u001b[0m\u001b[44mEpisode 1909 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.148 || 0.433 seconds, mem : 49531\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1911/3023  63% ETA:  0:05:00 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1910 with 30 steps || Reward : [0.   0.09] || avg reward :  0.102 || Noise  0.148 || 0.291 seconds, mem : 49561\n",
      "\u001b[0m\u001b[44mEpisode 1911 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.102 || Noise  0.148 || 0.438 seconds, mem : 49628\n",
      "\u001b[0m\u001b[41mEpisode 1912 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.102 || Noise  0.147 || 0.299 seconds, mem : 49658\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1914/3023  63% ETA:  0:04:59 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1913 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.102 || Noise  0.147 || 0.381 seconds, mem : 49710\n",
      "\u001b[0m\u001b[44mEpisode 1914 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.147 || 0.417 seconds, mem : 49773\n",
      "\u001b[0m\u001b[44mEpisode 1915 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.147 || 0.411 seconds, mem : 49838\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1917/3023  63% ETA:  0:04:58 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1916 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.103 || Noise  0.147 || 0.336 seconds, mem : 49868\n",
      "\u001b[0m\u001b[41mEpisode 1917 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.103 || Noise  0.147 || 0.393 seconds, mem : 49919\n",
      "\u001b[0m\u001b[41mEpisode 1918 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.103 || Noise  0.147 || 0.267 seconds, mem : 49950\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1920/3023  63% ETA:  0:04:58 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1919 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.146 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1920 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.146 || 0.292 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1921 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.146 || 0.256 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1922 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.146 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1924/3023  63% ETA:  0:04:57 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1923 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.146 || 0.267 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1924 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.146 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1925 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.146 || 0.444 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1927/3023  63% ETA:  0:04:56 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1926 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.099 || Noise  0.145 || 0.453 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1927 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.145 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1928 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.145 || 0.367 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1930/3023  63% ETA:  0:04:55 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1929 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.145 || 0.290 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1930 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.145 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1931 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.145 || 0.324 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1933/3023  63% ETA:  0:04:55 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1932 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.145 || 0.409 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1933 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.144 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1934 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.144 || 0.423 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1936/3023  64% ETA:  0:04:54 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1935 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.144 || 0.350 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1936 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.144 || 0.450 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1937 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.144 || 0.434 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1939/3023  64% ETA:  0:04:54 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1938 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.144 || 0.492 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1939 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.144 || 0.385 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1940 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.143 || 0.397 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1942/3023  64% ETA:  0:04:53 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1941 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.098 || Noise  0.143 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1942 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.143 || 0.419 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 1943 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.099 || Noise  0.143 || 0.560 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1945/3023  64% ETA:  0:04:52 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1944 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.143 || 0.313 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1945 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.143 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1946 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.143 || 0.374 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1947 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.142 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1949/3023  64% ETA:  0:04:52 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1948 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.142 || 0.411 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1949 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.142 || 0.460 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1950 with 29 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.142 || 0.267 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1952/3023  64% ETA:  0:04:51 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1951 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.142 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1952 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.142 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1953 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.142 || 0.256 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1955/3023  64% ETA:  0:04:50 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1954 with 71 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.141 || 0.457 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1955 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.141 || 0.376 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1956 with 57 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.141 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1958/3023  64% ETA:  0:04:50 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1957 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.141 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1958 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.141 || 0.422 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1959 with 55 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.141 || 0.374 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1961/3023  64% ETA:  0:04:49 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1960 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.141 || 0.287 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1961 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.140 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1962 with 53 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.140 || 0.355 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1963 with 30 steps || Reward : [0.   0.09] || avg reward :  0.101 || Noise  0.140 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1965/3023  65% ETA:  0:04:48 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1964 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.140 || 0.427 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1965 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.140 || 0.444 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1966 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.140 || 0.422 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1968/3023  65% ETA:  0:04:47 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1967 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.140 || 0.263 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1968 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.139 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1969 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.139 || 0.436 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1971/3023  65% ETA:  0:04:47 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1970 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.139 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1971 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.139 || 0.311 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1973 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.139 || 0.404 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1975/3023  65% ETA:  0:04:46 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1974 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.139 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1975 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.138 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1976 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.138 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1979/3023  65% ETA:  0:04:45 |||||||||||||||||||||||||              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1979 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.138 || 0.270 seconds, mem : 50000\n",
      "\u001b[0mEpisode 1980 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.097 || Noise  0.138 || 0.195 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1981 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.138 || 0.452 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1983/3023  65% ETA:  0:04:43 |////////////////////////              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1982 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.096 || Noise  0.138 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1983 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.096 || Noise  0.137 || 0.287 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1984 with 29 steps || Reward : [0.   0.09] || avg reward :  0.096 || Noise  0.137 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1986/3023  65% ETA:  0:04:43 |------------------------              | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1985 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.096 || Noise  0.137 || 0.432 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1986 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.137 || 0.437 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1987 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.137 || 0.469 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1989/3023  65% ETA:  0:04:42 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1988 with 70 steps || Reward : [0.1  0.09] || avg reward :  0.096 || Noise  0.137 || 0.425 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1989 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.137 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1990 with 30 steps || Reward : [0.   0.09] || avg reward :  0.097 || Noise  0.136 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1992/3023  65% ETA:  0:04:42 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1991 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.136 || 0.413 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1992 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.098 || Noise  0.136 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1993 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.136 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1994 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.136 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1996/3023  66% ETA:  0:04:41 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 1995 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.097 || Noise  0.136 || 0.393 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1996 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.136 || 0.383 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 1997 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.097 || Noise  0.135 || 0.479 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 1999/3023  66% ETA:  0:04:40 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 1998 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.097 || Noise  0.135 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 1999 with 57 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.135 || 0.391 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2000 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.135 || 0.368 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2002/3023  66% ETA:  0:04:39 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2001 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.135 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2002 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.097 || Noise  0.135 || 0.283 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2003 with 87 steps || Reward : [0.09 0.2 ] || avg reward :  0.098 || Noise  0.135 || 0.517 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2005/3023  66% ETA:  0:04:39 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2004 with 57 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.135 || 0.382 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2005 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.134 || 0.461 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2006 with 88 steps || Reward : [0.09 0.2 ] || avg reward :  0.099 || Noise  0.134 || 0.504 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2008/3023  66% ETA:  0:04:38 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2007 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.134 || 0.438 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2008 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.098 || Noise  0.134 || 0.496 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2009 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.134 || 0.320 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2011/3023  66% ETA:  0:04:37 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2010 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.098 || Noise  0.134 || 0.344 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2011 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.098 || Noise  0.134 || 0.507 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2012 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.098 || Noise  0.133 || 0.377 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2014/3023  66% ETA:  0:04:37 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2013 with 71 steps || Reward : [0.2  0.09] || avg reward :  0.099 || Noise  0.133 || 0.486 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2014 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.133 || 0.428 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2015 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.133 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2017/3023  66% ETA:  0:04:36 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2016 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.099 || Noise  0.133 || 0.349 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2017 with 31 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.133 || 0.283 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2018 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.133 || 0.468 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2020/3023  66% ETA:  0:04:36 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2019 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.133 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2020 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.099 || Noise  0.132 || 0.521 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2021 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.132 || 0.375 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2023/3023  66% ETA:  0:04:35 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2022 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.132 || 0.256 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2023 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.099 || Noise  0.132 || 0.459 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2024 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.132 || 0.272 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2026/3023  67% ETA:  0:04:34 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2025 with 50 steps || Reward : [ 0.1  -0.01] || avg reward :  0.099 || Noise  0.132 || 0.354 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2026 with 30 steps || Reward : [0.   0.09] || avg reward :  0.099 || Noise  0.132 || 0.291 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2027 with 91 steps || Reward : [0.09 0.2 ] || avg reward :  0.100 || Noise  0.131 || 0.516 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2029/3023  67% ETA:  0:04:33 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2028 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.131 || 0.311 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2029 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.131 || 0.518 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2031/3023  67% ETA:  0:04:33 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2030 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.100 || Noise  0.131 || 0.529 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2031 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.131 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2032 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.131 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2034/3023  67% ETA:  0:04:32 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2033 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.131 || 0.335 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2034 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.131 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2035 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.130 || 0.332 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2037/3023  67% ETA:  0:04:32 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2036 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.130 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2037 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.130 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2038 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.130 || 0.353 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2040/3023  67% ETA:  0:04:31 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2039 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.130 || 0.445 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2040 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.130 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2041 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.130 || 0.253 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2043/3023  67% ETA:  0:04:30 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2042 with 126 steps || Reward : [0.19 0.3 ] || avg reward :  0.102 || Noise  0.130 || 0.699 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2043 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.129 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2044 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.101 || Noise  0.129 || 0.369 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2046/3023  67% ETA:  0:04:30 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2045 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.101 || Noise  0.129 || 0.410 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2046 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.101 || Noise  0.129 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2047 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.101 || Noise  0.129 || 0.432 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2049/3023  67% ETA:  0:04:29 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2049 with 85 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.129 || 0.586 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2050 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.128 || 0.410 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2052/3023  67% ETA:  0:04:28 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2051 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.128 || 0.260 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2052 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.100 || Noise  0.128 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2053 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.128 || 0.455 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2055/3023  67% ETA:  0:04:28 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2054 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.128 || 0.360 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2055 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.128 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2056 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.100 || Noise  0.128 || 0.427 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2058/3023  68% ETA:  0:04:27 |-------------------------             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2057 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.128 || 0.287 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2058 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.127 || 0.304 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2059 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.127 || 0.362 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2060 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.127 || 0.267 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2062/3023  68% ETA:  0:04:26 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2061 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.127 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2062 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.100 || Noise  0.127 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2063 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.127 || 0.425 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2065/3023  68% ETA:  0:04:25 ||||||||||||||||||||||||||             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2064 with 95 steps || Reward : [0.09 0.1 ] || avg reward :  0.100 || Noise  0.127 || 0.552 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2065 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.127 || 0.416 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2066 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.100 || Noise  0.126 || 0.424 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2068/3023  68% ETA:  0:04:25 |/////////////////////////             | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2067 with 87 steps || Reward : [0.09 0.2 ] || avg reward :  0.101 || Noise  0.126 || 0.516 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2068 with 89 steps || Reward : [0.09 0.2 ] || avg reward :  0.102 || Noise  0.126 || 0.630 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2069 with 30 steps || Reward : [0.   0.09] || avg reward :  0.102 || Noise  0.126 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2071/3023  68% ETA:  0:04:24 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2070 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.126 || 0.504 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2071 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.102 || Noise  0.126 || 0.445 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2072 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.103 || Noise  0.126 || 0.506 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2074/3023  68% ETA:  0:04:24 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2073 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.103 || Noise  0.126 || 0.481 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2074 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.103 || Noise  0.125 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2075 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.103 || Noise  0.125 || 0.276 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2077/3023  68% ETA:  0:04:23 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2076 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.103 || Noise  0.125 || 0.363 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2077 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.104 || Noise  0.125 || 0.483 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2079/3023  68% ETA:  0:04:23 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2078 with 130 steps || Reward : [0.19 0.3 ] || avg reward :  0.107 || Noise  0.125 || 0.729 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2079 with 72 steps || Reward : [0.1  0.09] || avg reward :  0.107 || Noise  0.125 || 0.490 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2080 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.108 || Noise  0.125 || 0.436 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2082/3023  68% ETA:  0:04:22 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2081 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.108 || Noise  0.125 || 0.290 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2082 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.108 || Noise  0.124 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2083 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.108 || Noise  0.124 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2085/3023  68% ETA:  0:04:21 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2084 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.108 || Noise  0.124 || 0.355 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2085 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.108 || Noise  0.124 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2086 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.108 || Noise  0.124 || 0.283 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2088/3023  69% ETA:  0:04:21 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2087 with 109 steps || Reward : [0.2  0.19] || avg reward :  0.109 || Noise  0.124 || 0.634 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2088 with 156 steps || Reward : [0.3  0.29] || avg reward :  0.111 || Noise  0.124 || 0.843 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2090/3023  69% ETA:  0:04:20 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2089 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.111 || Noise  0.124 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2090 with 79 steps || Reward : [0.1  0.09] || avg reward :  0.112 || Noise  0.123 || 0.547 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2092/3023  69% ETA:  0:04:20 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2091 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.112 || Noise  0.123 || 0.450 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2092 with 94 steps || Reward : [0.09 0.2 ] || avg reward :  0.113 || Noise  0.123 || 0.584 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2093 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.123 || 0.361 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2095/3023  69% ETA:  0:04:19 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2094 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.123 || 0.441 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2095 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.123 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2096 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.123 || 0.413 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2098/3023  69% ETA:  0:04:19 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2097 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.123 || 0.416 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2098 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.122 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2099 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.122 || 0.419 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2101/3023  69% ETA:  0:04:18 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2100 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.122 || 0.375 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2101 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.122 || 0.350 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2102 with 60 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.122 || 0.404 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2104/3023  69% ETA:  0:04:17 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2103 with 61 steps || Reward : [0.   0.19] || avg reward :  0.112 || Noise  0.122 || 0.413 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2104 with 30 steps || Reward : [0.   0.09] || avg reward :  0.112 || Noise  0.122 || 0.293 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2105 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.112 || Noise  0.122 || 0.285 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2106 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.111 || Noise  0.121 || 0.372 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2108/3023  69% ETA:  0:04:16 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2107 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.111 || Noise  0.121 || 0.421 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2108 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.111 || Noise  0.121 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2109 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.111 || Noise  0.121 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2110 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.111 || Noise  0.121 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2112/3023  69% ETA:  0:04:15 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2111 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.111 || Noise  0.121 || 0.440 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2112 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.111 || Noise  0.121 || 0.424 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2114/3023  69% ETA:  0:04:15 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2113 with 107 steps || Reward : [0.2  0.19] || avg reward :  0.111 || Noise  0.121 || 0.612 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2114 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.111 || Noise  0.121 || 0.432 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2115 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.111 || Noise  0.120 || 0.348 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2117/3023  70% ETA:  0:04:14 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2116 with 127 steps || Reward : [0.19 0.3 ] || avg reward :  0.113 || Noise  0.120 || 0.728 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2117 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.120 || 0.373 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2118 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.120 || 0.378 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2120/3023  70% ETA:  0:04:14 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2119 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.120 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2120 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.120 || 0.448 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2121 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.120 || 0.420 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2123/3023  70% ETA:  0:04:13 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2122 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.114 || Noise  0.120 || 0.446 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2123 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.114 || Noise  0.119 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2124 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.114 || Noise  0.119 || 0.416 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2126/3023  70% ETA:  0:04:12 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2125 with 66 steps || Reward : [0.2  0.09] || avg reward :  0.115 || Noise  0.119 || 0.443 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2126 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.115 || Noise  0.119 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2129/3023  70% ETA:  0:04:12 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2128 with 30 steps || Reward : [0.   0.09] || avg reward :  0.113 || Noise  0.119 || 0.269 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2129 with 111 steps || Reward : [0.3  0.19] || avg reward :  0.115 || Noise  0.119 || 0.635 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2131/3023  70% ETA:  0:04:11 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2130 with 72 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.119 || 0.485 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2131 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.118 || 0.422 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2132 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.118 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2134/3023  70% ETA:  0:04:11 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2133 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.115 || Noise  0.118 || 0.443 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2134 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.115 || Noise  0.118 || 0.497 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2136/3023  70% ETA:  0:04:10 |//////////////////////////            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2135 with 107 steps || Reward : [0.3  0.19] || avg reward :  0.117 || Noise  0.118 || 0.600 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2136 with 30 steps || Reward : [0.   0.09] || avg reward :  0.117 || Noise  0.118 || 0.479 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2137 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.117 || Noise  0.118 || 0.438 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2139/3023  70% ETA:  0:04:10 |--------------------------            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2138 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.117 || Noise  0.118 || 0.530 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2139 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.117 || Noise  0.118 || 0.444 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2140 with 30 steps || Reward : [0.   0.09] || avg reward :  0.116 || Noise  0.117 || 0.315 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2142/3023  70% ETA:  0:04:09 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2141 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.116 || Noise  0.117 || 0.449 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2142 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.114 || Noise  0.117 || 0.285 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2143 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.114 || Noise  0.117 || 0.436 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2145/3023  70% ETA:  0:04:08 |||||||||||||||||||||||||||            | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2144 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.114 || Noise  0.117 || 0.449 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2145 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.114 || Noise  0.117 || 0.389 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2146 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.114 || Noise  0.117 || 0.449 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2148/3023  71% ETA:  0:04:08 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2147 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.114 || Noise  0.117 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2148 with 30 steps || Reward : [0.   0.09] || avg reward :  0.115 || Noise  0.116 || 0.333 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2149 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.116 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2151/3023  71% ETA:  0:04:07 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2150 with 19 steps || Reward : [0.09 0.  ] || avg reward :  0.115 || Noise  0.116 || 0.247 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2151 with 38 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.116 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2152 with 74 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.116 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2154/3023  71% ETA:  0:04:06 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2153 with 103 steps || Reward : [0.2  0.19] || avg reward :  0.116 || Noise  0.116 || 0.623 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2154 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.116 || 0.355 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2155 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.116 || Noise  0.116 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2156 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.116 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2158/3023  71% ETA:  0:04:05 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2157 with 30 steps || Reward : [0.   0.09] || avg reward :  0.116 || Noise  0.115 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2158 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.116 || Noise  0.115 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2159 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.116 || Noise  0.115 || 0.295 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2161/3023  71% ETA:  0:04:04 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2160 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.116 || Noise  0.115 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2161 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.116 || Noise  0.115 || 0.489 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2162 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.116 || Noise  0.115 || 0.440 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2164/3023  71% ETA:  0:04:04 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2163 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.115 || 0.377 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2164 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.116 || Noise  0.115 || 0.322 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2165 with 30 steps || Reward : [0.   0.09] || avg reward :  0.116 || Noise  0.115 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2166 with 30 steps || Reward : [0.   0.09] || avg reward :  0.116 || Noise  0.114 || 0.285 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2168/3023  71% ETA:  0:04:03 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2167 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.115 || Noise  0.114 || 0.315 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2168 with 63 steps || Reward : [0.1  0.09] || avg reward :  0.114 || Noise  0.114 || 0.436 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2169 with 78 steps || Reward : [0.2  0.09] || avg reward :  0.115 || Noise  0.114 || 0.490 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2171/3023  71% ETA:  0:04:02 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2170 with 56 steps || Reward : [0.09 0.1 ] || avg reward :  0.115 || Noise  0.114 || 0.397 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2171 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.114 || 0.457 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2172 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.115 || Noise  0.114 || 0.443 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2174/3023  71% ETA:  0:04:01 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2173 with 30 steps || Reward : [0.   0.09] || avg reward :  0.115 || Noise  0.114 || 0.262 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2174 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.115 || Noise  0.113 || 0.311 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2175 with 30 steps || Reward : [0.   0.09] || avg reward :  0.115 || Noise  0.113 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2176 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.115 || Noise  0.113 || 0.332 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2178/3023  72% ETA:  0:04:00 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2177 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.115 || Noise  0.113 || 0.439 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2178 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.113 || 0.442 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2179 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.113 || 0.434 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2181/3023  72% ETA:  0:03:59 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2180 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.113 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2181 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.113 || 0.292 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2183/3023  72% ETA:  0:03:59 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2182 with 173 steps || Reward : [0.40000001 0.39000001] || avg reward :  0.116 || Noise  0.113 || 0.883 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2183 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.112 || 0.276 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2184 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.116 || Noise  0.112 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2186/3023  72% ETA:  0:03:58 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2185 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.112 || 0.269 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2186 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.116 || Noise  0.112 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2187 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.115 || Noise  0.112 || 0.357 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2189/3023  72% ETA:  0:03:58 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2188 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.112 || 0.524 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2189 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.112 || 0.391 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2190 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.112 || 0.438 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2192/3023  72% ETA:  0:03:57 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2191 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.112 || 0.270 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2192 with 84 steps || Reward : [0.2  0.09] || avg reward :  0.113 || Noise  0.111 || 0.535 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2193 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.111 || 0.279 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2195/3023  72% ETA:  0:03:56 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2194 with 47 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.111 || 0.350 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2195 with 30 steps || Reward : [0.   0.09] || avg reward :  0.113 || Noise  0.111 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2196 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.111 || 0.277 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2198/3023  72% ETA:  0:03:55 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2197 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.111 || 0.428 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2198 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.111 || 0.463 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2199 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.111 || 0.265 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2201/3023  72% ETA:  0:03:54 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2200 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.111 || 0.428 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2201 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.110 || 0.320 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2202 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.110 || 0.401 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2204/3023  72% ETA:  0:03:54 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2203 with 79 steps || Reward : [0.1  0.19] || avg reward :  0.113 || Noise  0.110 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2204 with 53 steps || Reward : [ 0.1  -0.01] || avg reward :  0.113 || Noise  0.110 || 0.373 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2205 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.110 || 0.434 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2207/3023  73% ETA:  0:03:53 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2206 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.113 || Noise  0.110 || 0.439 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2207 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.110 || 0.443 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2208 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.113 || Noise  0.110 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2210/3023  73% ETA:  0:03:52 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2209 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.110 || 0.266 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2210 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.113 || Noise  0.109 || 0.317 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2212/3023  73% ETA:  0:03:52 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2211 with 497 steps || Reward : [1.30000002 1.19000002] || avg reward :  0.125 || Noise  0.109 || 2.283 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2212 with 50 steps || Reward : [ 0.1  -0.01] || avg reward :  0.125 || Noise  0.109 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2214/3023  73% ETA:  0:03:52 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2213 with 318 steps || Reward : [0.70000001 0.69000001] || avg reward :  0.130 || Noise  0.109 || 1.470 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2214 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.130 || Noise  0.109 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2215 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.130 || Noise  0.109 || 0.434 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2217/3023  73% ETA:  0:03:52 ||||||||||||||||||||||||||||           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2216 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.128 || Noise  0.109 || 0.453 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2217 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.109 || 0.283 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2218 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.128 || Noise  0.109 || 0.290 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2219 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.108 || 0.278 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2221/3023  73% ETA:  0:03:50 |///////////////////////////           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2220 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.108 || 0.292 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2221 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.108 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2222 with 47 steps || Reward : [-0.01  0.1 ] || avg reward :  0.128 || Noise  0.108 || 0.366 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2224/3023  73% ETA:  0:03:50 |---------------------------           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2223 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.128 || Noise  0.108 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2224 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.128 || Noise  0.108 || 0.486 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2225 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.127 || Noise  0.108 || 0.313 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2227/3023  73% ETA:  0:03:49 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\           | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2226 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.127 || Noise  0.108 || 0.287 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2227 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.128 || Noise  0.108 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2228 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.108 || 0.295 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2230/3023  73% ETA:  0:03:48 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2229 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.126 || Noise  0.107 || 0.384 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2232/3023  73% ETA:  0:03:48 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2231 with 424 steps || Reward : [1.00000001 0.99000002] || avg reward :  0.134 || Noise  0.107 || 2.047 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2232 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.134 || Noise  0.107 || 0.464 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2233 with 39 steps || Reward : [ 0.1  -0.01] || avg reward :  0.134 || Noise  0.107 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2235/3023  73% ETA:  0:03:47 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2234 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.134 || Noise  0.107 || 0.273 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2235 with 34 steps || Reward : [-0.01  0.1 ] || avg reward :  0.132 || Noise  0.107 || 0.321 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2236 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.132 || Noise  0.107 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2238/3023  74% ETA:  0:03:47 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2237 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.132 || Noise  0.107 || 0.495 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2238 with 61 steps || Reward : [0.09 0.1 ] || avg reward :  0.132 || Noise  0.106 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2239 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.132 || Noise  0.106 || 0.317 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2241/3023  74% ETA:  0:03:46 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2240 with 30 steps || Reward : [0.   0.09] || avg reward :  0.132 || Noise  0.106 || 0.266 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2241 with 91 steps || Reward : [0.2  0.09] || avg reward :  0.133 || Noise  0.106 || 0.547 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2242 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.133 || Noise  0.106 || 0.446 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2244/3023  74% ETA:  0:03:45 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2243 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.133 || Noise  0.106 || 0.466 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2244 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.133 || Noise  0.106 || 0.466 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2246/3023  74% ETA:  0:03:45 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2245 with 116 steps || Reward : [0.2  0.29] || avg reward :  0.135 || Noise  0.106 || 0.643 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2246 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.135 || Noise  0.106 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2247 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.135 || Noise  0.105 || 0.329 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2249/3023  74% ETA:  0:03:44 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2248 with 86 steps || Reward : [0.09 0.2 ] || avg reward :  0.136 || Noise  0.105 || 0.555 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2249 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.136 || Noise  0.105 || 0.480 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2251/3023  74% ETA:  0:03:44 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2250 with 108 steps || Reward : [0.1  0.19] || avg reward :  0.137 || Noise  0.105 || 0.619 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2251 with 93 steps || Reward : [0.2  0.09] || avg reward :  0.138 || Noise  0.105 || 0.593 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2252 with 30 steps || Reward : [0.   0.09] || avg reward :  0.138 || Noise  0.105 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2254/3023  74% ETA:  0:03:43 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2253 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.137 || Noise  0.105 || 0.331 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2255/3023  74% ETA:  0:03:43 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2254 with 283 steps || Reward : [0.60000001 0.59000001] || avg reward :  0.142 || Noise  0.105 || 1.345 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2255 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.143 || Noise  0.105 || 0.553 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2256 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.143 || Noise  0.105 || 0.427 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2258/3023  74% ETA:  0:03:42 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2257 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.143 || Noise  0.104 || 0.320 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2258 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.143 || Noise  0.104 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2259 with 30 steps || Reward : [0.   0.09] || avg reward :  0.143 || Noise  0.104 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2261/3023  74% ETA:  0:03:42 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2260 with 221 steps || Reward : [0.50000001 0.49000001] || avg reward :  0.147 || Noise  0.104 || 1.095 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2261 with 104 steps || Reward : [0.2  0.19] || avg reward :  0.148 || Noise  0.104 || 0.614 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2263/3023  74% ETA:  0:03:41 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2262 with 70 steps || Reward : [0.2  0.09] || avg reward :  0.149 || Noise  0.104 || 0.486 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2263 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.149 || Noise  0.104 || 0.429 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2264 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.149 || Noise  0.104 || 0.459 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2266/3023  74% ETA:  0:03:40 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2265 with 60 steps || Reward : [0.1  0.09] || avg reward :  0.149 || Noise  0.104 || 0.386 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2266 with 30 steps || Reward : [0.   0.09] || avg reward :  0.149 || Noise  0.104 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2267 with 29 steps || Reward : [0.   0.09] || avg reward :  0.149 || Noise  0.103 || 0.289 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2268 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.149 || Noise  0.103 || 0.355 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2270/3023  75% ETA:  0:03:39 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2269 with 30 steps || Reward : [0.   0.09] || avg reward :  0.148 || Noise  0.103 || 0.273 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2270 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.148 || Noise  0.103 || 0.411 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2271 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.148 || Noise  0.103 || 0.408 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2273/3023  75% ETA:  0:03:39 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2272 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.148 || Noise  0.103 || 0.273 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2273 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.148 || Noise  0.103 || 0.348 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2274 with 95 steps || Reward : [0.09 0.2 ] || avg reward :  0.149 || Noise  0.103 || 0.539 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2276/3023  75% ETA:  0:03:38 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2275 with 99 steps || Reward : [0.2  0.19] || avg reward :  0.150 || Noise  0.103 || 0.596 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2276 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.150 || Noise  0.102 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2278/3023  75% ETA:  0:03:37 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2277 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.151 || Noise  0.102 || 0.571 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2278 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.151 || Noise  0.102 || 0.510 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2279 with 30 steps || Reward : [0.   0.09] || avg reward :  0.151 || Noise  0.102 || 0.376 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2281/3023  75% ETA:  0:03:37 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2280 with 29 steps || Reward : [0.   0.09] || avg reward :  0.151 || Noise  0.102 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2281 with 30 steps || Reward : [0.   0.09] || avg reward :  0.151 || Noise  0.102 || 0.313 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2282 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.148 || Noise  0.102 || 0.385 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2283 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.148 || Noise  0.102 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2285/3023  75% ETA:  0:03:35 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2284 with 46 steps || Reward : [-0.01  0.1 ] || avg reward :  0.148 || Noise  0.102 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2285 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.148 || Noise  0.102 || 0.400 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2286 with 67 steps || Reward : [0.2  0.09] || avg reward :  0.149 || Noise  0.101 || 0.414 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2288/3023  75% ETA:  0:03:35 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2287 with 96 steps || Reward : [0.19 0.2 ] || avg reward :  0.150 || Noise  0.101 || 0.614 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2288 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.150 || Noise  0.101 || 0.447 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2289 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.150 || Noise  0.101 || 0.446 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2291/3023  75% ETA:  0:03:34 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2290 with 67 steps || Reward : [0.09 0.1 ] || avg reward :  0.150 || Noise  0.101 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2291 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.150 || Noise  0.101 || 0.286 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2292 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.150 || Noise  0.101 || 0.629 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2294/3023  75% ETA:  0:03:33 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2293 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.150 || Noise  0.101 || 0.274 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2294 with 92 steps || Reward : [0.09 0.2 ] || avg reward :  0.151 || Noise  0.101 || 0.566 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2295 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.101 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2297/3023  75% ETA:  0:03:33 |||||||||||||||||||||||||||||          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2296 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.100 || 0.357 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2297 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.100 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2298 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.100 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2299 with 30 steps || Reward : [0.   0.09] || avg reward :  0.151 || Noise  0.100 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2301/3023  76% ETA:  0:03:31 |////////////////////////////          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2300 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.100 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2301 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.100 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2302 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.151 || Noise  0.100 || 0.360 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2304/3023  76% ETA:  0:03:31 |----------------------------          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2303 with 106 steps || Reward : [0.2  0.19] || avg reward :  0.151 || Noise  0.100 || 0.625 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2304 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.151 || Noise  0.100 || 0.421 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2306/3023  76% ETA:  0:03:30 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\          | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2305 with 108 steps || Reward : [0.2  0.19] || avg reward :  0.152 || Noise  0.100 || 0.665 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2306 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.152 || Noise  0.099 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2307 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.152 || Noise  0.099 || 0.447 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2309/3023  76% ETA:  0:03:29 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2308 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.152 || Noise  0.099 || 0.282 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2309 with 139 steps || Reward : [0.2  0.19] || avg reward :  0.153 || Noise  0.099 || 0.882 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2311/3023  76% ETA:  0:03:29 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2310 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.153 || Noise  0.099 || 0.448 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2311 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.141 || Noise  0.099 || 0.350 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2312 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.141 || Noise  0.099 || 0.392 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2314/3023  76% ETA:  0:03:28 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2313 with 36 steps || Reward : [0.1  0.09] || avg reward :  0.135 || Noise  0.099 || 0.292 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2314 with 54 steps || Reward : [0.1  0.09] || avg reward :  0.135 || Noise  0.099 || 0.420 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2315 with 76 steps || Reward : [0.2  0.09] || avg reward :  0.136 || Noise  0.099 || 0.470 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2317/3023  76% ETA:  0:03:27 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2316 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.136 || Noise  0.098 || 0.387 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2317 with 30 steps || Reward : [0.   0.09] || avg reward :  0.136 || Noise  0.098 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2318 with 88 steps || Reward : [0.1  0.09] || avg reward :  0.136 || Noise  0.098 || 0.508 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2320/3023  76% ETA:  0:03:27 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2319 with 124 steps || Reward : [0.3  0.19] || avg reward :  0.138 || Noise  0.098 || 0.742 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2320 with 30 steps || Reward : [0.   0.09] || avg reward :  0.138 || Noise  0.098 || 0.343 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2321 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.098 || 0.411 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2323/3023  76% ETA:  0:03:26 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2322 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.138 || Noise  0.098 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2323 with 30 steps || Reward : [0.   0.09] || avg reward :  0.137 || Noise  0.098 || 0.304 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2324 with 29 steps || Reward : [0.   0.09] || avg reward :  0.137 || Noise  0.098 || 0.304 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2326/3023  76% ETA:  0:03:25 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2325 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.137 || Noise  0.098 || 0.460 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2326 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.137 || Noise  0.097 || 0.473 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2327 with 30 steps || Reward : [0.   0.09] || avg reward :  0.137 || Noise  0.097 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2329/3023  77% ETA:  0:03:24 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2328 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.137 || Noise  0.097 || 0.425 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2329 with 69 steps || Reward : [0.1  0.08] || avg reward :  0.137 || Noise  0.097 || 0.490 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2330 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.138 || Noise  0.097 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2332/3023  77% ETA:  0:03:23 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2331 with 30 steps || Reward : [0.   0.09] || avg reward :  0.129 || Noise  0.097 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2332 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.129 || Noise  0.097 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2333 with 29 steps || Reward : [0.   0.09] || avg reward :  0.129 || Noise  0.097 || 0.276 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2336/3023  77% ETA:  0:03:22 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2335 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.128 || Noise  0.097 || 0.456 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2336 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.097 || 0.282 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2338/3023  77% ETA:  0:03:22 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2337 with 155 steps || Reward : [0.29 0.3 ] || avg reward :  0.130 || Noise  0.096 || 0.812 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2338 with 124 steps || Reward : [0.19 0.2 ] || avg reward :  0.131 || Noise  0.096 || 0.707 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2340/3023  77% ETA:  0:03:21 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2339 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.131 || Noise  0.096 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2340 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.131 || Noise  0.096 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2341 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.130 || Noise  0.096 || 0.276 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2344/3023  77% ETA:  0:03:20 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2343 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.129 || Noise  0.096 || 0.262 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2344 with 30 steps || Reward : [0.   0.09] || avg reward :  0.129 || Noise  0.096 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2345 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.127 || Noise  0.096 || 0.220 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2346 with 84 steps || Reward : [0.1  0.19] || avg reward :  0.128 || Noise  0.096 || 0.387 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2348/3023  77% ETA:  0:03:19 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2347 with 132 steps || Reward : [0.3  0.29] || avg reward :  0.130 || Noise  0.095 || 0.807 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2348 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.129 || Noise  0.095 || 0.445 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2350/3023  77% ETA:  0:03:19 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2349 with 103 steps || Reward : [0.19 0.2 ] || avg reward :  0.130 || Noise  0.095 || 0.589 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2350 with 85 steps || Reward : [0.09 0.2 ] || avg reward :  0.130 || Noise  0.095 || 0.526 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2351 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.129 || Noise  0.095 || 0.428 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2353/3023  77% ETA:  0:03:18 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2352 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.129 || Noise  0.095 || 0.267 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2353 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.129 || Noise  0.095 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2354 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.124 || Noise  0.095 || 0.272 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2355 with 55 steps || Reward : [0.09 0.1 ] || avg reward :  0.123 || Noise  0.095 || 0.372 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2357/3023  77% ETA:  0:03:17 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2356 with 134 steps || Reward : [0.2  0.29] || avg reward :  0.125 || Noise  0.095 || 0.851 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2357 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.125 || Noise  0.094 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2358 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.125 || Noise  0.094 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2359 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.125 || Noise  0.094 || 0.285 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2361/3023  78% ETA:  0:03:16 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2360 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.121 || Noise  0.094 || 0.270 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2361 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.120 || Noise  0.094 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2362 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.119 || Noise  0.094 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2364/3023  78% ETA:  0:03:15 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2363 with 72 steps || Reward : [0.2  0.09] || avg reward :  0.120 || Noise  0.094 || 0.483 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2364 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.120 || Noise  0.094 || 0.368 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2366/3023  78% ETA:  0:03:15 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2365 with 247 steps || Reward : [0.49000001 0.60000001] || avg reward :  0.125 || Noise  0.094 || 1.252 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2366 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.125 || Noise  0.094 || 0.476 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2367 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.126 || Noise  0.094 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2369/3023  78% ETA:  0:03:14 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2368 with 85 steps || Reward : [0.09 0.2 ] || avg reward :  0.127 || Noise  0.093 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2369 with 40 steps || Reward : [0.1  0.09] || avg reward :  0.127 || Noise  0.093 || 0.337 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2370 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.127 || Noise  0.093 || 0.416 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2372/3023  78% ETA:  0:03:13 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2371 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.127 || Noise  0.093 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2372 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.127 || Noise  0.093 || 0.287 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2373 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.127 || Noise  0.093 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2375/3023  78% ETA:  0:03:12 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2374 with 45 steps || Reward : [-0.01  0.1 ] || avg reward :  0.126 || Noise  0.093 || 0.347 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2375 with 102 steps || Reward : [0.2  0.19] || avg reward :  0.126 || Noise  0.093 || 0.568 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2377/3023  78% ETA:  0:03:12 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2376 with 103 steps || Reward : [0.2  0.19] || avg reward :  0.127 || Noise  0.093 || 0.563 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2377 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.126 || Noise  0.093 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2378 with 29 steps || Reward : [0.   0.09] || avg reward :  0.126 || Noise  0.093 || 0.257 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2379 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.126 || Noise  0.092 || 0.360 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2381/3023  78% ETA:  0:03:10 ||||||||||||||||||||||||||||||         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2380 with 30 steps || Reward : [0.   0.09] || avg reward :  0.126 || Noise  0.092 || 0.270 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2381 with 71 steps || Reward : [0.2  0.09] || avg reward :  0.127 || Noise  0.092 || 0.450 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2383/3023  78% ETA:  0:03:10 |/////////////////////////////         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2382 with 210 steps || Reward : [0.40000001 0.49000001] || avg reward :  0.131 || Noise  0.092 || 1.013 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2383 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.131 || Noise  0.092 || 0.433 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2384 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.131 || Noise  0.092 || 0.352 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2386/3023  78% ETA:  0:03:09 |-----------------------------         | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2385 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.131 || Noise  0.092 || 0.410 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2386 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.130 || Noise  0.092 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2387 with 30 steps || Reward : [0.   0.09] || avg reward :  0.129 || Noise  0.092 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2388 with 29 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.092 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2390/3023  79% ETA:  0:03:08 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2389 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.092 || 0.322 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2390 with 121 steps || Reward : [0.19 0.3 ] || avg reward :  0.130 || Noise  0.091 || 0.632 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2391 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.130 || Noise  0.091 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2393/3023  79% ETA:  0:03:07 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2392 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.129 || Noise  0.091 || 0.301 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2393 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.129 || Noise  0.091 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2394 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.091 || 0.309 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2395 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.091 || 0.302 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2397/3023  79% ETA:  0:03:06 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2396 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.091 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2397 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.091 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2398 with 69 steps || Reward : [0.09 0.1 ] || avg reward :  0.128 || Noise  0.091 || 0.469 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2400/3023  79% ETA:  0:03:05 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2399 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.091 || 0.278 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2400 with 30 steps || Reward : [0.   0.09] || avg reward :  0.128 || Noise  0.091 || 0.272 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2401 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.128 || Noise  0.090 || 0.301 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2402 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.128 || Noise  0.090 || 0.393 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2404/3023  79% ETA:  0:03:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2403 with 30 steps || Reward : [0.   0.09] || avg reward :  0.127 || Noise  0.090 || 0.269 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2404 with 30 steps || Reward : [0.   0.09] || avg reward :  0.127 || Noise  0.090 || 0.309 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2405 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.126 || Noise  0.090 || 0.270 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2406 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.126 || Noise  0.090 || 0.274 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2408/3023  79% ETA:  0:03:03 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2407 with 26 steps || Reward : [-0.01  0.1 ] || avg reward :  0.126 || Noise  0.090 || 0.266 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2408 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.126 || Noise  0.090 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2409 with 50 steps || Reward : [ 0.2  -0.01] || avg reward :  0.126 || Noise  0.090 || 0.353 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2411/3023  79% ETA:  0:03:02 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2410 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.126 || Noise  0.090 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2412/3023  79% ETA:  0:03:02 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2411 with 271 steps || Reward : [0.70000001 0.59000001] || avg reward :  0.132 || Noise  0.090 || 1.228 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2412 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.132 || Noise  0.089 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2413 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.132 || Noise  0.089 || 0.263 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2414 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.132 || Noise  0.089 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2416/3023  79% ETA:  0:03:01 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2415 with 30 steps || Reward : [0.   0.09] || avg reward :  0.131 || Noise  0.089 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2416 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.131 || Noise  0.089 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2418/3023  79% ETA:  0:03:00 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2417 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.131 || Noise  0.089 || 0.520 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2418 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.131 || Noise  0.089 || 0.292 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2419 with 30 steps || Reward : [0.   0.09] || avg reward :  0.129 || Noise  0.089 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2421/3023  80% ETA:  0:03:00 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2420 with 289 steps || Reward : [0.70000001 0.69000001] || avg reward :  0.135 || Noise  0.089 || 1.272 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2421 with 123 steps || Reward : [0.3  0.19] || avg reward :  0.137 || Noise  0.089 || 0.667 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2422 with 30 steps || Reward : [0.   0.09] || avg reward :  0.137 || Noise  0.089 || 0.261 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2424/3023  80% ETA:  0:02:59 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2423 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.137 || Noise  0.088 || 0.278 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2424 with 103 steps || Reward : [0.2  0.19] || avg reward :  0.138 || Noise  0.088 || 0.568 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2425 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.088 || 0.352 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2427/3023  80% ETA:  0:02:58 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2426 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.088 || 0.279 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2427 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.088 || 0.362 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2429 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.137 || Noise  0.088 || 0.265 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2431/3023  80% ETA:  0:02:57 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2430 with 428 steps || Reward : [1.10000002 0.99000002] || avg reward :  0.147 || Noise  0.088 || 1.814 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2431 with 88 steps || Reward : [0.1  0.19] || avg reward :  0.148 || Noise  0.088 || 0.529 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2432 with 66 steps || Reward : [0.09 0.1 ] || avg reward :  0.148 || Noise  0.088 || 0.401 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2434/3023  80% ETA:  0:02:56 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2433 with 60 steps || Reward : [0.09 0.1 ] || avg reward :  0.148 || Noise  0.088 || 0.394 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2435 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.148 || Noise  0.087 || 0.260 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2436 with 29 steps || Reward : [0.   0.09] || avg reward :  0.148 || Noise  0.087 || 0.271 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2438/3023  80% ETA:  0:02:55 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2437 with 86 steps || Reward : [0.09 0.2 ] || avg reward :  0.147 || Noise  0.087 || 0.509 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2438 with 29 steps || Reward : [0.   0.09] || avg reward :  0.146 || Noise  0.087 || 0.266 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2439 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.087 || 0.402 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2441/3023  80% ETA:  0:02:54 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2440 with 66 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.087 || 0.429 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2441 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.087 || 0.271 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2443 with 29 steps || Reward : [0.   0.09] || avg reward :  0.146 || Noise  0.087 || 0.270 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2445/3023  80% ETA:  0:02:53 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2444 with 100 steps || Reward : [0.2  0.19] || avg reward :  0.147 || Noise  0.087 || 0.554 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2445 with 30 steps || Reward : [0.   0.09] || avg reward :  0.147 || Noise  0.087 || 0.276 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2446 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.086 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2447 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.144 || Noise  0.086 || 0.348 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2449/3023  81% ETA:  0:02:52 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2448 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.144 || Noise  0.086 || 0.268 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2449 with 53 steps || Reward : [-0.01  0.1 ] || avg reward :  0.143 || Noise  0.086 || 0.400 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2450 with 76 steps || Reward : [0.09 0.1 ] || avg reward :  0.142 || Noise  0.086 || 0.440 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2452/3023  81% ETA:  0:02:51 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2451 with 30 steps || Reward : [0.   0.09] || avg reward :  0.142 || Noise  0.086 || 0.259 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2452 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.142 || Noise  0.086 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2453 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.086 || 0.349 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2454 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.086 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2456/3023  81% ETA:  0:02:50 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2455 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.086 || 0.313 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2456 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.140 || Noise  0.086 || 0.269 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2457 with 50 steps || Reward : [ 0.1  -0.01] || avg reward :  0.140 || Noise  0.086 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2458 with 30 steps || Reward : [0.   0.09] || avg reward :  0.140 || Noise  0.085 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2460/3023  81% ETA:  0:02:49 |||||||||||||||||||||||||||||||        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2459 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.140 || Noise  0.085 || 0.347 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2460 with 91 steps || Reward : [0.2  0.19] || avg reward :  0.141 || Noise  0.085 || 0.514 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2462/3023  81% ETA:  0:02:48 |//////////////////////////////        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2461 with 98 steps || Reward : [0.1  0.19] || avg reward :  0.142 || Noise  0.085 || 0.569 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2462 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.142 || Noise  0.085 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2463 with 57 steps || Reward : [-0.01  0.1 ] || avg reward :  0.141 || Noise  0.085 || 0.426 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2464 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.141 || Noise  0.085 || 0.256 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2466/3023  81% ETA:  0:02:47 |------------------------------        | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2465 with 148 steps || Reward : [0.3  0.29] || avg reward :  0.138 || Noise  0.085 || 0.766 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2466 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.138 || Noise  0.085 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2467 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.085 || 0.340 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2469/3023  81% ETA:  0:02:46 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2468 with 30 steps || Reward : [0.   0.09] || avg reward :  0.137 || Noise  0.085 || 0.315 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2469 with 115 steps || Reward : [0.2  0.19] || avg reward :  0.138 || Noise  0.084 || 0.600 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2471/3023  81% ETA:  0:02:46 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2470 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.138 || Noise  0.084 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2471 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.138 || Noise  0.084 || 0.288 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2472 with 83 steps || Reward : [0.2  0.09] || avg reward :  0.139 || Noise  0.084 || 0.470 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2474/3023  81% ETA:  0:02:45 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2473 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.139 || Noise  0.084 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2474 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.139 || Noise  0.084 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2475 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.138 || Noise  0.084 || 0.402 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2477/3023  81% ETA:  0:02:44 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2476 with 84 steps || Reward : [0.2  0.09] || avg reward :  0.138 || Noise  0.084 || 0.498 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2477 with 30 steps || Reward : [0.   0.09] || avg reward :  0.138 || Noise  0.084 || 0.275 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2478 with 33 steps || Reward : [-0.01  0.1 ] || avg reward :  0.138 || Noise  0.084 || 0.337 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2480/3023  82% ETA:  0:02:43 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2479 with 165 steps || Reward : [0.29       0.40000001] || avg reward :  0.141 || Noise  0.084 || 0.804 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2481/3023  82% ETA:  0:02:43 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2480 with 279 steps || Reward : [0.59000001 0.70000001] || avg reward :  0.147 || Noise  0.084 || 1.340 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2481 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.083 || 0.353 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2482 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.142 || Noise  0.083 || 0.263 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2484/3023  82% ETA:  0:02:42 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2483 with 65 steps || Reward : [0.09 0.1 ] || avg reward :  0.142 || Noise  0.083 || 0.484 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2484 with 30 steps || Reward : [0.   0.09] || avg reward :  0.142 || Noise  0.083 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2485 with 30 steps || Reward : [0.   0.09] || avg reward :  0.142 || Noise  0.083 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2487/3023  82% ETA:  0:02:41 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2486 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.083 || 0.387 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2487 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.083 || 0.369 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2488 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.142 || Noise  0.083 || 0.410 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2490/3023  82% ETA:  0:02:41 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2489 with 112 steps || Reward : [0.2  0.19] || avg reward :  0.143 || Noise  0.083 || 0.642 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2490 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.141 || Noise  0.083 || 0.327 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2491 with 74 steps || Reward : [-0.01  0.2 ] || avg reward :  0.142 || Noise  0.083 || 0.460 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2493/3023  82% ETA:  0:02:40 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2492 with 30 steps || Reward : [0.   0.09] || avg reward :  0.142 || Noise  0.083 || 0.269 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2494/3023  82% ETA:  0:02:40 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2493 with 216 steps || Reward : [0.39000001 0.50000001] || avg reward :  0.146 || Noise  0.082 || 1.048 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2494 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.082 || 0.380 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2495 with 84 steps || Reward : [0.09 0.2 ] || avg reward :  0.147 || Noise  0.082 || 0.520 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2497/3023  82% ETA:  0:02:39 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2496 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.147 || Noise  0.082 || 0.424 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2497 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.147 || Noise  0.082 || 0.406 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2498 with 30 steps || Reward : [0.   0.09] || avg reward :  0.147 || Noise  0.082 || 0.259 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2500/3023  82% ETA:  0:02:38 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2499 with 68 steps || Reward : [0.1  0.09] || avg reward :  0.147 || Noise  0.082 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2500 with 29 steps || Reward : [0.   0.09] || avg reward :  0.147 || Noise  0.082 || 0.289 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2501 with 85 steps || Reward : [0.2  0.09] || avg reward :  0.148 || Noise  0.082 || 0.543 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2503/3023  82% ETA:  0:02:37 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2502 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.148 || Noise  0.082 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2503 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.148 || Noise  0.082 || 0.342 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2504 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.149 || Noise  0.082 || 0.512 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2506/3023  82% ETA:  0:02:36 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2505 with 81 steps || Reward : [0.2  0.09] || avg reward :  0.150 || Noise  0.081 || 0.461 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2506 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.150 || Noise  0.081 || 0.399 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2508/3023  82% ETA:  0:02:36 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2507 with 142 steps || Reward : [0.3  0.29] || avg reward :  0.152 || Noise  0.081 || 0.684 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2508 with 71 steps || Reward : [0.09 0.1 ] || avg reward :  0.152 || Noise  0.081 || 0.448 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2509 with 66 steps || Reward : [0.2  0.09] || avg reward :  0.152 || Noise  0.081 || 0.405 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2511/3023  83% ETA:  0:02:35 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2510 with 30 steps || Reward : [0.   0.09] || avg reward :  0.152 || Noise  0.081 || 0.272 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2511 with 30 steps || Reward : [0.   0.09] || avg reward :  0.146 || Noise  0.081 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2512 with 69 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.081 || 0.413 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2513 with 30 steps || Reward : [0.   0.09] || avg reward :  0.146 || Noise  0.081 || 0.283 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2515/3023  83% ETA:  0:02:34 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2514 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.081 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2515 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.081 || 0.420 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2516 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.146 || Noise  0.081 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2518/3023  83% ETA:  0:02:33 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2517 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.081 || 0.379 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2518 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.080 || 0.350 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2519 with 86 steps || Reward : [0.2  0.09] || avg reward :  0.147 || Noise  0.080 || 0.511 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2521/3023  83% ETA:  0:02:32 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2520 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.141 || Noise  0.080 || 0.329 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2521 with 30 steps || Reward : [0.   0.09] || avg reward :  0.139 || Noise  0.080 || 0.357 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2522 with 62 steps || Reward : [0.1  0.09] || avg reward :  0.139 || Noise  0.080 || 0.496 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2524/3023  83% ETA:  0:02:31 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2523 with 70 steps || Reward : [0.1  0.09] || avg reward :  0.139 || Noise  0.080 || 0.509 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2524 with 30 steps || Reward : [0.   0.09] || avg reward :  0.138 || Noise  0.080 || 0.324 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2525 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.139 || Noise  0.080 || 0.404 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2527/3023  83% ETA:  0:02:30 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2526 with 68 steps || Reward : [0.09 0.2 ] || avg reward :  0.140 || Noise  0.080 || 0.425 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2527 with 137 steps || Reward : [0.2        0.59000001] || avg reward :  0.145 || Noise  0.080 || 0.700 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2529/3023  83% ETA:  0:02:30 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2528 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.146 || Noise  0.080 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2530/3023  83% ETA:  0:02:30 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2529 with 223 steps || Reward : [0.50000001 0.49000001] || avg reward :  0.150 || Noise  0.080 || 1.037 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2530 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.140 || Noise  0.079 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2532/3023  83% ETA:  0:02:29 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2531 with 210 steps || Reward : [0.40000001 0.49000001] || avg reward :  0.143 || Noise  0.079 || 0.975 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2532 with 123 steps || Reward : [0.3  0.19] || avg reward :  0.145 || Noise  0.079 || 0.649 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2534/3023  83% ETA:  0:02:29 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2533 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.145 || Noise  0.079 || 0.369 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2534 with 74 steps || Reward : [0.1  0.09] || avg reward :  0.146 || Noise  0.079 || 0.427 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2535 with 62 steps || Reward : [0.   0.19] || avg reward :  0.147 || Noise  0.079 || 0.426 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2537/3023  83% ETA:  0:02:28 |///////////////////////////////       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2536 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.147 || Noise  0.079 || 0.389 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2537 with 48 steps || Reward : [ 0.1  -0.01] || avg reward :  0.146 || Noise  0.079 || 0.383 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2539/3023  83% ETA:  0:02:27 |-------------------------------       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2538 with 252 steps || Reward : [0.60000001 0.59000001] || avg reward :  0.151 || Noise  0.079 || 1.124 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2539 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.151 || Noise  0.079 || 0.287 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2540 with 85 steps || Reward : [0.2  0.09] || avg reward :  0.152 || Noise  0.079 || 0.480 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2542/3023  84% ETA:  0:02:26 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2541 with 100 steps || Reward : [0.1  0.29] || avg reward :  0.154 || Noise  0.079 || 0.547 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2542 with 67 steps || Reward : [0.09 0.2 ] || avg reward :  0.156 || Noise  0.079 || 0.415 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2543 with 68 steps || Reward : [0.09 0.2 ] || avg reward :  0.157 || Noise  0.078 || 0.419 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2545/3023  84% ETA:  0:02:26 ||||||||||||||||||||||||||||||||       | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2544 with 53 steps || Reward : [-0.01  0.1 ] || avg reward :  0.156 || Noise  0.078 || 0.359 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2545 with 67 steps || Reward : [0.09 0.2 ] || avg reward :  0.157 || Noise  0.078 || 0.437 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2547/3023  84% ETA:  0:02:25 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2546 with 265 steps || Reward : [0.60000001 0.59000001] || avg reward :  0.162 || Noise  0.078 || 1.259 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2547 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.162 || Noise  0.078 || 0.406 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2548 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.162 || Noise  0.078 || 0.335 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2550/3023  84% ETA:  0:02:24 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2549 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.162 || Noise  0.078 || 0.342 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2550 with 147 steps || Reward : [0.29       0.40000001] || avg reward :  0.165 || Noise  0.078 || 0.730 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2552/3023  84% ETA:  0:02:24 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2551 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.165 || Noise  0.078 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2552 with 30 steps || Reward : [0.   0.09] || avg reward :  0.165 || Noise  0.078 || 0.289 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2554/3023  84% ETA:  0:02:23 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2553 with 155 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.168 || Noise  0.078 || 0.798 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2555/3023  84% ETA:  0:02:24 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2554 with 941 steps || Reward : [2.40000004 2.39000004] || avg reward :  0.191 || Noise  0.078 || 3.881 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2555 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.191 || Noise  0.078 || 0.427 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2556 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.191 || Noise  0.077 || 0.280 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2557 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.191 || Noise  0.077 || 0.278 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2559/3023  84% ETA:  0:02:22 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2558 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.191 || Noise  0.077 || 0.261 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2559 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.191 || Noise  0.077 || 0.424 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2561/3023  84% ETA:  0:02:22 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2560 with 380 steps || Reward : [0.90000001 0.89000001] || avg reward :  0.198 || Noise  0.077 || 1.668 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2562/3023  84% ETA:  0:02:22 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2561 with 652 steps || Reward : [1.60000002 1.59000002] || avg reward :  0.212 || Noise  0.077 || 2.775 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2562 with 30 steps || Reward : [0.   0.09] || avg reward :  0.212 || Noise  0.077 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2563 with 30 steps || Reward : [0.   0.09] || avg reward :  0.212 || Noise  0.077 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2564 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.212 || Noise  0.077 || 0.392 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2566/3023  84% ETA:  0:02:21 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2565 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.210 || Noise  0.077 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2566 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.210 || Noise  0.077 || 0.342 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2567 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.210 || Noise  0.077 || 0.290 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2569/3023  84% ETA:  0:02:20 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2568 with 85 steps || Reward : [0.09 0.2 ] || avg reward :  0.211 || Noise  0.077 || 0.506 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2570/3023  85% ETA:  0:02:20 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2569 with 493 steps || Reward : [1.30000002 1.19000002] || avg reward :  0.222 || Noise  0.076 || 3.442 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2570 with 45 steps || Reward : [-0.01  0.1 ] || avg reward :  0.222 || Noise  0.076 || 0.645 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2571 with 29 steps || Reward : [-0.01  0.1 ] || avg reward :  0.222 || Noise  0.076 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2573/3023  85% ETA:  0:02:19 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2572 with 168 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.224 || Noise  0.076 || 0.816 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2573 with 190 steps || Reward : [0.39000001 0.40000001] || avg reward :  0.227 || Noise  0.076 || 0.971 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2575/3023  85% ETA:  0:02:19 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2574 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.227 || Noise  0.076 || 0.271 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2575 with 56 steps || Reward : [0.09 0.1 ] || avg reward :  0.227 || Noise  0.076 || 0.442 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2576 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.226 || Noise  0.076 || 0.393 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2578/3023  85% ETA:  0:02:18 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2577 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.226 || Noise  0.076 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2578 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.226 || Noise  0.076 || 0.315 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2579 with 29 steps || Reward : [0.   0.09] || avg reward :  0.223 || Noise  0.076 || 0.262 seconds, mem : 50000\n",
      "\u001b[0mEpisode 2580 with 23 steps || Reward : [ 0.   -0.01] || avg reward :  0.216 || Noise  0.076 || 0.226 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2582/3023  85% ETA:  0:02:17 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2581 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.216 || Noise  0.076 || 0.267 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2582 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.216 || Noise  0.075 || 0.304 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2583 with 79 steps || Reward : [0.1  0.09] || avg reward :  0.216 || Noise  0.075 || 0.450 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2585/3023  85% ETA:  0:02:16 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2584 with 50 steps || Reward : [-0.01  0.1 ] || avg reward :  0.216 || Noise  0.075 || 0.343 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2585 with 29 steps || Reward : [0.   0.09] || avg reward :  0.216 || Noise  0.075 || 0.288 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2586 with 66 steps || Reward : [0.2  0.09] || avg reward :  0.217 || Noise  0.075 || 0.386 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2587 with 30 steps || Reward : [0.   0.09] || avg reward :  0.217 || Noise  0.075 || 0.260 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2589/3023  85% ETA:  0:02:15 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2588 with 30 steps || Reward : [0.   0.09] || avg reward :  0.217 || Noise  0.075 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2589 with 30 steps || Reward : [0.   0.09] || avg reward :  0.216 || Noise  0.075 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2590 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.216 || Noise  0.075 || 0.247 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2591 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.215 || Noise  0.075 || 0.271 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2593/3023  85% ETA:  0:02:13 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2592 with 65 steps || Reward : [0.2  0.09] || avg reward :  0.216 || Noise  0.075 || 0.398 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2593 with 61 steps || Reward : [0.2  0.09] || avg reward :  0.213 || Noise  0.075 || 0.398 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2595/3023  85% ETA:  0:02:13 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2594 with 350 steps || Reward : [0.80000001 0.79000001] || avg reward :  0.220 || Noise  0.075 || 1.629 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2595 with 154 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.222 || Noise  0.074 || 0.896 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2597/3023  85% ETA:  0:02:13 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2596 with 171 steps || Reward : [0.3        0.39000001] || avg reward :  0.225 || Noise  0.074 || 0.812 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2598/3023  85% ETA:  0:02:12 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2597 with 388 steps || Reward : [0.90000001 0.89000001] || avg reward :  0.233 || Noise  0.074 || 1.839 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2598 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.233 || Noise  0.074 || 0.479 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2600/3023  86% ETA:  0:02:12 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2599 with 112 steps || Reward : [0.2  0.19] || avg reward :  0.234 || Noise  0.074 || 0.659 seconds, mem : 50000\n",
      "\u001b[0mEpisode 2600 with 14 steps || Reward : [-0.01  0.  ] || avg reward :  0.233 || Noise  0.074 || 0.221 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2601 with 64 steps || Reward : [0.2  0.09] || avg reward :  0.233 || Noise  0.074 || 0.446 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2603/3023  86% ETA:  0:02:11 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2602 with 44 steps || Reward : [0.1  0.09] || avg reward :  0.233 || Noise  0.074 || 0.373 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2605 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.229 || Noise  0.074 || 0.279 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2607/3023  86% ETA:  0:02:10 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2606 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.229 || Noise  0.074 || 0.423 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2607 with 88 steps || Reward : [0.19 0.2 ] || avg reward :  0.228 || Noise  0.074 || 0.564 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2608 with 50 steps || Reward : [-0.01  0.1 ] || avg reward :  0.228 || Noise  0.074 || 0.382 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2610/3023  86% ETA:  0:02:09 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2609 with 135 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.230 || Noise  0.073 || 0.750 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2610 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.230 || Noise  0.073 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2611 with 32 steps || Reward : [-0.01  0.1 ] || avg reward :  0.230 || Noise  0.073 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2613/3023  86% ETA:  0:02:08 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2612 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.230 || Noise  0.073 || 0.403 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2614/3023  86% ETA:  0:02:08 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2613 with 303 steps || Reward : [0.80000001 0.69000001] || avg reward :  0.237 || Noise  0.073 || 1.494 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2614 with 30 steps || Reward : [0.   0.09] || avg reward :  0.237 || Noise  0.073 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2616/3023  86% ETA:  0:02:07 |||||||||||||||||||||||||||||||||      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2615 with 312 steps || Reward : [0.69000001 0.80000001] || avg reward :  0.244 || Noise  0.073 || 1.505 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2616 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.244 || Noise  0.073 || 0.417 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2617 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.244 || Noise  0.073 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2619/3023  86% ETA:  0:02:07 |////////////////////////////////      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2618 with 269 steps || Reward : [0.60000001 0.59000001] || avg reward :  0.249 || Noise  0.073 || 1.362 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2619 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.248 || Noise  0.073 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2620 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.248 || Noise  0.073 || 0.338 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2621 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.248 || Noise  0.073 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2623/3023  86% ETA:  0:02:05 |--------------------------------      | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2622 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.248 || Noise  0.072 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2623 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.248 || Noise  0.072 || 0.375 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2624 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.249 || Noise  0.072 || 0.304 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2625 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.248 || Noise  0.072 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2627/3023  86% ETA:  0:02:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2626 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.247 || Noise  0.072 || 0.399 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2627 with 30 steps || Reward : [0.   0.09] || avg reward :  0.242 || Noise  0.072 || 0.312 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2628 with 64 steps || Reward : [0.2  0.09] || avg reward :  0.243 || Noise  0.072 || 0.422 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2630/3023  86% ETA:  0:02:03 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2629 with 61 steps || Reward : [ 0.2  -0.01] || avg reward :  0.240 || Noise  0.072 || 0.617 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2631/3023  87% ETA:  0:02:03 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2630 with 247 steps || Reward : [0.50000001 0.59000001] || avg reward :  0.245 || Noise  0.072 || 1.908 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2631 with 30 steps || Reward : [0.   0.09] || avg reward :  0.241 || Noise  0.072 || 0.372 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2632 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.239 || Noise  0.072 || 0.420 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2634/3023  87% ETA:  0:02:02 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2633 with 155 steps || Reward : [0.3  0.29] || avg reward :  0.241 || Noise  0.072 || 0.987 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2634 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.241 || Noise  0.072 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2635 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.240 || Noise  0.072 || 0.400 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2637/3023  87% ETA:  0:02:01 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2636 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.240 || Noise  0.071 || 0.348 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2637 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.240 || Noise  0.071 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2638 with 30 steps || Reward : [0.   0.09] || avg reward :  0.235 || Noise  0.071 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2640/3023  87% ETA:  0:02:01 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2639 with 479 steps || Reward : [1.30000002 1.29000002] || avg reward :  0.247 || Noise  0.071 || 2.277 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2640 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.246 || Noise  0.071 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2641 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.244 || Noise  0.071 || 0.272 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2642 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.243 || Noise  0.071 || 0.315 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2644/3023  87% ETA:  0:02:00 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2643 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.242 || Noise  0.071 || 0.298 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2644 with 30 steps || Reward : [0.   0.09] || avg reward :  0.242 || Noise  0.071 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2645 with 30 steps || Reward : [0.   0.09] || avg reward :  0.240 || Noise  0.071 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2646 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.235 || Noise  0.071 || 0.311 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2648/3023  87% ETA:  0:01:58 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2647 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.236 || Noise  0.071 || 0.441 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2648 with 30 steps || Reward : [0.   0.09] || avg reward :  0.236 || Noise  0.071 || 0.328 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2649 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.236 || Noise  0.071 || 0.378 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2651/3023  87% ETA:  0:01:57 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2650 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.233 || Noise  0.070 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2651 with 34 steps || Reward : [ 0.1  -0.01] || avg reward :  0.233 || Noise  0.070 || 0.351 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2652 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.233 || Noise  0.070 || 0.380 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2654/3023  87% ETA:  0:01:56 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2653 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.230 || Noise  0.070 || 0.296 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2654 with 56 steps || Reward : [0.1  0.09] || avg reward :  0.207 || Noise  0.070 || 0.431 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2655 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.207 || Noise  0.070 || 0.301 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2657/3023  87% ETA:  0:01:55 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2656 with 30 steps || Reward : [0.   0.09] || avg reward :  0.207 || Noise  0.070 || 0.278 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2657 with 78 steps || Reward : [0.1  0.19] || avg reward :  0.208 || Noise  0.070 || 0.539 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2658 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.209 || Noise  0.070 || 0.441 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2660/3023  87% ETA:  0:01:55 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2659 with 30 steps || Reward : [0.   0.09] || avg reward :  0.209 || Noise  0.070 || 0.336 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2660 with 30 steps || Reward : [0.   0.09] || avg reward :  0.201 || Noise  0.070 || 0.317 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2661 with 52 steps || Reward : [ 0.1  -0.01] || avg reward :  0.186 || Noise  0.070 || 0.371 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2663/3023  88% ETA:  0:01:54 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2662 with 66 steps || Reward : [0.2  0.09] || avg reward :  0.187 || Noise  0.070 || 0.453 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2663 with 29 steps || Reward : [0.   0.09] || avg reward :  0.187 || Noise  0.070 || 0.319 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2664 with 112 steps || Reward : [0.2  0.19] || avg reward :  0.188 || Noise  0.070 || 0.638 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2666/3023  88% ETA:  0:01:53 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2665 with 48 steps || Reward : [-0.01  0.1 ] || avg reward :  0.188 || Noise  0.069 || 0.372 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2666 with 85 steps || Reward : [0.1  0.19] || avg reward :  0.189 || Noise  0.069 || 0.549 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2667 with 50 steps || Reward : [ 0.1  -0.01] || avg reward :  0.189 || Noise  0.069 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2669/3023  88% ETA:  0:01:52 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2668 with 465 steps || Reward : [1.09000002 1.20000002] || avg reward :  0.199 || Noise  0.069 || 2.150 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2669 with 67 steps || Reward : [0.2  0.09] || avg reward :  0.188 || Noise  0.069 || 0.528 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2671/3023  88% ETA:  0:01:52 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2670 with 120 steps || Reward : [0.19 0.3 ] || avg reward :  0.190 || Noise  0.069 || 0.705 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2671 with 71 steps || Reward : [0.09 0.2 ] || avg reward :  0.191 || Noise  0.069 || 0.503 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2672 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.188 || Noise  0.069 || 0.293 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2674/3023  88% ETA:  0:01:51 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2673 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.185 || Noise  0.069 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2674 with 31 steps || Reward : [0.   0.09] || avg reward :  0.185 || Noise  0.069 || 0.322 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2675 with 30 steps || Reward : [0.   0.09] || avg reward :  0.185 || Noise  0.069 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2676 with 31 steps || Reward : [0.   0.09] || avg reward :  0.185 || Noise  0.069 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2678/3023  88% ETA:  0:01:49 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2677 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.185 || Noise  0.069 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2678 with 30 steps || Reward : [0.   0.09] || avg reward :  0.184 || Noise  0.069 || 0.313 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2679 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.185 || Noise  0.068 || 0.401 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2681/3023  88% ETA:  0:01:48 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2680 with 62 steps || Reward : [0.2  0.09] || avg reward :  0.187 || Noise  0.068 || 0.449 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2682/3023  88% ETA:  0:01:48 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2681 with 394 steps || Reward : [0.99000002 1.00000001] || avg reward :  0.196 || Noise  0.068 || 1.873 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2682 with 179 steps || Reward : [0.40000001 0.39000001] || avg reward :  0.199 || Noise  0.068 || 0.974 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2684/3023  88% ETA:  0:01:48 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2683 with 547 steps || Reward : [1.39000002 1.40000002] || avg reward :  0.212 || Noise  0.068 || 2.558 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2684 with 30 steps || Reward : [0.   0.09] || avg reward :  0.211 || Noise  0.068 || 0.504 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2685 with 30 steps || Reward : [0.   0.09] || avg reward :  0.211 || Noise  0.068 || 0.339 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2687/3023  88% ETA:  0:01:47 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2686 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.210 || Noise  0.068 || 0.693 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2687 with 84 steps || Reward : [0.09 0.2 ] || avg reward :  0.212 || Noise  0.068 || 0.774 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2689/3023  88% ETA:  0:01:47 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2688 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.212 || Noise  0.068 || 0.601 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2689 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.212 || Noise  0.068 || 0.358 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2690 with 30 steps || Reward : [0.   0.09] || avg reward :  0.212 || Noise  0.068 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2692/3023  89% ETA:  0:01:46 |---------------------------------     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2691 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.212 || Noise  0.068 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2692 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.211 || Noise  0.068 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2693 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.210 || Noise  0.068 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2694 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.203 || Noise  0.067 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2696/3023  89% ETA:  0:01:44 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2695 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.200 || Noise  0.067 || 0.430 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2696 with 30 steps || Reward : [0.   0.09] || avg reward :  0.197 || Noise  0.067 || 0.315 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2697 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.189 || Noise  0.067 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2699/3023  89% ETA:  0:01:43 ||||||||||||||||||||||||||||||||||     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2698 with 71 steps || Reward : [0.1  0.09] || avg reward :  0.189 || Noise  0.067 || 0.497 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2699 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.188 || Noise  0.067 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2700 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.189 || Noise  0.067 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2702/3023  89% ETA:  0:01:42 |/////////////////////////////////     | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2701 with 82 steps || Reward : [0.09 0.2 ] || avg reward :  0.189 || Noise  0.067 || 0.569 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2702 with 30 steps || Reward : [0.   0.09] || avg reward :  0.189 || Noise  0.067 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2703 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.190 || Noise  0.067 || 0.334 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2705/3023  89% ETA:  0:01:42 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2704 with 316 steps || Reward : [0.80000001 0.79000001] || avg reward :  0.198 || Noise  0.067 || 1.590 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2705 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.198 || Noise  0.067 || 0.339 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2707/3023  89% ETA:  0:01:41 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2706 with 147 steps || Reward : [0.3  0.29] || avg reward :  0.200 || Noise  0.067 || 0.857 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2707 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.199 || Noise  0.067 || 0.356 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2708 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.199 || Noise  0.067 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2709 with 30 steps || Reward : [0.   0.09] || avg reward :  0.195 || Noise  0.066 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2711/3023  89% ETA:  0:01:40 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2710 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.195 || Noise  0.066 || 0.364 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2711 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.195 || Noise  0.066 || 0.331 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2712 with 30 steps || Reward : [0.   0.09] || avg reward :  0.195 || Noise  0.066 || 0.384 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2714/3023  89% ETA:  0:01:39 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2713 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.188 || Noise  0.066 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2714 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.188 || Noise  0.066 || 0.368 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2715 with 31 steps || Reward : [0.   0.09] || avg reward :  0.181 || Noise  0.066 || 0.625 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2717/3023  89% ETA:  0:01:38 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2716 with 30 steps || Reward : [0.   0.09] || avg reward :  0.181 || Noise  0.066 || 0.482 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2717 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.181 || Noise  0.066 || 0.635 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2719/3023  89% ETA:  0:01:37 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2718 with 47 steps || Reward : [ 0.1  -0.01] || avg reward :  0.176 || Noise  0.066 || 0.412 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2719 with 43 steps || Reward : [-0.01  0.1 ] || avg reward :  0.176 || Noise  0.066 || 0.445 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2720 with 30 steps || Reward : [0.   0.09] || avg reward :  0.176 || Noise  0.066 || 0.335 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2722/3023  90% ETA:  0:01:36 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2721 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.176 || Noise  0.066 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2722 with 30 steps || Reward : [0.   0.09] || avg reward :  0.176 || Noise  0.066 || 0.311 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2723 with 76 steps || Reward : [0.2  0.19] || avg reward :  0.177 || Noise  0.066 || 0.480 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2725/3023  90% ETA:  0:01:35 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2724 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.177 || Noise  0.065 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2726/3023  90% ETA:  0:01:35 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2725 with 443 steps || Reward : [1.09000002 1.10000002] || avg reward :  0.187 || Noise  0.065 || 2.148 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2727/3023  90% ETA:  0:01:35 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2726 with 215 steps || Reward : [0.49000001 0.50000001] || avg reward :  0.191 || Noise  0.065 || 1.255 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2727 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.192 || Noise  0.065 || 0.616 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2728 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.191 || Noise  0.065 || 0.373 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2730/3023  90% ETA:  0:01:34 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2729 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.190 || Noise  0.065 || 0.424 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2730 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.185 || Noise  0.065 || 0.519 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2731 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.185 || Noise  0.065 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2733/3023  90% ETA:  0:01:33 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2732 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.185 || Noise  0.065 || 0.321 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2733 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.183 || Noise  0.065 || 0.322 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2734 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.184 || Noise  0.065 || 0.456 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2736/3023  90% ETA:  0:01:32 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2735 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.184 || Noise  0.065 || 0.289 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2736 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.184 || Noise  0.065 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2737 with 45 steps || Reward : [ 0.1  -0.01] || avg reward :  0.184 || Noise  0.065 || 0.368 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2739/3023  90% ETA:  0:01:31 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2738 with 102 steps || Reward : [0.2  0.19] || avg reward :  0.185 || Noise  0.065 || 0.604 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2739 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.174 || Noise  0.064 || 0.495 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2740 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.174 || Noise  0.064 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2742/3023  90% ETA:  0:01:30 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2741 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.174 || Noise  0.064 || 0.440 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2742 with 92 steps || Reward : [0.2  0.09] || avg reward :  0.175 || Noise  0.064 || 0.583 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2744/3023  90% ETA:  0:01:30 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2743 with 142 steps || Reward : [0.29 0.3 ] || avg reward :  0.177 || Noise  0.064 || 0.782 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2745/3023  90% ETA:  0:01:30 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2744 with 761 steps || Reward : [2.00000003 1.89000003] || avg reward :  0.196 || Noise  0.064 || 3.489 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2746/3023  90% ETA:  0:01:30 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2745 with 482 steps || Reward : [1.19000002 1.20000002] || avg reward :  0.207 || Noise  0.064 || 2.200 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2747/3023  90% ETA:  0:01:30 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2746 with 563 steps || Reward : [1.40000002 1.39000002] || avg reward :  0.220 || Noise  0.064 || 2.534 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2747 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.219 || Noise  0.064 || 0.331 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2749/3023  90% ETA:  0:01:29 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2748 with 149 steps || Reward : [0.29 0.3 ] || avg reward :  0.222 || Noise  0.064 || 0.795 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2749 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.222 || Noise  0.064 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2750 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.222 || Noise  0.064 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2751 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.222 || Noise  0.064 || 0.306 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2753/3023  91% ETA:  0:01:28 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2752 with 30 steps || Reward : [0.   0.09] || avg reward :  0.221 || Noise  0.064 || 0.295 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2753 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.221 || Noise  0.064 || 0.341 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2754 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.221 || Noise  0.064 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2755 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.221 || Noise  0.063 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2757/3023  91% ETA:  0:01:26 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2756 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.222 || Noise  0.063 || 0.363 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2757 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.221 || Noise  0.063 || 0.361 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2758 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.220 || Noise  0.063 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2759 with 30 steps || Reward : [0.   0.09] || avg reward :  0.220 || Noise  0.063 || 0.338 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2761/3023  91% ETA:  0:01:25 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2760 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.220 || Noise  0.063 || 0.286 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2761 with 65 steps || Reward : [0.1  0.19] || avg reward :  0.221 || Noise  0.063 || 0.499 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2762 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.220 || Noise  0.063 || 0.337 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2764/3023  91% ETA:  0:01:24 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2763 with 71 steps || Reward : [0.1  0.09] || avg reward :  0.220 || Noise  0.063 || 0.390 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2764 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.219 || Noise  0.063 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2765 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.219 || Noise  0.063 || 0.340 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2767/3023  91% ETA:  0:01:23 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2766 with 68 steps || Reward : [0.1  0.19] || avg reward :  0.219 || Noise  0.063 || 0.470 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2767 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.219 || Noise  0.063 || 0.352 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2768 with 74 steps || Reward : [0.1  0.19] || avg reward :  0.209 || Noise  0.063 || 0.474 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2770/3023  91% ETA:  0:01:22 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2769 with 92 steps || Reward : [0.2  0.09] || avg reward :  0.209 || Noise  0.063 || 0.571 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2771/3023  91% ETA:  0:01:22 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2770 with 369 steps || Reward : [0.89000001 0.90000001] || avg reward :  0.215 || Noise  0.063 || 1.695 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2771 with 69 steps || Reward : [0.09 0.2 ] || avg reward :  0.215 || Noise  0.062 || 0.484 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2772 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.215 || Noise  0.062 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2774/3023  91% ETA:  0:01:21 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2773 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.215 || Noise  0.062 || 0.301 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2774 with 68 steps || Reward : [0.09 0.2 ] || avg reward :  0.216 || Noise  0.062 || 0.475 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2776/3023  91% ETA:  0:01:20 |----------------------------------    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2775 with 116 steps || Reward : [0.3  0.19] || avg reward :  0.218 || Noise  0.062 || 0.661 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2776 with 50 steps || Reward : [-0.01  0.1 ] || avg reward :  0.218 || Noise  0.062 || 0.401 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2777 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.218 || Noise  0.062 || 0.286 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2779/3023  91% ETA:  0:01:19 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2778 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.218 || Noise  0.062 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2779 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.218 || Noise  0.062 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2781/3023  91% ETA:  0:01:19 |||||||||||||||||||||||||||||||||||    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2780 with 142 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.220 || Noise  0.062 || 0.782 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2782/3023  92% ETA:  0:01:19 |//////////////////////////////////    | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2781 with 416 steps || Reward : [1.10000002 0.99000002] || avg reward :  0.221 || Noise  0.062 || 1.926 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2782 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.219 || Noise  0.062 || 0.462 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2783 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.206 || Noise  0.062 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2785/3023  92% ETA:  0:01:18 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2784 with 30 steps || Reward : [0.   0.09] || avg reward :  0.206 || Noise  0.062 || 0.331 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2785 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.206 || Noise  0.062 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2786 with 29 steps || Reward : [0.   0.09] || avg reward :  0.206 || Noise  0.062 || 0.279 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2788/3023  92% ETA:  0:01:17 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2787 with 90 steps || Reward : [0.2  0.09] || avg reward :  0.206 || Noise  0.061 || 0.557 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2788 with 64 steps || Reward : [0.1  0.09] || avg reward :  0.206 || Noise  0.061 || 0.438 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2789 with 30 steps || Reward : [0.   0.09] || avg reward :  0.206 || Noise  0.061 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2791/3023  92% ETA:  0:01:16 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2790 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.207 || Noise  0.061 || 0.485 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2791 with 69 steps || Reward : [0.2  0.09] || avg reward :  0.208 || Noise  0.061 || 0.495 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2793/3023  92% ETA:  0:01:15 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2792 with 140 steps || Reward : [0.3  0.19] || avg reward :  0.210 || Noise  0.061 || 0.746 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2793 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.210 || Noise  0.061 || 0.366 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2795/3023  92% ETA:  0:01:14 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2794 with 203 steps || Reward : [0.39000001 0.40000001] || avg reward :  0.213 || Noise  0.061 || 1.051 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2795 with 32 steps || Reward : [0.   0.09] || avg reward :  0.213 || Noise  0.061 || 0.318 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2796 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.213 || Noise  0.061 || 0.268 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2797 with 31 steps || Reward : [0.   0.09] || avg reward :  0.213 || Noise  0.061 || 0.359 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2799/3023  92% ETA:  0:01:13 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2798 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.213 || Noise  0.061 || 0.310 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2799 with 79 steps || Reward : [0.2  0.09] || avg reward :  0.214 || Noise  0.061 || 0.531 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2800 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.214 || Noise  0.061 || 0.329 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2802/3023  92% ETA:  0:01:12 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2801 with 31 steps || Reward : [0.   0.09] || avg reward :  0.213 || Noise  0.061 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2802 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.213 || Noise  0.061 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2803 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.213 || Noise  0.060 || 0.333 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2805/3023  92% ETA:  0:01:11 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2804 with 176 steps || Reward : [0.40000001 0.39000001] || avg reward :  0.209 || Noise  0.060 || 0.919 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2805 with 30 steps || Reward : [0.   0.09] || avg reward :  0.209 || Noise  0.060 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2806 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.207 || Noise  0.060 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2808/3023  92% ETA:  0:01:10 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2807 with 67 steps || Reward : [0.1  0.19] || avg reward :  0.208 || Noise  0.060 || 0.472 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2808 with 115 steps || Reward : [0.2  0.19] || avg reward :  0.209 || Noise  0.060 || 0.634 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2809 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.209 || Noise  0.060 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2811/3023  92% ETA:  0:01:09 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2810 with 31 steps || Reward : [0.   0.09] || avg reward :  0.209 || Noise  0.060 || 0.301 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2811 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.209 || Noise  0.060 || 0.295 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2812 with 64 steps || Reward : [0.1  0.19] || avg reward :  0.210 || Noise  0.060 || 0.460 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2814/3023  93% ETA:  0:01:08 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2813 with 520 steps || Reward : [1.29000002 1.30000002] || avg reward :  0.222 || Noise  0.060 || 2.374 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2814 with 32 steps || Reward : [ 0.1  -0.01] || avg reward :  0.222 || Noise  0.060 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2816/3023  93% ETA:  0:01:08 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2815 with 822 steps || Reward : [2.09000003 2.10000003] || avg reward :  0.242 || Noise  0.060 || 3.872 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2816 with 30 steps || Reward : [0.   0.09] || avg reward :  0.242 || Noise  0.060 || 0.375 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2817 with 74 steps || Reward : [0.1  0.09] || avg reward :  0.242 || Noise  0.060 || 0.559 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2819/3023  93% ETA:  0:01:07 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2818 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.243 || Noise  0.060 || 0.545 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2819 with 139 steps || Reward : [0.29 0.3 ] || avg reward :  0.245 || Noise  0.060 || 0.862 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2821/3023  93% ETA:  0:01:07 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2820 with 766 steps || Reward : [1.89000003 2.00000003] || avg reward :  0.264 || Noise  0.059 || 3.457 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2821 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.264 || Noise  0.059 || 0.310 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2823/3023  93% ETA:  0:01:06 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2822 with 243 steps || Reward : [0.59000001 0.60000001] || avg reward :  0.269 || Noise  0.059 || 1.207 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2823 with 137 steps || Reward : [0.40000001 0.19      ] || avg reward :  0.271 || Noise  0.059 || 0.836 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2825/3023  93% ETA:  0:01:05 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2824 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.271 || Noise  0.059 || 0.385 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2825 with 105 steps || Reward : [0.2  0.19] || avg reward :  0.262 || Noise  0.059 || 0.708 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2827/3023  93% ETA:  0:01:05 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2826 with 30 steps || Reward : [0.   0.09] || avg reward :  0.258 || Noise  0.059 || 0.324 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2827 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.257 || Noise  0.059 || 0.399 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2828 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.257 || Noise  0.059 || 0.311 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2830/3023  93% ETA:  0:01:04 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2829 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.257 || Noise  0.059 || 0.413 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2830 with 30 steps || Reward : [0.   0.09] || avg reward :  0.257 || Noise  0.059 || 0.352 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2831 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.257 || Noise  0.059 || 0.409 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2833/3023  93% ETA:  0:01:03 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2832 with 1001 steps || Reward : [2.60000004 2.50000004] || avg reward :  0.282 || Noise  0.059 || 4.351 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2834/3023  93% ETA:  0:01:03 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2833 with 757 steps || Reward : [2.00000003 1.99000003] || avg reward :  0.301 || Noise  0.059 || 3.507 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2834 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.300 || Noise  0.059 || 0.333 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2835 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.300 || Noise  0.059 || 0.373 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2837/3023  93% ETA:  0:01:02 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2836 with 30 steps || Reward : [0.   0.09] || avg reward :  0.300 || Noise  0.059 || 0.314 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2837 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.300 || Noise  0.058 || 0.333 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2838 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.299 || Noise  0.058 || 0.392 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2840/3023  93% ETA:  0:01:01 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2839 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.298 || Noise  0.058 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2840 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.298 || Noise  0.058 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2841 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.298 || Noise  0.058 || 0.398 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2843/3023  94% ETA:  0:01:00 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2842 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.322 || Noise  0.058 || 4.474 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2844/3023  94% ETA:  0:01:00 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2843 with 831 steps || Reward : [2.20000003 2.09000003] || avg reward :  0.341 || Noise  0.058 || 3.671 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2845/3023  94% ETA:  0:01:00 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2844 with 1001 steps || Reward : [2.60000004 2.50000004] || avg reward :  0.347 || Noise  0.058 || 4.357 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2845 with 45 steps || Reward : [0.1  0.09] || avg reward :  0.336 || Noise  0.058 || 0.379 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2846 with 77 steps || Reward : [0.09 0.1 ] || avg reward :  0.323 || Noise  0.058 || 0.499 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2848/3023  94% ETA:  0:00:59 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2847 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.323 || Noise  0.058 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2848 with 68 steps || Reward : [0.09 0.1 ] || avg reward :  0.321 || Noise  0.058 || 0.466 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2849 with 61 steps || Reward : [0.2  0.09] || avg reward :  0.322 || Noise  0.058 || 0.418 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2851/3023  94% ETA:  0:00:58 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2850 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.322 || Noise  0.058 || 0.400 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2851 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.322 || Noise  0.058 || 0.403 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2852 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.322 || Noise  0.058 || 0.399 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2854/3023  94% ETA:  0:00:57 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2853 with 58 steps || Reward : [0.1  0.09] || avg reward :  0.322 || Noise  0.058 || 0.415 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2855/3023  94% ETA:  0:00:57 |-----------------------------------   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2854 with 215 steps || Reward : [0.49000001 0.50000001] || avg reward :  0.326 || Noise  0.057 || 1.066 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2855 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.326 || Noise  0.057 || 0.409 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2856 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.327 || Noise  0.057 || 0.474 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2858/3023  94% ETA:  0:00:56 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2857 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.327 || Noise  0.057 || 0.291 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2859/3023  94% ETA:  0:00:56 ||||||||||||||||||||||||||||||||||||   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2858 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.352 || Noise  0.057 || 4.348 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2859 with 28 steps || Reward : [ 0.1  -0.01] || avg reward :  0.352 || Noise  0.057 || 0.341 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2861/3023  94% ETA:  0:00:55 |///////////////////////////////////   | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2860 with 739 steps || Reward : [1.90000003 1.89000003] || avg reward :  0.370 || Noise  0.057 || 3.315 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2861 with 42 steps || Reward : [ 0.1  -0.01] || avg reward :  0.369 || Noise  0.057 || 0.363 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2862 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.369 || Noise  0.057 || 0.346 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2864/3023  94% ETA:  0:00:54 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2863 with 30 steps || Reward : [0.   0.09] || avg reward :  0.369 || Noise  0.057 || 0.300 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2865/3023  94% ETA:  0:00:54 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2864 with 252 steps || Reward : [0.59000001 0.60000001] || avg reward :  0.374 || Noise  0.057 || 1.253 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2865 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.374 || Noise  0.057 || 0.323 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2866 with 100 steps || Reward : [0.19 0.2 ] || avg reward :  0.374 || Noise  0.057 || 0.595 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2868/3023  94% ETA:  0:00:53 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2867 with 67 steps || Reward : [0.1  0.09] || avg reward :  0.374 || Noise  0.057 || 0.463 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2869/3023  94% ETA:  0:00:53 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2868 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.398 || Noise  0.057 || 4.416 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2870/3023  94% ETA:  0:00:52 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2869 with 1001 steps || Reward : [2.70000004 2.60000004] || avg reward :  0.423 || Noise  0.057 || 4.479 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2871/3023  94% ETA:  0:00:52 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2870 with 214 steps || Reward : [0.49000001 0.60000001] || avg reward :  0.420 || Noise  0.057 || 1.166 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2871 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.419 || Noise  0.057 || 0.333 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2872 with 46 steps || Reward : [-0.01  0.1 ] || avg reward :  0.419 || Noise  0.056 || 0.370 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2874/3023  95% ETA:  0:00:51 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2873 with 54 steps || Reward : [0.1  0.09] || avg reward :  0.419 || Noise  0.056 || 0.403 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2874 with 153 steps || Reward : [0.3  0.29] || avg reward :  0.420 || Noise  0.056 || 0.849 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2876/3023  95% ETA:  0:00:51 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2875 with 496 steps || Reward : [1.19000002 1.20000002] || avg reward :  0.429 || Noise  0.056 || 2.245 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2877/3023  95% ETA:  0:00:50 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2876 with 252 steps || Reward : [0.59000001 0.60000001] || avg reward :  0.434 || Noise  0.056 || 1.235 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2878/3023  95% ETA:  0:00:50 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2877 with 225 steps || Reward : [0.49000001 0.50000001] || avg reward :  0.438 || Noise  0.056 || 1.103 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2878 with 73 steps || Reward : [0.1  0.19] || avg reward :  0.439 || Noise  0.056 || 0.521 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2880/3023  95% ETA:  0:00:49 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2879 with 355 steps || Reward : [0.90000001 0.79000001] || avg reward :  0.447 || Noise  0.056 || 1.674 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2880 with 65 steps || Reward : [0.1  0.09] || avg reward :  0.444 || Noise  0.056 || 0.454 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2881 with 65 steps || Reward : [0.1  0.19] || avg reward :  0.435 || Noise  0.056 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2883/3023  95% ETA:  0:00:48 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2882 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.434 || Noise  0.056 || 0.406 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2883 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.434 || Noise  0.056 || 0.310 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2884 with 52 steps || Reward : [0.09 0.1 ] || avg reward :  0.434 || Noise  0.056 || 0.411 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2886/3023  95% ETA:  0:00:47 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2885 with 70 steps || Reward : [0.1  0.09] || avg reward :  0.434 || Noise  0.056 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2886 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.434 || Noise  0.056 || 0.384 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2887 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.433 || Noise  0.056 || 0.349 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2889/3023  95% ETA:  0:00:46 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2888 with 31 steps || Reward : [ 0.1  -0.01] || avg reward :  0.433 || Noise  0.056 || 0.296 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2889 with 143 steps || Reward : [0.3  0.29] || avg reward :  0.435 || Noise  0.055 || 0.701 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2891/3023  95% ETA:  0:00:46 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2890 with 290 steps || Reward : [0.70000001 0.59000001] || avg reward :  0.440 || Noise  0.055 || 1.372 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2892/3023  95% ETA:  0:00:45 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2891 with 281 steps || Reward : [0.69000001 0.70000001] || avg reward :  0.445 || Noise  0.055 || 1.357 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2893/3023  95% ETA:  0:00:45 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2892 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.468 || Noise  0.055 || 4.412 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2893 with 29 steps || Reward : [ 0.1  -0.01] || avg reward :  0.468 || Noise  0.055 || 0.326 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2894 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.465 || Noise  0.055 || 0.431 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2896/3023  95% ETA:  0:00:44 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2895 with 1001 steps || Reward : [2.60000004 2.50000004] || avg reward :  0.491 || Noise  0.055 || 4.434 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2896 with 92 steps || Reward : [0.19 0.2 ] || avg reward :  0.492 || Noise  0.055 || 0.635 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2897 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.492 || Noise  0.055 || 0.306 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2899/3023  95% ETA:  0:00:43 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2898 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.517 || Noise  0.055 || 4.355 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2899 with 63 steps || Reward : [0.2  0.09] || avg reward :  0.517 || Noise  0.055 || 0.464 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2901/3023  95% ETA:  0:00:43 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2900 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.542 || Noise  0.055 || 4.302 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2902/3023  95% ETA:  0:00:43 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2901 with 1001 steps || Reward : [2.70000004 2.60000004] || avg reward :  0.568 || Noise  0.055 || 4.465 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2903/3023  96% ETA:  0:00:42 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2902 with 216 steps || Reward : [0.49000001 0.60000001] || avg reward :  0.573 || Noise  0.055 || 1.116 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2904/3023  96% ETA:  0:00:42 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2903 with 348 steps || Reward : [0.79000001 0.90000001] || avg reward :  0.581 || Noise  0.055 || 1.626 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2904 with 51 steps || Reward : [ 0.1  -0.01] || avg reward :  0.578 || Noise  0.055 || 0.440 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2905 with 66 steps || Reward : [0.2  0.09] || avg reward :  0.579 || Noise  0.055 || 0.436 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2907/3023  96% ETA:  0:00:41 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2906 with 475 steps || Reward : [1.10000002 1.29000002] || avg reward :  0.591 || Noise  0.055 || 2.223 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2908/3023  96% ETA:  0:00:41 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2907 with 704 steps || Reward : [1.80000003 1.79000003] || avg reward :  0.607 || Noise  0.055 || 3.180 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2908 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.606 || Noise  0.054 || 0.437 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2910/3023  96% ETA:  0:00:40 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2909 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.631 || Noise  0.054 || 4.391 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2910 with 93 steps || Reward : [0.3  0.19] || avg reward :  0.633 || Noise  0.054 || 0.619 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2912/3023  96% ETA:  0:00:40 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2911 with 53 steps || Reward : [0.1  0.09] || avg reward :  0.633 || Noise  0.054 || 0.386 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2912 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.632 || Noise  0.054 || 0.316 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2913 with 71 steps || Reward : [0.2  0.09] || avg reward :  0.621 || Noise  0.054 || 0.494 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2915/3023  96% ETA:  0:00:38 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2914 with 70 steps || Reward : [0.2  0.09] || avg reward :  0.622 || Noise  0.054 || 0.467 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2915 with 30 steps || Reward : [0.   0.09] || avg reward :  0.602 || Noise  0.054 || 0.335 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2916 with 65 steps || Reward : [0.1  0.19] || avg reward :  0.603 || Noise  0.054 || 0.447 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2918/3023  96% ETA:  0:00:37 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2917 with 174 steps || Reward : [0.40000001 0.29      ] || avg reward :  0.606 || Noise  0.054 || 0.890 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2918 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.605 || Noise  0.054 || 0.416 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2919 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.603 || Noise  0.054 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2921/3023  96% ETA:  0:00:36 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2920 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.584 || Noise  0.054 || 0.423 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2921 with 55 steps || Reward : [0.1  0.09] || avg reward :  0.584 || Noise  0.054 || 0.420 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2923/3023  96% ETA:  0:00:36 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2922 with 813 steps || Reward : [2.09000003 2.10000003] || avg reward :  0.599 || Noise  0.054 || 3.625 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2923 with 66 steps || Reward : [0.1  0.19] || avg reward :  0.597 || Noise  0.054 || 0.464 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2925/3023  96% ETA:  0:00:35 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2924 with 89 steps || Reward : [0.3  0.09] || avg reward :  0.599 || Noise  0.054 || 0.568 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2926/3023  96% ETA:  0:00:35 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2925 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.623 || Noise  0.054 || 4.506 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2926 with 133 steps || Reward : [0.29       0.40000001] || avg reward :  0.626 || Noise  0.053 || 0.807 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2928/3023  96% ETA:  0:00:34 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2927 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.626 || Noise  0.053 || 0.297 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2929/3023  96% ETA:  0:00:34 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2928 with 1001 steps || Reward : [2.50000004 2.60000004] || avg reward :  0.651 || Noise  0.053 || 4.879 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2929 with 35 steps || Reward : [0.09 0.1 ] || avg reward :  0.651 || Noise  0.053 || 0.349 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2931/3023  96% ETA:  0:00:33 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2930 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.676 || Noise  0.053 || 4.503 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2931 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.676 || Noise  0.053 || 0.317 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2932 with 64 steps || Reward : [0.09 0.1 ] || avg reward :  0.651 || Noise  0.053 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2934/3023  97% ETA:  0:00:32 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2933 with 62 steps || Reward : [0.09 0.1 ] || avg reward :  0.632 || Noise  0.053 || 0.448 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2934 with 87 steps || Reward : [0.09 0.2 ] || avg reward :  0.633 || Noise  0.053 || 0.538 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2935 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.633 || Noise  0.053 || 0.306 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2937/3023  97% ETA:  0:00:31 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2936 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.658 || Noise  0.053 || 4.590 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2938/3023  97% ETA:  0:00:31 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2937 with 253 steps || Reward : [0.59000001 0.60000001] || avg reward :  0.663 || Noise  0.053 || 1.341 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2938 with 90 steps || Reward : [0.09 0.2 ] || avg reward :  0.664 || Noise  0.053 || 0.613 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2940/3023  97% ETA:  0:00:30 |////////////////////////////////////  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2939 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.664 || Noise  0.053 || 0.392 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2941/3023  97% ETA:  0:00:30 |------------------------------------  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2940 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.689 || Noise  0.053 || 4.825 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2942/3023  97% ETA:  0:00:30 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2941 with 1001 steps || Reward : [2.70000004 2.60000004] || avg reward :  0.715 || Noise  0.053 || 4.652 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2943/3023  97% ETA:  0:00:29 |||||||||||||||||||||||||||||||||||||  | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2942 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.715 || Noise  0.053 || 4.628 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2943 with 33 steps || Reward : [ 0.1  -0.01] || avg reward :  0.694 || Noise  0.053 || 0.353 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2944 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.669 || Noise  0.053 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2946/3023  97% ETA:  0:00:28 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2945 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.694 || Noise  0.052 || 4.730 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2947/3023  97% ETA:  0:00:28 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2946 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.719 || Noise  0.052 || 4.578 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2947 with 62 steps || Reward : [0.09 0.2 ] || avg reward :  0.720 || Noise  0.052 || 0.478 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2948 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.720 || Noise  0.052 || 0.288 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2950/3023  97% ETA:  0:00:27 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2949 with 30 steps || Reward : [0.   0.09] || avg reward :  0.719 || Noise  0.052 || 0.298 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2950 with 82 steps || Reward : [0.2  0.09] || avg reward :  0.720 || Noise  0.052 || 0.536 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2951 with 30 steps || Reward : [0.   0.09] || avg reward :  0.720 || Noise  0.052 || 0.299 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2953/3023  97% ETA:  0:00:26 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2952 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.720 || Noise  0.052 || 0.281 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2953 with 42 steps || Reward : [-0.01  0.1 ] || avg reward :  0.720 || Noise  0.052 || 0.387 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2954 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.716 || Noise  0.052 || 0.289 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2955 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.716 || Noise  0.052 || 0.295 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2957/3023  97% ETA:  0:00:24 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2956 with 138 steps || Reward : [0.29 0.3 ] || avg reward :  0.717 || Noise  0.052 || 0.778 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2957 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.717 || Noise  0.052 || 0.422 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2959/3023  97% ETA:  0:00:24 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2958 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.717 || Noise  0.052 || 4.520 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2960/3023  97% ETA:  0:00:23 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2959 with 1001 steps || Reward : [2.60000004 2.70000004] || avg reward :  0.743 || Noise  0.052 || 4.609 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2961/3023  97% ETA:  0:00:23 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2960 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.750 || Noise  0.052 || 4.572 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2961 with 51 steps || Reward : [0.2  0.09] || avg reward :  0.751 || Noise  0.052 || 0.437 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2963/3023  98% ETA:  0:00:22 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2962 with 1001 steps || Reward : [2.50000004 2.60000004] || avg reward :  0.776 || Noise  0.052 || 5.119 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2963 with 89 steps || Reward : [0.2  0.19] || avg reward :  0.777 || Noise  0.052 || 0.639 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2965/3023  98% ETA:  0:00:22 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2964 with 42 steps || Reward : [-0.01  0.1 ] || avg reward :  0.772 || Noise  0.051 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2965 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.772 || Noise  0.051 || 0.331 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2966 with 64 steps || Reward : [0.2  0.09] || avg reward :  0.772 || Noise  0.051 || 0.454 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2968/3023  98% ETA:  0:00:21 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 2967 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.772 || Noise  0.051 || 0.410 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2969/3023  98% ETA:  0:00:20 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2968 with 382 steps || Reward : [0.90000001 0.89000001] || avg reward :  0.755 || Noise  0.051 || 1.898 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2969 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.729 || Noise  0.051 || 0.312 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2971/3023  98% ETA:  0:00:19 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2970 with 1001 steps || Reward : [2.50000004 2.60000004] || avg reward :  0.749 || Noise  0.051 || 4.378 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2971 with 49 steps || Reward : [ 0.1  -0.01] || avg reward :  0.749 || Noise  0.051 || 0.402 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2973/3023  98% ETA:  0:00:19 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2972 with 248 steps || Reward : [0.60000001 0.59000001] || avg reward :  0.754 || Noise  0.051 || 1.203 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2974/3023  98% ETA:  0:00:18 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2973 with 605 steps || Reward : [1.49000002 1.60000002] || avg reward :  0.769 || Noise  0.051 || 2.741 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2975/3023  98% ETA:  0:00:18 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2974 with 671 steps || Reward : [1.69000003 1.70000003] || avg reward :  0.783 || Noise  0.051 || 3.009 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2975 with 55 steps || Reward : [ 0.1  -0.01] || avg reward :  0.772 || Noise  0.051 || 0.404 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2976 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.767 || Noise  0.051 || 0.392 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2978/3023  98% ETA:  0:00:17 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2977 with 1001 steps || Reward : [2.50000004 2.60000004] || avg reward :  0.788 || Noise  0.051 || 4.371 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2978 with 51 steps || Reward : [0.2  0.09] || avg reward :  0.788 || Noise  0.051 || 0.436 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2979 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.780 || Noise  0.051 || 0.400 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2981/3023  98% ETA:  0:00:16 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2980 with 1001 steps || Reward : [2.60000004 2.50000004] || avg reward :  0.805 || Noise  0.051 || 4.379 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2981 with 46 steps || Reward : [0.1  0.19] || avg reward :  0.805 || Noise  0.051 || 0.408 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2983/3023  98% ETA:  0:00:15 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2982 with 227 steps || Reward : [0.49000001 0.60000001] || avg reward :  0.810 || Noise  0.051 || 1.117 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2983 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.810 || Noise  0.051 || 0.307 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2984 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.810 || Noise  0.050 || 0.395 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2986/3023  98% ETA:  0:00:14 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2985 with 30 steps || Reward : [0.   0.09] || avg reward :  0.810 || Noise  0.050 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2986 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.810 || Noise  0.050 || 0.308 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2987 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.810 || Noise  0.050 || 0.398 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2989/3023  98% ETA:  0:00:13 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 2988 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.810 || Noise  0.050 || 0.316 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2989 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.808 || Noise  0.050 || 0.400 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2990 with 44 steps || Reward : [ 0.1  -0.01] || avg reward :  0.802 || Noise  0.050 || 0.357 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2992/3023  98% ETA:  0:00:12 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2991 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.821 || Noise  0.050 || 4.409 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2993/3023  99% ETA:  0:00:11 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2992 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.821 || Noise  0.050 || 4.404 seconds, mem : 50000\n",
      "\u001b[0mDouble Hit\n",
      "\u001b[42mEpisode 2993 with 67 steps || Reward : [0.2  0.19] || avg reward :  0.822 || Noise  0.050 || 0.474 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2994 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.822 || Noise  0.050 || 0.309 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2996/3023  99% ETA:  0:00:10 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2995 with 98 steps || Reward : [0.29000001 0.2       ] || avg reward :  0.799 || Noise  0.050 || 0.582 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 2996 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.798 || Noise  0.050 || 0.404 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 2998/3023  99% ETA:  0:00:09 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 2997 with 1001 steps || Reward : [2.50000004 2.60000004] || avg reward :  0.823 || Noise  0.050 || 4.433 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2998 with 20 steps || Reward : [ 0.1  -0.01] || avg reward :  0.798 || Noise  0.050 || 0.284 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 2999 with 44 steps || Reward : [ 0.1  -0.01] || avg reward :  0.797 || Noise  0.050 || 0.367 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3001/3023  99% ETA:  0:00:08 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3000 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.797 || Noise  0.050 || 4.391 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3001 with 27 steps || Reward : [ 0.1  -0.01] || avg reward :  0.771 || Noise  0.050 || 0.319 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 3002 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.766 || Noise  0.050 || 0.435 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3004/3023  99% ETA:  0:00:07 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 3003 with 46 steps || Reward : [ 0.1  -0.01] || avg reward :  0.758 || Noise  0.050 || 0.362 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 3004 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.758 || Noise  0.049 || 0.395 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3006/3023  99% ETA:  0:00:06 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3005 with 856 steps || Reward : [2.19000003 2.20000003] || avg reward :  0.778 || Noise  0.049 || 3.849 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3007/3023  99% ETA:  0:00:06 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3006 with 1001 steps || Reward : [2.60000004 2.50000004] || avg reward :  0.791 || Noise  0.049 || 4.508 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3007 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.774 || Noise  0.049 || 0.337 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 3008 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.774 || Noise  0.049 || 0.379 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3010/3023  99% ETA:  0:00:05 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mEpisode 3009 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.749 || Noise  0.049 || 0.305 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 3010 with 51 steps || Reward : [0.1  0.09] || avg reward :  0.747 || Noise  0.049 || 0.396 seconds, mem : 50000\n",
      "\u001b[0m\u001b[44mEpisode 3011 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.747 || Noise  0.049 || 0.407 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3013/3023  99% ETA:  0:00:03 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44mEpisode 3012 with 52 steps || Reward : [0.1  0.09] || avg reward :  0.747 || Noise  0.049 || 0.403 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3014/3023  99% ETA:  0:00:03 |||||||||||||||||||||||||||||||||||||| | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3013 with 355 steps || Reward : [0.90000001 0.89000001] || avg reward :  0.754 || Noise  0.049 || 1.680 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3014 with 31 steps || Reward : [-0.01  0.1 ] || avg reward :  0.753 || Noise  0.049 || 0.330 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3015 with 30 steps || Reward : [-0.01  0.1 ] || avg reward :  0.753 || Noise  0.049 || 0.293 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3017/3023  99% ETA:  0:00:02 |///////////////////////////////////// | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3016 with 1001 steps || Reward : [2.60000004 2.60000004] || avg reward :  0.777 || Noise  0.049 || 4.411 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3017 with 25 steps || Reward : [ 0.1  -0.01] || avg reward :  0.774 || Noise  0.049 || 0.303 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3018 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.774 || Noise  0.049 || 0.294 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3019 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.774 || Noise  0.049 || 0.335 seconds, mem : 50000\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode: 3021/3023  99% ETA:  0:00:00 |------------------------------------- | \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Hit\n",
      "\u001b[42mEpisode 3020 with 374 steps || Reward : [0.89000001 1.00000001] || avg reward :  0.783 || Noise  0.049 || 1.707 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3021 with 30 steps || Reward : [ 0.1  -0.01] || avg reward :  0.783 || Noise  0.049 || 0.338 seconds, mem : 50000\n",
      "\u001b[0m\u001b[41mEpisode 3022 with 44 steps || Reward : [ 0.1  -0.01] || avg reward :  0.763 || Noise  0.049 || 0.352 seconds, mem : 50000\n",
      "\u001b[0msave agent :  (50000, 48) (50000, 4) (50000, 2) (50000, 48) (50000, 2)\n",
      "Saved Networks and ER-memory in  trained_tennis64.pth\n",
      "Config Parameters    : \n",
      "gamma                : 0.99\n",
      "tau                  : 0.01\n",
      "action_size          : 2\n",
      "state_size           : 24\n",
      "hidden_size          : 256\n",
      "buffer_size          : 50000\n",
      "batch_size           : 256\n",
      "seed                 : 64\n",
      "max_episodes         : 3023\n",
      "dropout              : 0.01\n",
      "learn_every          : 1\n",
      "learn_num            : 2\n",
      "critic_learning_rate : 0.001\n",
      "actor_learning_rate  : 0.001\n",
      "noise_decay          : 0.999\n",
      "sigma                : 1\n",
      "num_agents           : 2\n",
      "env_file_name        : Tennis_Windows_x86_64/Tennis.exe\n",
      "load_model           : False\n",
      "save_model           : True\n",
      "train_mode           : True\n",
      "brain_name           : TennisBrain\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Summary :\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Config Parameters    : \n",
      "gamma                : 0.99\n",
      "tau                  : 0.01\n",
      "action_size          : 2\n",
      "state_size           : 24\n",
      "hidden_size          : 256\n",
      "buffer_size          : 50000\n",
      "batch_size           : 256\n",
      "seed                 : 64\n",
      "max_episodes         : 3023\n",
      "dropout              : 0.01\n",
      "learn_every          : 1\n",
      "learn_num            : 2\n",
      "critic_learning_rate : 0.001\n",
      "actor_learning_rate  : 0.001\n",
      "noise_decay          : 0.999\n",
      "sigma                : 1\n",
      "num_agents           : 2\n",
      "env_file_name        : Tennis_Windows_x86_64/Tennis.exe\n",
      "load_model           : False\n",
      "save_model           : True\n",
      "train_mode           : True\n",
      "brain_name           : TennisBrain\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from maddpg import maddpg\n",
    "import cProfile\n",
    "DoProfile = False\n",
    "\n",
    "config = {\n",
    "    'gamma'               : 0.99,\n",
    "    'tau'                 : 0.01,\n",
    "    'action_size'         : action_size,\n",
    "    'state_size'          : state_size,\n",
    "    'hidden_size'         : 256,\n",
    "    'buffer_size'         : 50000,\n",
    "    'batch_size'          : 256,\n",
    "    'seed'                : 86,\n",
    "    'max_episodes'        : 3023,\n",
    "    'dropout'             : 0.01,      # currently not active\n",
    "    'learn_every'         : 1,\n",
    "    'learn_num'           : 2,\n",
    "    'critic_learning_rate': 1e-3,\n",
    "    'actor_learning_rate' : 1e-3,\n",
    "    'noise_decay'         : 0.999,\n",
    "    'sigma'               : 1,\n",
    "    'num_agents'          : num_agents,\n",
    "    'env_file_name'       : env_file_name,\n",
    "    'load_model'          : False,\n",
    "    'save_model'          : True,\n",
    "    'train_mode'          : True,\n",
    "    'brain_name'          : brain_name}\n",
    "\n",
    "def print_config(config):\n",
    "    print('Config Parameters    : ')\n",
    "    for c,k in config.items():\n",
    "        print('{:20s} : {}'.format(c,k))\n",
    "\n",
    "config_list = []\n",
    "result_list = []\n",
    "var_range = []\n",
    "# batch = [512,1024]\n",
    "# nd = [0.999, 0.998]\n",
    "# for l in learn:\n",
    "    # for b in batch:\n",
    "        # var_range.append([l,b])\n",
    "        # for h in hidden:\n",
    "            # for n in nd:\n",
    "var_range = [0.05] #, 0.1, 0.15, 0.2, 0.4, 0.6] # , 0.999975] # , 0.6, 0.7, 0.8] #, 0.45, 0.5]\n",
    "# var_range = [0.9998, 0.9999, 0.99995] # , 0.0003, 0.0005, 0.001]# [0.2, 0.25, 0.3]\n",
    "selected_seeds = [64] # [31,36,43,44] # 24,26, 33] # [8,16] # [7,9,13,15]\n",
    "# [8,16] for learn2,sig6, hidden256, batch 256, ind\n",
    "# [41,43,48,50,54,55,57,62,64,67,77,86]\n",
    "# num_runs = 50\n",
    "for param in range(len(var_range)):\n",
    "    alt_config = config.copy()\n",
    "    # alt_config['sigma'] = var_range[param]\n",
    "    # alt_config['noise_decay'] = var_range[param]\n",
    "    # alt_config['noise_scale_trigger'] = var_range[param]\n",
    "    # alt_config['actor_learning_rate'] = var_range[param]\n",
    "    # alt_config['learn_every_low'] = var_range[param][0]\n",
    "    num_runs = len(selected_seeds)\n",
    "    for main in range(num_runs):#len(tau_range)):\n",
    "        print('-------------------------------------')\n",
    "        print('New Run :')\n",
    "        print('-------------------------------------')\n",
    "        # env = UnityEnvironment(file_name=env_file_name,no_graphics=True)\n",
    "        # brain_name = env.brain_names[0]\n",
    "        # brain = env.brains[brain_name]\n",
    "        # alt_config['seed'] += 1\n",
    "        alt_config['seed'] = selected_seeds[main]\n",
    "        print_config(alt_config)\n",
    "        config_list.append(alt_config.copy())\n",
    "        alt_config['brain_name'] = brain_name\n",
    "        agent = maddpg(env, alt_config)\n",
    "        if DoProfile:cProfile.run(\"results = agent.train()\",'PerfStats')\n",
    "        else:results = agent.train()\n",
    "        result_list.append(results)\n",
    "        # all_rewards,avg_rewards,critic_losses,actor_losses = agent.train()\n",
    "        print_config(alt_config)\n",
    "        plot_results(results)\n",
    "        \n",
    "print('-------------------------------------')\n",
    "print('-------------------------------------')\n",
    "print('Summary :')\n",
    "print('-------------------------------------')\n",
    "print('-------------------------------------')\n",
    "for param in range(len(var_range)):\n",
    "    for main in range(num_runs):\n",
    "        print_config(config_list[param*num_runs+main])\n",
    "        plot_results(result_list[param*num_runs+main])\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
